{
  "hash": "c7a0870c4b960363394776808c7d50f7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Step-function selection models for meta-analysis\ndate: '2024-06-18'\ncategories:\n- effect size\n- distribution theory\n- selective reporting\nexecute:\n  echo: false\nbibliography: \"../selection-references.bib\"\ncsl: \"../apa.csl\"\nlink-citations: true\ncode-tools: true\ntoc: true\ncrossref: \n  eq-prefix: \"\"\n---\n\n\nIn [a recent post](/posts/distribution-of-significant-effects/) I looked at the distribution of statistically significant effect sizes in studies that report multiple outcomes, when those studies are subject to a certain form of selective reporting. \nSpecifically, I considered a scenario where each effect size within the study is more likely to be reported when it is __affirmative__---or statistically significant and in the hypothesized direction---than when it is __non-affirmative__. \nBecause studies with multiple effect sizes are a very common occurrence in social science meta-analysis, it's interesting to think about how this form of selection leads to distortions of the results that are actually reported and available for meta-analysis. \nIn this post, I want to look a different scenario that is simpler in one respect but more complicated in another. \nSimpler, in that I'm going to ignore dependence issues and just think about the distribution of one effect size at a time. \nMore complicated, in that I'm going to look at a more general model for how selective reporting occurs, which I'll call the __*step-function selection model*__.\n\n# The step-function selection model \n\nThe step-function selection model was introduced by @hedges1992modeling and has been further expanded, tweaked, and studied in a bunch of subsequent work. \nThe model has two components: a set of assumptions about how effect size estimates are generated prior to selection (the __*evidence-generation process*__), and a set of assumptions about how selective reporting happens as a function of the effect size estimates (the __*selective reporting process*__). \nIn the original formulation, the evidence-generation process is a random effects model. Letting $T_i^*$ denote an effect size estimate prior to selective reporting and $\\sigma_i^*$ denote its standard error, we assume that\n$$\nT_i^* | \\sigma_i^* \\sim N\\left(\\mu, \\tau^2 + \\left(\\sigma_i^*\\right)^2\\right),\n$$ {#eq-evidence-generation}\njust as in the conventional random effects model. Here $\\mu$ is the overall average effect size and $\\tau$ is the standard deviation of the effect size distribution.\n\nFor the second component, we assume that the selective-reporting process is fully determined by the statistical significance and sign of the effect size estimates. We can therefore formalize the selective reporting process in terms of the one-sided p-values of the effect size estimates. Assuming that the degrees of freedom are large enough to not worry about, the one-sided p-value for effect size $i$ is a transformation of the effect size and its standard error:\n$$\np_i^* = 1 - \\Phi\\left(T_i^* / \\sigma_i^*\\right)\n$$ {#eq-p-onesided}\nIn the step-function model, we assume that the probability that an effect size estimate is reported (and thus available for meta-analysis) depends on where this one-sided p-value lies relative to a pre-specified set of significance thresholds, $\\alpha_1,...,\\alpha_H$. These thresholds define a set of intervals, each of which can have a different probability of selection.\nLet $O_i^*$ be a binary indicator equal to 1 if $T_i^*$ is reported and otherwise equal to zero. \nThe selective reporting process is then\n$$\n\\Pr\\left(O_i^* = 1| T_i^*, \\sigma_i^*\\right) = \\begin{cases}\n1 & \\text{if} \\quad p_i^* < \\alpha_1 \\\\ \n\\lambda_1 & \\text{if} \\quad \\alpha_h \\leq p_i^* < \\alpha_{h+1}, \\quad h = 1,...,H-1 \\\\ \n\\lambda_H & \\text{if} \\quad \\alpha_H \\leq p_i^* \\\\ \n\\end{cases}.\n$$ {#eq-selection-process}\nNote that the selection probability for the lowest interval $[0, \\alpha_1)$ is fixed to 1 because we can't estimate the absolute probability that an effect size estimate is reported. \nThe remaining parameters of the selection process therefore each represent a ratio of the probability of reporting an effect size estimate falling in a given interval to the probability of reporting an effect size estimate falling in the lowest interval.\n\nIn practice, the analyst will need to specify the thresholds of the significance intervals in order to estimate the model. One common choice is to use only a single threshold at $\\alpha_1 = .025$, which corresponds to a two-sided level of .05---Fisher's vaunted criteria for when a result should be considered significant. This is the so-called \"three-parameter\" selection model, where the parameters of interest are the average effect size $\\mu$, the heterogeneity SD $\\tau$, and the relative selection probability $\\lambda_1$. Other possible choices for thresholds might be:\n\n* A single threshold at $\\alpha_1 = .50$, so that negatively-signed effect size estimates have a different selection probability than positively-signed estimates;\n* A two-threshold model with $\\alpha_1 = .025$ and $\\alpha_2 = .50$ (I like to call this a four-parameter selection model); or\n* A model with thresholds for significant, positive results at $\\alpha_1 = .025$, for the sign of the estimate at $\\alpha_2 = .50$, and for statistically significant results in the opposite of the expected direction at $\\alpha_3 = .975$. \n\nMany other choices are possible, of course.\n\n# Distribution of observed effect sizes\n\nEquations (@eq-evidence-generation) and (@eq-selection-process) are sufficient to describe the distribution of effect sizes actually observed after selection. If we let $T_i$ and $\\sigma_i$ denote effect size estimates that are actually observed, then the distribution of $\\left(T_i | \\sigma_i\\right)$ is the same as that of $\\left(T_i^* | \\sigma_i^*, O_i^* = 1\\right)$. By Bayes Theorem, \n$$\n\\Pr(T = t | \\sigma_i) = \\frac{\\Pr\\left(O_i^* = 1| T_i^* = t, \\sigma_i^* = \\sigma_i\\right) \\times \\Pr(T_i^*  = t| \\sigma_i^* = \\sigma_i)}{\\Pr\\left(O_i^* = 1| \\sigma_i^* = \\sigma_i\\right)}\n$$ {#eq-observed-effect-distribution}\nFor the specific distributional assumptions of the step-function selection model, we can find an expression for the exact form of (@eq-observed-effect-distribution). \nNote that (@eq-selection-process) is equivalent to writing the relative selection probabilities as a function of $T_i^*$ and $\\sigma_i^*$:\n$$\nw\\left(T_i^*, \\sigma_i^*\\right) = \\begin{cases}\n1 & \\text{if} \\quad -\\sigma_i^*  \\Phi^{-1}\\left(\\alpha_1\\right) < T_i^* \\\\ \n\\lambda_1 & \\text{if} \\quad -\\sigma_i^*  \\Phi^{-1}\\left(\\alpha_{h+1}\\right) < T_i^* \\leq -\\sigma_i^*  \\Phi^{-1}\\left(\\alpha_h\\right), \\quad h = 1,...,H-1 \\\\ \n\\lambda_H & \\text{if} \\quad T_i^* \\leq -\\sigma_i^*  \\Phi^{-1}\\left(\\alpha_H \\right) \\\\ \n\\end{cases}.\n$$ {#eq-selection-weights}\nAlso note that, prior to selection, the effect size estimate $T_i^*$ have marginal variance $\\eta_i^2 = \\tau^2 + \\left(\\sigma_i^*\\right)^2$, so we can write $\\Pr(T_i^*  = t| \\sigma_i^*) =  \\frac{1}{\\eta_i}\\phi\\left(\\frac{t - \\mu}{\\eta_i}\\right)$, where $\\phi()$ is the standard normal density.  We can then write the distribution of the observed effect size estimates as\n$$\n\\Pr(T = t | \\sigma_i) = \\frac{w\\left(t, \\sigma_i\\right) \\times \\frac{1}{\\eta_i}\\phi\\left(\\frac{t - \\mu}{\\eta_i}\\right)}{A_i},\n$$ {#eq-observed-effect-density}\nwhere\n$$\n\\begin{aligned}\nA_i &= \\int w\\left(t, \\sigma_i^*\\right) \\times \\frac{1}{\\eta_i}\\phi\\left(\\frac{t - \\mu}{\\eta_i}\\right) dt \\\\\n&= \\sum_{h=0}^H \\lambda_h \\left[\\Phi(c_{hi}) - \\Phi(c_{h+1,i})\\right],\n\\end{aligned}\n$$\nwith $c_{hi} = \\left(-\\sigma_i^* \\Phi^{-1}(\\alpha_h) - \\mu\\right) / \\eta_i$ and we take $\\lambda_0 = 1$, $\\alpha_0 = 0$, and $\\alpha_{H+1} = 1$ [@hedges2005selection].\n\nThe observed effect size estimates follow what we might call a \"piece-wise normal\" distribution. \nFor a given $\\sigma_i$, the p-value thresholds correspond to fixed intervals of the range of $T_i$, and $T_i$ follows a truncated normal distribution within each interval. \nHere are some pictures of these distributions for a few different values of $\\mu$, $\\tau$, and $\\sigma_i$, using selection thresholds of $\\alpha_1 = .025$ and $\\alpha_2 = .50$ with $\\lambda_1 = 0.6$ and $\\lambda_2 = 0.3$:\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n```{ojs}\nmath = require(\"mathjs\")\nnorm = import('https://unpkg.com/norm-dist@3.1.0/index.js?module')\n\nlambda = Array(H+1).fill(1)\n\neta = math.sqrt(tau**2 + sigma**2)\n\n```\n\n\n:::: {.grid .column-page-inset}\n\n::: {.g-col-7}\n\n:::\n\n::: {.g-col-5}\n\n\n```{ojs}\n//| panel: input\n\nviewof H = Inputs.range(\n  [1, 10], \n  {value: 1, step: 1, label: \"Number of thresholds (H):\"}\n)\n\nviewof mu = Inputs.range(\n  [-2, 2], \n  {value: 0, step: 0.01, label: \"Average effect size (mu):\"}\n)\n\nviewof tau = Inputs.range(\n  [0, 2], \n  {value: 0.10, step: 0.01, label: \"Heterogeneity SD (tau):\"}\n)\n\nviewof sigma = Inputs.range(\n  [0, 1], \n  {value: 0.10, step: 0.01, label: \"Standard error (sigma):\"}\n)\n\n```\n\n:::\n\n::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}