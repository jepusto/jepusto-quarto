{
  "hash": "6bcb759d9e9775cbd1e7db43202fa4bd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Copas selection models for meta-analysis\ndate: '2024-07-21'\ncategories:\n- effect size\n- distribution theory\n- selective reporting\ndraft: true\nexecute:\n  echo: false\nbibliography: \"../selection-references.bib\"\ncsl: \"../apa.csl\"\nlink-citations: true\ncode-tools: true\ntoc: true\ncss: styles.css\ncrossref: \n  eq-prefix: \"\"\n---\n\n\nRecently, I've been working a lot on models for selective reporting of study results in meta-analysis.\nI've mostly focused on [step-function selection models](/posts/step-function-selection-models/) [@hedges1992modeling; @vevea1995general; @Hedges1996estimating; @vevea2005publication], which assume that selective reporting of study results is driven fully by the $p$-values of the reported effect size estimates (and specifically, where those $p$-values fall relative to certain thresholds).\nThis is not the only form of selection model, though.\nOne prominent alternative model, usually referred to as the Copas selection model, is based on distinctly different assumptions than the step-function model.\nThis model was described in a series of papers by John Copas and colleagues [@copas1997inference; @copas1999what; @copas2000metaanalysis; @Copas2001sensitivity] and has received a fair amount of attention in the literature on meta-analysis of medical and epidemiological research, but relatively little attention from the social science side of things. \nIn this post, I'll give an overview of the Copas model and highlight some of the ways that it differs from step function selection models.\n\n# The Copas selection model \n\nSimilar to the step function selection model, the Copas model is composed of two components: an _evidence-generating process_ that describes the distribution of effect size estimates prior to selection and a _selective reporting process_ that describes how selective reporting happens as a function of the effect size estimates. \nThe evidence-generating process is (once again) just a conventional random effects model. \nLetting $T_i^*$ denote an effect size estimate prior to selective reporting, $\\theta_i^*$ denote the corresponding effect size parameter, and $\\sigma_i^*$ denote its (known) standard error, we assume that effect size estimate $i$ is drawn from a normal distribution with mean $\\theta_i^*$ and standard deviation $\\sigma_i^*$:\n$$\nT_i^* | \\theta_i^*, \\sigma_i^* \\sim N\\left(\\theta_i^*,  \\left(\\sigma_i^*\\right)^2\\right).\n$$ {#eq-evidence-generation-level1}\nWe further assume that the effect size parameters are drawn from a normal distribution with overall average effect size $\\mu$ and standard deviation $\\tau$:\n$$\n\\theta_i^* | \\sigma_i^* \\sim N\\left(\\mu,  \\tau^2\\right).\n$$ {#eq-evidence-generation-level2}\nThe full evidence-generating process can also be written as a random effects model with two sources of error:\n$$\nT_i^* = \\mu + \\nu_i^* + \\epsilon_i^*,\n$$ {#eq-evidence-generation-full}\nwhere $\\nu_i^* \\sim N(0, \\tau^2)$ and $\\epsilon_i^* \\sim N\\left(0, \\left(\\sigma_i^*\\right)^2\\right)$.\n\nThe second component is where the Copas model diverges from the step-function model. The Copas model posits that selection is driven by a latent index $\\zeta_i$ that is normally distributed and correlated with $\\epsilon_i^*$, with mean that is a function of $\\sigma_i^*$:\n$$\n\\zeta_i = \\alpha + \\frac{\\beta}{\\sigma_i^*} + \\delta_i,\n$$ {#eq-selection}\nwhere $\\delta_i \\sim N(0, 1)$ and $\\text{cor}(\\delta_i, \\epsilon_i^*) = \\rho$. \nWith this specification, $T_i^*$ is reported (and thus available for inclusion in a meta-analysis) if $\\zeta_i > 0$ and is otherwise unreported.\nFollowing the notation of my previous post, I'll use $O_i^*$ to denote a binary indicator equal to 1 if $T_i^*$ is reported and otherwise equal to zero, so $\\Pr\\left(O_i^* = 1 | \\sigma_i^*\\right) = \\Pr\\left(\\zeta_i > 0 | \\sigma_i^*\\right)$.\n\n@Copas2001sensitivity calls $\\zeta_i$ the _propensity for selection_. \nUnder the posited model, the selection propensity depends both on the precision of the study through $\\sigma_i^*$ (because the mean of $\\zeta_i$ depends on  the inverse of $\\sigma_i^*$) and on the magnitude of the reported effect size estimate (because $\\zeta_i$ is correlated with $\\epsilon_i^*$).\nThe parameter $\\alpha$ controls the overall probability of selection, irrespective of the findings; $\\beta$ controls how strongly selection depends on study precision; and $\\rho$ controls how strongly selection depends on the effect size estimate itself.\n\nThe Copas model posits a stable correlation $\\rho$ between the selection propensity index and the _samplng error_ of the random effects model, $\\epsilon_i^*$. \nIf there is heterogeneity in the effect size parameters and heterogeneity in the sampling variances, then the correlation between $\\zeta_i$ and $T_i^*$ will be lower than $\\rho$ and will differ from  study to study. \nWith a little variance algebra, it can be seen that\n$$\n\\text{cor}\\left(\\zeta_i, T_i^* | \\sigma_i^*\\right) = \\tilde\\rho_i = \\frac{\\rho \\sigma_i^*}{\\sqrt{\\tau^2 + \\left(\\sigma_i^*\\right)^2}}. \n$$ {#eq-zeta-correlation}\nUsing the correlation, we can write the selection propensity index in terms of a regression on $T_i^*$:\n$$\n\\zeta_i | T_i^*, \\sigma_i^* \\sim N \\left(\\alpha + \\frac{\\beta}{\\sigma_i^*} + \\tilde\\rho_i \\left(\\frac{T_i^* - \\mu}{\\sqrt{\\tau^2 + \\left(\\sigma_i^*\\right)^2}}\\right), \\ 1 - \\rho_i^2\\right).\n$$\nThus, given the effect size estimate $T_i^*$ and its standard error $\\sigma_i^*$, the probability that finding $i$ is reported is\n$$\n\\Pr\\left(O_i^* = 1 | T_i^*, \\sigma_i^*\\right) = \\Phi\\left(\\frac{1}{\\sqrt{1 - \\tilde\\rho_i^2}}\\left[\\alpha + \\frac{\\beta}{\\sigma_i^*} + \\tilde\\rho_i \\left(\\frac{T_i^* - \\mu}{\\sqrt{\\tau^2 + \\left(\\sigma_i^*\\right)^2}}\\right)\\right]\\right)\n$$ {#eq-conditional-selection-probability}\n[@Copas2001sensitivity, Equation 4; @hedges2005selection, Equation 9.6].\n\n# Distribution of observed effect sizes\n\nThe observed effect size estimates $T_i$ follow a distribution equivalent to that of $\\left(T_i^* | \\sigma_i^*, O_i^* = 1\\right)$. It's possible to find an analytic expression for the density of the observed effect sizes (using Bayes Theorem, just as in [my previous post](/posts/step-function-selection-models/)). The density of the observed $T_i$'s is\n$$\n\\Pr\\left(T_i = t| \\sigma_i^*\\right) = \\Pr\\left(T_i^* = t | \\sigma_i^*, O_i^* = 1\\right) = \\frac{\\Pr\\left(O_i^* = 1 | T_i^* = t, \\sigma_i^*\\right) \\times \\Pr\\left(T_i^* = t | \\sigma_i^*\\right)}{\\Pr\\left(O_i^* = 1 | \\sigma_i^*\\right)},\n$$ {#eq-Bayes-theorem}\nwhere the first term in the numerator is given in (@eq-conditional-selection-probability), the second term in the numerator can be derived from (@eq-evidence-generation-full), and the denominator can be derived from (@eq-selection).\nSubstituting everything into the above gives\n$$\n\\Pr\\left(T_i = t| \\sigma_i^*\\right) = \\frac{1}{\\sqrt{\\tau^2 + \\left(\\sigma_i^*\\right)^2}} \\phi\\left(\\frac{t - \\mu}{\\sqrt{\\tau^2 + \\left(\\sigma_i^*\\right)^2}}\\right) \\times \\frac{\\Phi\\left(\\frac{1}{\\sqrt{1 - \\tilde\\rho_i^2}}\\left[\\alpha + \\frac{\\beta}{\\sigma_i^*} + \\tilde\\rho_i \\left(\\frac{t - \\mu}{\\sqrt{\\tau^2 + \\left(\\sigma_i^*\\right)^2}}\\right)\\right]\\right)} {\\Phi\\left(\\alpha + \\frac{\\beta}{\\sigma_i^*}\\right)}\n$$ {#eq-observed-density}\nThis density is identical to that of the _generalized skew-normal distribution_ [@arellano20006unification]. \n\nHere is an interactive graph showing the distribution of the effects prior to selection (in grey) and the distribution of observed effect sizes (in blue) based on the Copas selection model.[^unnormalized]\nInitially, the selection parameters are set to $\\alpha = -3$, $\\beta = 0.5$ and $\\rho = 0.5$, but you can change these however you like. Try wiggling $\\rho$ up and down to see how the bias and shape of the density changes.\n\n[^unnormalized]: Note that I've plotted the _unnormalized density_ (the density before dividing by $\\Phi\\left(\\alpha + \\frac{\\beta}{\\sigma_i^*}\\right)$) so that it's clear that the distribution of observed effects is a subset of the distribution of effects prior to selection. \n\n\n```{ojs}\nmath = require(\"mathjs\")\nnorm = import('https://unpkg.com/norm-dist@3.1.0/index.js?module')\n\neta = math.sqrt(tau**2 + sigma**2)\nrho_i = rho * sigma / eta\nu = alpha + beta / sigma\nlambda = norm.pdf(u) / norm.cdf(u)\n\nAi = norm.cdf(u)\nET = mu + rho * sigma * lambda\nSDT = eta * math.sqrt(1 - rho_i**2 * lambda * (u + lambda))\nAi_toprint = Ai.toFixed(3)\nET_toprint = ET.toFixed(3)\neta_toprint = eta.toFixed(3)\nSDT_toprint = SDT.toFixed(3)\n\nfunction CopasSelection(t, s, alpha, beta, rho) {\n  let u = alpha + beta / s;\n  let eta_ = math.sqrt(tau**2 + s**2);\n  let rho_i_ = rho * s / eta_; \n  let z = (t - mu) / eta_;\n  let x = (u + rho_i_ * z) / math.sqrt(1 - rho_i_**2);\n  return norm.cdf(x);\n}\n\n```\n\n```{ojs}\npts = 201\n\ndat = Array(pts).fill().map((element, index) => {\n  let t = mu - 3 * eta + index * eta * 6 / (pts - 1);\n  let dt = norm.pdf((t - mu) / eta) / eta;\n  let pr_sel = CopasSelection(t, sigma, alpha, beta, rho);\n  return ({\n    t: t,\n    d_unselected: dt,\n    d_selected: pr_sel * dt\n  })\n})\n\n```\n\n\n::::: {.grid .column-page}\n\n:::: {.g-col-8 .center}\n\n\n```{ojs}\nPlot.plot({\n  height: 300,\n  y: {\n    grid: false,\n    label: \"Density\"\n  },\n  x: {\n    label: \"Effect size estimate (Ti)\"\n  },   \n  marks: [\n    Plot.ruleY([0]),\n    Plot.ruleX([0]),\n    Plot.areaY(dat, {x: \"t\", y: \"d_unselected\", fillOpacity: 0.3}),\n    Plot.areaY(dat, {x: \"t\", y: \"d_selected\", fill: \"blue\", fillOpacity: 0.5}),\n    Plot.lineY(dat, {x: \"t\", y: \"d_selected\", stroke: \"blue\"})\n  ]\n})\n```\n\n\n:::{.moments}\n\n\n```{ojs}\ntex`\n\\begin{aligned}\n\\mu &= ${mu} & \\qquad \\eta &= ${eta_toprint} \\\\\n\\mathbb{E}\\left(T_i | \\sigma_i\\right) &= ${ET_toprint}\n& \\qquad \\sqrt{\\mathbb{V}\\left(T_i | \\sigma_i\\right)} &= ${SDT_toprint} \\\\ \n\\Pr(O_i^* = 1 | \\sigma_i^*) &= ${Ai_toprint}\n\\end{aligned}\n`\n```\n\n:::\n\n::::\n\n:::: {.g-col-4}\n\n\n```{ojs}\n//| panel: input\n\nviewof mu = Inputs.range(\n  [-2, 2], \n  {value: 0.15, step: 0.01, label: \"Average effect size (mu):\"}\n)\n\nviewof tau = Inputs.range(\n  [0, 2], \n  {value: 0.10, step: 0.01, label: \"Heterogeneity SD (tau):\"}\n)\n\nviewof sigma = Inputs.range(\n  [0, 1], \n  {value: 0.20, step: 0.01, label: \"Standard error (sigma):\"}\n)\n\nviewof alpha = Inputs.range(\n  [-10, 10],\n  {value: -3, step: 0.1, label: \"alpha selection parameter\"}\n)\n\nviewof beta = Inputs.range(\n  [0, 2],\n  {value: 0.5, step: 0.01, label: \"beta selection parameter\"}\n)\n\nviewof rho = Inputs.range(\n  [-1, 1],\n  {value: 0.5, step: 0.01, label: \"rho selection parameter\"}\n)\n\n```\n\n\n::::\n\n\n:::::\n\n# Moments of $T_i | \\sigma_i$\n\n@arnold1999nontruncated derived the moment-generating function and first several moments of a further generalization of the skew-normal distribution, of which the distribution of $T_i$ is a special case. Letting $Z_i = \\frac{T_i - \\mu}{\\sqrt{\\tau^2 + \\sigma_i^2}}$, $u_i = \\alpha + \\frac{\\beta}{\\sigma_i}$, and $\\lambda(u_i) = \\phi(u_i) / \\Phi(u_i)$, they give the first two moments of $Z_i$ as\n$$\n\\begin{aligned}\n\\mathbb{E}\\left(Z_i | \\sigma_i \\right) &= \\rho_i \\lambda\\left(u_i\\right) \\\\\n\\mathbb{E}\\left(Z_i^2 | \\sigma_i \\right) &= 1 - \\rho_i^2 u_i \\lambda(u_i) \n\\end{aligned}\n$$\nby which it follows that\n$$\n\\begin{aligned}\n\\mathbb{E}\\left(T_i | \\sigma_i \\right) &= \\mu + \\sqrt{\\tau^2 + \\sigma_i^2} \\times \\rho_i \\lambda\\left(u_i\\right) \\\\\n &= \\mu + \\rho \\sigma_i \\lambda\\left(u_i\\right)\n \\end{aligned}\n$$ {#eq-Ti-mean}\nand \n$$\n\\begin{aligned}\n\\mathbb{V}\\left(T_i | \\sigma_i \\right) &= \\left(\\tau^2 + \\sigma_i^2\\right) \\left(1 - \\rho_i^2\\lambda(u_i) \\times [u_i  + \\lambda(u_i)]\\right) \\\\\n &= \\tau^2 + \\sigma_i^2\\left(1 - \\rho^2 \\lambda(u_i) \\times [u_i  + \\lambda(u_i)]\\right).\n\\end{aligned}\n$$ {#eq-Ti-variance}\nThe expression for $\\mathbb{E}\\left(T_i | \\sigma_i \\right)$ is also given in @copas2000metaanalysis and @Copas2001sensitivity.[^variance-of-T]\n\n[^variance-of-T]: These sources give the variance of the observed effect size estimates as $\\mathbb{V}\\left(T_i | \\sigma_i \\right) =  \\sigma_i^2\\left(1 - \\rho^2 \\lambda(u_i) \\times [u_i  + \\lambda(u_i)]\\right)$ [see p. 250 of @copas2000metaanalysis; see Equation 6 of @Copas2001sensitivity]. However, these expressions are incorrect as stated because they omit the between-study heterogeneity $\\tau^2$.\n\nSeveral things are noteworthy about these expressions.\nFor one, the expectation of $T_i$ is additive in $\\mu$, so the bias $\\mathbb{E}(T_i | \\sigma_i) - \\mu$ does not depend on the location of the distribution prior to selection. Nor does it depend on the degree of heterogeneity $\\tau$. \nLikewise, the variance of $T_i$ is additive in $\\tau^2$. Only the sampling variance is affected by selection.\nAll of these properties are in contrast to the step-function selection model, where both the bias and the variance are complex functions that _do_ depend on $\\mu$ and $\\tau$. \n\nUnder the Copas model, the bias of $T_i$ is directly proportional to $\\rho$ and is a more complicated function of $\\alpha$ and $\\beta$ (through $u_i$). \nThe bias is an increasing function of $\\sigma$, the shape of which depends on $\\alpha$ and $\\beta$. \nHere's an illustration of $\\sigma_i \\times \\lambda(u_i)$ as a function of $\\sigma_i$ for a few different values of the selection parameters:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\nWhen $\\beta = 0$, the bias is directly proportional to $\\sigma_i$, just like in an Egger regression or the PET meta-regression adjustment method [@stanley2008metaregression].\nAs $\\beta$ increases, the bias is initially very close to zero and then grows almost linearly after a certain point---much as in the kinked meta-regression adjustment proposed by @bom2019kinked.\nVery curious.\n\n# Funnel density\n\nHere is an interactive funnel plot showing the distribution of effect size estimates under the Copas selection model. I initially set $\\mu = 0.15$ and $\\tau = 0.10$ and selection parameters of $\\alpha = -3$, $\\beta = 0.5$ and $\\rho = 0.5$, but you can change these however you like.\n\n\n```{ojs}\nSE_pts = 100\nt_pts = 181\nsigma_max = 0.5\neta_max_f = math.sqrt(tau_f**2 + sigma_max**2)\n\nfunnel_dat = Array(t_pts * SE_pts).fill(null).map((x,row) => {\n  let i = row % SE_pts;\n  let j = (row - i) / SE_pts;\n  let sigma = (i + 1) * sigma_max / SE_pts;\n  let t = mu_f - 3 * eta_max_f + j * eta_max_f * 6 / (t_pts - 1);\n  let eta = math.sqrt(tau_f**2 + sigma**2);\n  let dt = norm.pdf((t - mu_f) / eta) / eta;\n  let pr_sel = CopasSelection(t, sigma, alpha_f, beta_f, rho_f);\n  return ({t: t, sigma: sigma, dt: dt, pr_sel: pr_sel, d_selected: pr_sel * dt});\n})\n\nsigline_dat = [\n  ({t: 0, sigma: 0}),\n  ({t: sigma_max * norm.icdf(0.975), sigma: sigma_max})\n]\n\n```\n\n\n::::: {.grid .column-page}\n\n:::: {.g-col-8 .center}\n\n\n```{ojs}\nPlot.plot({\n  height: 400,\n  width: 700,\n  padding: 0,\n  grid: false,\n  x: {axis: \"top\", label: \"Effect size estimate (Ti)\"},\n  y: {label: \"Standard error (sigma_i)\", reverse: true},\n  color: {\n    scheme: \"pubugn\",\n    type: \"sqrt\",\n    label: \"Density\"\n  },\n  marks: [\n    Plot.dot(funnel_dat, {x: \"t\", y: \"sigma\", fill: \"d_selected\", r:2, symbol: \"square\"}),\n    Plot.ruleY([0], {stroke: \"black\"}),\n    Plot.ruleX([0], {stroke: \"grey\"}),\n    Plot.line(sigline_dat, {x: \"t\", y: \"sigma\", stroke: \"gray\", strokeWidth: 1})\n  ]\n})\n```\n\n```{ojs}\nPlot.legend({color: {scheme: \"pubugn\", type: \"sqrt\", label: \"Density\"}})\n```\n\n\n::::\n\n:::: {.g-col-4}\n\n\n```{ojs}\n//| panel: input\n\nviewof mu_f = Inputs.range(\n  [-2, 2], \n  {value: 0.15, step: 0.01, label: \"Average effect size (mu):\"}\n)\n\nviewof tau_f = Inputs.range(\n  [0, 2], \n  {value: 0.10, step: 0.01, label: \"Heterogeneity SD (tau):\"}\n)\n\nviewof alpha_f = Inputs.range(\n  [-10, 10],\n  {value: -3, step: 0.1, label: \"alpha selection parameter\"}\n)\n\nviewof beta_f = Inputs.range(\n  [0, 2],\n  {value: 0.5, step: 0.01, label: \"beta selection parameter\"}\n)\n\nviewof rho_f = Inputs.range(\n  [-1, 1],\n  {value: 0.5, step: 0.01, label: \"rho selection parameter\"}\n)\n```\n\n\n::::\n\n:::::\n\nIf you fiddle with the selection parameters, you can see how the density of certain areas of the plot changes.\n\n# Comments\n\nThe Copas model has three parameters but only produces a limited range of distributional shapes.\n\nThe selection propensity index is correlated with the _sampling errors_ rather than with the marginal distribution of $T_i^*$.\n\nThe probability of selection is not directly connected to $p$-values.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}