{
  "hash": "0e3f65895721ee64ec73976b3c1e067a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Implementing Consul's generalized Poisson distribution in Stan\nauthors: admin\ndate: '2023-12-06'\ncategories:\n- Bayes\n- simulation\n- distribution-theory\n- generalized linear model\n- programming\n- Rstats\ncode-fold: show\ncode-tools: true\n\n---\n\n\n$$\n\\def\\Pr{{\\text{Pr}}}\n\\def\\E{{\\text{E}}}\n\\def\\Var{{\\text{Var}}}\n\\def\\Cov{{\\text{Cov}}}\n\\def\\bm{\\mathbf}\n\\def\\bs{\\boldsymbol}\n$$\n\nFor a project I am working on, we are using [Stan](https://mc-stan.org/) to fit generalized random effects location-scale models to a bunch of count data. \nIn [a previous post](/double-poisson-in-Stan/), I walked through our implementation of [Efron's (1986)](https://doi.org/10.2307/2289002) double-Poisson distribution, which we are interested in using because it allows for both over- and under-dispersion relative to the Poisson distribution. \nAnother distribution with these properties is the generalized Poisson distribution described by [Consul and Jain (1973)](https://doi.org/10.1080/00401706.1973.10489112).\n\nIn this post, I'll walk through my implementation of the GPO in Stan.\nThe [`gamlss.dist` package](https://cran.r-project.org/package=gamlss.dist) provides a full set of distributional functions for the generalized Poisson distribution, including a sampler, but the functions are configured to only allow for over-dispersion. Since I'm interested in allowing for under-dispersion as well, I'll need to write my own functions. As in my previous post, I can validate my Stan functions against the functions from `gamlss.dist` (although only for over-dispersion scenarios).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(patchwork)   # composing figures\nlibrary(gamlss.dist) # DPO distribution functions\nlibrary(rstan)       # Stan interface to R\nlibrary(brms)        # fitting generalized linear models\nlibrary(bayesplot)   # Examine fitted models\nlibrary(loo)         # Model fit measures\n```\n:::\n\n\n## The generalized Poisson \n\nConsul and Jain's generalized Poisson distribution is a discrete distribution for non-negative counts, with support $\\mathcal{S}_X = \\{0, 1, 2, 3, ...\\}$. \nThe mean-variance relationship of the generalized Poisson is constant; for $X \\sim GPO(\\mu, \\phi)$,  $\\text{E}(X) = \\mu$ and $\\text{Var}(X) = \\mu / \\phi$ for $0 < \\phi < 1$; the expectation and variance are not exact but are close approximations when there is underdispersion, so $\\phi > 1$. Thus, like the double-Poisson distribution, the generalized Poisson satisfies the assumptions of a quasi-Poisson generalized linear model (at least approximately). \n\nThe density of the generalized Poisson distribution with mean $\\mu$ and inverse-disperson $\\phi$ is:\n$$\nf(x | \\mu, \\phi) = \\mu \\sqrt{\\phi} \\left( x + \\sqrt{\\phi}(\\mu - x) \\right)^{x-1} \\frac{\\exp \\left[-\\left( x + \\sqrt{\\phi}(\\mu - x)\\right)\\right]}{x!}.\n$$\nWe then have\n$$\n\\ln f(x | \\mu, \\phi) = \\frac{1}{2} \\ln \\phi + \\ln \\mu + (x - 1) \\ln \\left( x + \\sqrt{\\phi}(\\mu - x) \\right) - \\left( x + \\sqrt{\\phi}(\\mu - x) \\right) - \\ln \\left(x!\\right).\n$$\nUsing the GPO with under-dispersed data is a little bit more controversial (by statistical standards) than using the DPO. \nThis is because, for parameter values corresponding to under-dispersion, its probability mass function becomes negative for large counts. In particular, note that for values $x > \\frac{\\mu\\sqrt\\phi}{\\sqrt\\phi - 1}$, the quantity $x + \\sqrt{\\phi}(\\mu - x)$ becomes negative, and so $f(x| \\mu, \\phi)$ is no longer a proper probability. \nConsul suggested handling this situation by truncating the distribution at $m = \\left\\lfloor \\frac{\\mu\\sqrt\\phi}{\\sqrt\\phi - 1}\\right\\rfloor$. However, doing so makes the distribution only an approximation, such that $\\mu$ is no longer exactly the mean and $\\phi$ is no longer exactly the inverse dispersion. \nFor modest under-dispersion of no less than 60% of the mean, $1 < \\phi < 5 / 3$ and the truncation point is fairly extreme, with $m \\approx 4.4 \\mu$, so I'm not too worried about this issue. \nWe'll see how it plays out in application, of course.\n\n# Log of the probability mass function\n\nHere's a Stan function implementing the lpmf, with the truncation bit:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstancode_lpmf <- \"\nreal gpo_lpmf(int X, real mu, real phi) {\n  real ans;\n  real m = mu / (1 - inv(sqrt(phi)));\n  real z = X + sqrt(phi) * (mu - X);\n  if (phi > 1 && X > m)\n    ans = negative_infinity();\n  else \n    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);\n  return ans;\n}\n\"\n```\n:::\n\n\nTo check that this is accurate, I'll compare the Stan function to the corresponding function from `gamlss.dist` for a couple of different parameter values and for $x = 0,...,100$. If my function is accurate, my calculated log-probabilities should be equal to the results from `gamlss.dist::dGPO`. Note that the `gamlss.dist` function uses a different parameterization for the dispersion, with $\\sigma = \\frac{\\phi^{-1/2} - 1}{\\mu}$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwriteLines(paste(\"functions {\", stancode_lpmf, \"}\", sep = \"\\n\"), \"GPO-lpmf.stan\")\nexpose_stan_functions(\"GPO-lpmf.stan\")\n\ntest_lpmf <- \n  expand_grid(\n    mu = c(2, 5, 10, 20),\n    phi = seq(0.1, 0.9, 0.1),\n    X = 0:100\n  ) %>%\n  mutate(\n    sigma = (phi^(-1/2) - 1) / mu,\n    gamlss_lpmf = dGPO(x = X, mu = mu, sigma = sigma, log = TRUE),\n    my_lpmf = pmap_dbl(.l = list(X = X, mu = mu, phi = phi), .f = gpo_lpmf),\n    diff = my_lpmf - gamlss_lpmf\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(test_lpmf, aes(factor(phi), diff, color = factor(phi))) + \n  geom_boxplot() + \n  facet_wrap( ~ mu, labeller = \"label_both\", ncol = 2) + \n  theme_minimal() + \n  labs(x = \"phi\") + \n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nChecks out. Onward!\n\n# Quantile function\n\nI'll next implement the generalized Poisson quantile function, taking advantage of a recurrence relationship for sequential values. Note that\n$$\n\\begin{aligned}\nf(0 | \\mu, \\phi) &= \\exp \\left(-\\mu \\sqrt{\\phi}\\right) \\\\\nf(x | \\mu, \\phi) &= f(x - 1 | \\mu, \\phi) \\times \\frac{\\left(x + \\sqrt{\\phi}(\\mu - x)\\right)^{x - 1}}{\\left(x - 1 + \\sqrt{\\phi}(\\mu - (x - 1))\\right)^{x - 2}} \\times \\frac{\\exp(\\sqrt{\\phi} - 1)}{x}\n\\end{aligned}\n$$\nwhere the second expression holds for $x \\geq 1$.\n\nThe function below computes the quantile given a value $p$ by computing the cumulative distribution function until $p$ is exceeded: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstancode_quantile <- \" \nint gpo_quantile(real p, real mu, real phi) {\n  int q = 0;\n  real phi_sqrt = sqrt(phi);\n  real mu_phi_sqrt = mu * phi_sqrt;\n  real m;\n  if (phi > 1) \n    m = mu / (1 - inv(phi_sqrt));\n  else \n    m = positive_infinity();\n  real lpmf = - mu_phi_sqrt;\n  real cdf = exp(lpmf);\n  real ln_inc;\n  while (cdf < p && q < m) {\n    q += 1;\n    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);\n    lpmf += ln_inc;    \n    cdf += exp(lpmf);\n  }\n  return q;\n}\n\"\n```\n:::\n\n\nIf my quantile function is accurate, it should match the value computed from `gamlss.dist::qDPO()` exactly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwriteLines(paste(\"functions {\", stancode_quantile, \"}\", sep = \"\\n\"), \"GPO-quantile.stan\")\nexpose_stan_functions(\"GPO-quantile.stan\")\n\ntest_quantile <- \n  expand_grid(\n    mu = c(2, 5, 10, 20),\n    phi = seq(0.1, 0.9, 0.1),\n  ) %>%\n  mutate(\n    sigma = (phi^(-1/2) - 1) / mu,\n    p = map(1:n(), ~ runif(100)),\n  ) %>%\n  unnest(p) %>%\n  mutate(\n    my_q = pmap_dbl(list(p = p, mu = mu, phi = phi), .f = gpo_quantile),\n    gamlss_q = qGPO(p, mu = mu, sigma = sigma),\n    diff = my_q - gamlss_q\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(test_quantile, aes(factor(phi), diff, color = factor(phi))) + \n  geom_boxplot() + \n  facet_wrap( ~ mu, labeller = \"label_both\", ncol = 2) + \n  theme_minimal() + \n  labs(x = \"phi\") + \n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/check-quantile-plot-1.png){width=672}\n:::\n:::\n\n\nI should enter this figure in the competition for the world's most boring statistical graphic.\n\n# Sampler\n\nThe last thing I'll need is a sampler, which I'll implement by generating random points from a uniform distribution, then computing the generalized Poisson quantiles of these random points. My implementation just generates a single random variate:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstancode_qr <- \"\nint gpo_quantile(real p, real mu, real phi) {\n  int q = 0;\n  real phi_sqrt = sqrt(phi);\n  real mu_phi_sqrt = mu * phi_sqrt;\n  real m;\n  if (phi > 1) \n    m = mu / (1 - inv(phi_sqrt));\n  else \n    m = positive_infinity();\n  real lpmf = - mu_phi_sqrt;\n  real cdf = exp(lpmf);\n  real ln_inc;\n  while (cdf < p && q < m) {\n    q += 1;\n    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);\n    lpmf += ln_inc;    \n    cdf += exp(lpmf);\n  }\n  return q;\n}\n\nint gpo_rng(real mu, real phi) {\n  real p = uniform_rng(0,1);\n  int x = gpo_quantile(p, mu, phi);\n  return x;\n}\n\"\n```\n:::\n\n\nTo check this function, I'll generate some large samples from the generalized Poisson with a few different parameter sets. If the sampler is working properly, the empirical cumulative distribution should line up closely with the cumulative distribution computed using `gamlss.dist::pGPO()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwriteLines(paste(\"functions {\", stancode_qr, \"}\", sep = \"\\n\"), \"GPO-rng.stan\")\nexpose_stan_functions(\"GPO-rng.stan\")\n\ngpo_rng_sampler <- function(N, mu, phi) {\n  replicate(N, gpo_rng(mu = mu, phi = phi))\n}\n\ntest_rng <- \n  expand_grid(\n    mu = c(2, 5, 10, 20),\n    phi = seq(0.1, 0.9, 0.1),\n  ) %>%\n  mutate(\n    sigma = (phi^(-1/2) - 1) / mu,\n    x = pmap(.l = list(N = 10000, mu = mu, phi = phi), .f = gpo_rng_sampler),\n    tb = map(x, ~ as.data.frame(table(.x)))\n  ) %>%\n  dplyr::select(-x) %>%\n  group_by(mu, phi) %>%\n  unnest(tb) %>%\n  mutate(\n    .x = as.integer(levels(.x))[.x],\n    Freq_cum = cumsum(Freq) / 10000,\n    gamlss_F = pGPO(q = .x, mu = mu, sigma = sigma)\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(test_rng, aes(gamlss_F, Freq_cum, color = factor(phi))) + \n  geom_abline(slope = 1, color = \"blue\", linetype = \"dashed\") + \n  geom_point() + geom_line() +  \n  facet_grid(phi ~ mu, labeller = \"label_both\") + \n  theme_minimal() + \n  labs(x = \"Theoretical cdf (gamlss.dist)\", y = \"Empirical cdf (my function)\") + \n  theme(legend.position = \"none\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/check-rng-plot-1.png){width=672}\n:::\n:::\n\nAnother approach to checking the sampler is to simulate a bunch of observations and check whether the empirical mean and variance match the theoretical moments. I'll do this as well, using some values of $\\phi > 1$ to test whether the sampler still works when there's under-dispersion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_moments <- \n  expand_grid(\n    mu = c(5, 10, 20, 40, 60),\n    phi = seq(1, 2, 0.1),\n  ) %>%\n  mutate(\n    x = pmap(.l = list(N = 1e5, mu = mu, phi = phi), .f = gpo_rng_sampler),\n    M = map_dbl(x, mean),\n    S = map_dbl(x, sd),\n    M_ratio = M / mu,\n    S_ratio = S / sqrt(mu / phi)\n  ) %>%\n  dplyr::select(-x) %>%\n  pivot_longer(ends_with(\"_ratio\"),names_to = \"moment\",values_to = \"ratio\") %>%\n  mutate(\n    moment = factor(moment, levels = c(\"M_ratio\", \"S_ratio\"), labels = c(\"Sample mean\", \"Standard deviation\")),\n    mu = factor(mu)\n  )\n\nggplot(test_moments, aes(phi, ratio, color = mu)) + \n  geom_point() + geom_line() + \n  facet_wrap(~ moment) + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/test-sample-moments-1.png){width=768}\n:::\n:::\n\nLooks like the sample moments closely match the parameter values, with deviations that look pretty much like random error. Nice!\n\n# Using the custom distribution functions\n\nTo finish out my tests of these functions, I'll try out a small simulation. Following my [previous post](/Double-Poisson-in-Stan/), I'll generate data based on a generalized linear model with a single predictor $X$, where the outcome $Y$ follows a generalized Poisson distribution conditional on $X$. The data-generating process is:\n\n$$\n\\begin{aligned}\nX &\\sim \\Gamma(6,2) \\\\\nY|X &\\sim GPO(\\mu(X), \\phi) \\\\\n\\log \\mu(X) &= 2 + 0.3 \\times X\n\\end{aligned}\n$$\nwith the dispersion parameter set to $\\phi = 6/10$ so that the outcome is _over_-dispersed. I'm looking at over-dispersion here so that the negative binomial has a chance to keep up, since it doesn't allow for any degree of under-dispersion.\n\nThe following code generates a large sample from the data-generating process:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20231206)\nN <- 1500\nX <- rgamma(N, shape = 6, rate = 2)\nmu <- exp(2 + 0.3 * X)\nphi <- 6 / 10\nY <- map_dbl(mu, gpo_rng, phi = phi)\ndat <- data.frame(X = X, Y = Y)\n```\n:::\n\n\nHere's what the sample looks like, along with a smoothed regression estimated using a basic cubic spline:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(X, Y)) + \n  geom_point(alpha = 0.1) + \n  geom_smooth(method = 'gam', formula = y ~ s(x, bs = \"cs\")) + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/glm-scatterplot-1.png){width=576}\n:::\n:::\n\nHere is a fit using quasi-likelihood estimation of a log-linear model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquasi_fit <- glm(Y ~ X, family = quasipoisson(link = \"log\"), data = dat)\nsummary(quasi_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Y ~ X, family = quasipoisson(link = \"log\"), data = dat)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.981959   0.020609   96.17   <2e-16 ***\nX           0.306733   0.005525   55.52   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 1.680427)\n\n    Null deviance: 7248.1  on 1499  degrees of freedom\nResidual deviance: 2520.5  on 1498  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\nThis approach recovers the data-generating parameters quite well, with a dispersion estimate of 1.68 compared to the true dispersion parameter of 1.67. \n\n## Candidate models\n\nNow let me fit the same generalized linear model but assuming that the outcome follow a couple of different distributions, including a true Poisson (with unit dispersion), a negative binomial, the double-Poisson distribution from the previous post, and the generalized Poisson distribution. Here goes!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPoisson_fit <- \n  brm(\n    Y ~ X, family = poisson(link = \"log\"),\n    data = dat, \n    warmup = 500, \n    iter = 2500, \n    chains = 4, \n    cores = 4,\n    seed = 20231204\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnegbin_fit <- \n  brm(\n    Y ~ X, family = negbinomial(link = \"log\"),\n    data = dat, \n    warmup = 500, \n    iter = 2500, \n    chains = 4, \n    cores = 4,\n    seed = 20231204\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstancode_dpo <- \"\nreal dpo_lpmf(int X, real mu, real phi) {\n  real ans;\n  real A = inv(2) * log(phi) - phi * mu;\n  if (X == 0)\n    ans = A;\n  else\n    ans = A + X * (phi * (1 + log(mu)) - 1) - lgamma(X + 1) + (1 - phi) * X * log(X);\n  return ans;\n}\nvector dpo_cdf_vec(real mu, real phi, int maxval) {\n  real d = exp(phi * (1 + log(mu)) - 1);\n  real prob;\n  int n = maxval + 1;\n  vector[n] cdf;\n  cdf[1] = sqrt(phi) * exp(-mu * phi);\n  prob = cdf[1] * d;\n  cdf[2] = cdf[1] + prob;\n  for (i in 2:maxval) {\n    prob = prob * d * exp((1 - phi) * (i - 1) * (log(i) - log(i - 1))) / (i^phi);\n    cdf[i + 1] = cdf[i] + prob;\n    if (prob / cdf[i + 1] < 1e-8) {\n      n = i + 1;\n      break;\n    }\n  }\n  return cdf / cdf[n];\n}\nint dpo_quantile(real p, real mu, real phi, int maxval) {\n  vector[maxval + 1] cdf_vec = dpo_cdf_vec(mu, phi, maxval);\n  int q = 0;\n  while (cdf_vec[q + 1] < p) {\n      q += 1;\n    }\n  return q;\n}\nint dpo_rng(real mu, real phi, int maxval) {\n  real p = uniform_rng(0,1);\n  int x = dpo_quantile(p, mu, phi, maxval);\n  return x;\n}\n\"\ndouble_Poisson <- custom_family(\n  \"dpo\", dpars = c(\"mu\",\"phi\"),\n  links = c(\"log\",\"log\"),\n  lb = c(0, 0), ub = c(NA, NA),\n  type = \"int\"\n)\n\ndouble_Poisson_stanvars <- stanvar(scode = stancode_dpo, block = \"functions\")\n\nphi_prior <- prior(exponential(1), class = \"phi\")\n\nDPO_fit <- \n  brm(\n    Y ~ X, family = double_Poisson,\n    prior = phi_prior,\n    stanvars = double_Poisson_stanvars,\n    data = dat, \n    warmup = 500, \n    iter = 2500, \n    chains = 4, \n    cores = 4,\n    seed = 20231204\n  )\n\nexpose_functions(DPO_fit, vectorize = TRUE)\n\nlog_lik_dpo <- function(i, prep) {\n  mu <- brms::get_dpar(prep, \"mu\", i = i)\n  phi <- brms::get_dpar(prep, \"phi\", i = i)\n  y <- prep$data$Y[i]\n  dpo_lpmf(y, mu, phi)\n}\n\nposterior_predict_dpo <- function(i, prep, maxval = NULL, ...) {\n  mu <- brms::get_dpar(prep, \"mu\", i = i)\n  phi <- brms::get_dpar(prep, \"phi\", i = i)\n  if (is.null(maxval)) maxval <- 20 * mu / min(phi, 1)\n  dpo_rng(mu, phi, maxval = maxval)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstancode_gpo <- \"\nreal gpo_lpmf(int X, real mu, real phi) {\n  real ans;\n  real m = mu / (1 - inv(sqrt(phi)));\n  real z = X + sqrt(phi) * (mu - X);\n  if (phi > 1 && X > m)\n    ans = negative_infinity();\n  else \n    ans = log(mu) + inv(2) * log(phi) + (X - 1) * log(z) - z - lgamma(X + 1);\n  return ans;\n}\nint gpo_quantile(real p, real mu, real phi) {\n  int q = 0;\n  real phi_sqrt = sqrt(phi);\n  real mu_phi_sqrt = mu * phi_sqrt;\n  real m;\n  if (phi > 1) \n    m = mu / (1 - inv(phi_sqrt));\n  else \n    m = positive_infinity();\n  real lpmf = - mu_phi_sqrt;\n  real cdf = exp(lpmf);\n  real ln_inc;\n  while (cdf < p && q < m) {\n    q += 1;\n    ln_inc = (q - 1) * log(mu_phi_sqrt + q * (1 - phi_sqrt)) - (q - 2) * log(mu_phi_sqrt + (q - 1) * (1 - phi_sqrt)) + (phi_sqrt - 1) - log(q);\n    lpmf += ln_inc;    \n    cdf += exp(lpmf);\n  }\n  return q;\n}\nint gpo_rng(real mu, real phi) {\n  real p = uniform_rng(0,1);\n  int x = gpo_quantile(p, mu, phi);\n  return x;\n}\n\"\ngeneralized_Poisson <- custom_family(\n  \"gpo\", dpars = c(\"mu\",\"phi\"),\n  links = c(\"log\",\"log\"),\n  lb = c(0, 0), ub = c(NA, NA),\n  type = \"int\"\n)\n\ngeneralized_Poisson_stanvars <- stanvar(scode = stancode_gpo, block = \"functions\")\n\nphi_prior <- prior(exponential(1), class = \"phi\")\n\nGPO_fit <- \n  brm(\n    Y ~ X, family = generalized_Poisson,\n    prior = phi_prior,\n    stanvars = generalized_Poisson_stanvars,\n    data = dat, \n    warmup = 500, \n    iter = 2500, \n    chains = 4, \n    cores = 4,\n    seed = 20231204\n  )\n\nexpose_functions(GPO_fit, vectorize = TRUE)\n\nlog_lik_gpo <- function(i, prep) {\n  mu <- brms::get_dpar(prep, \"mu\", i = i)\n  phi <- brms::get_dpar(prep, \"phi\", i = i)\n  y <- prep$data$Y[i]\n  gpo_lpmf(y, mu, phi)\n}\n\nposterior_predict_gpo <- function(i, prep, maxval = NULL, ...) {\n  mu <- brms::get_dpar(prep, \"mu\", i = i)\n  phi <- brms::get_dpar(prep, \"phi\", i = i)\n  gpo_rng(mu, phi)\n}\n```\n:::\n\n\n## Model comparison\n\nHere is a comparison of LOOIC for all of the models:\n\n::: {.cell}\n\n```{.r .cell-code}\nloo_comparison <- loo(Poisson_fit, negbin_fit, DPO_fit, GPO_fit)\nloo_comparison$diffs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            elpd_diff se_diff\nDPO_fit        0.0       0.0 \nGPO_fit       -2.9       2.8 \nnegbin_fit    -8.9       4.4 \nPoisson_fit -120.8      20.1 \n```\n\n\n:::\n:::\n\n\nThe model based on the double-Poisson distribution fits equally well to the true data-generating process here, suggesting that there's really just not enough information to distriguish between the two models. The negative binomial distribution fit is substantially worse, and the Poisson distribution fit is awful.\n\nHere's the posterior for the dispersion (i.e., $1 / \\phi$) based on the GPO and DPO models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolor_scheme_set(\"green\")\nGPO_dispersion <- \n  mcmc_areas(GPO_fit, pars = \"phi\", transformations = \\(x) 1 / x) + \n  theme_minimal() + \n  ggtitle(\"Generalized Poisson\")\n\ncolor_scheme_set(\"brightblue\")\nDPO_dispersion <- \n  mcmc_areas(DPO_fit, pars = \"phi\", transformations = \\(x) 1 / x) + \n  theme_minimal() + \n  ggtitle(\"Double Poisson\")\n\nDPO_dispersion / GPO_dispersion & \n  xlim(1.5, 2.0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/dispersion-comparison-1.png){width=480}\n:::\n:::\n\n\nRight on par. To get a better sense of model fit, I'll run some posterior predictive checks, using the quasi-likelihood dispersion as a summary statistic:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nYrep_Poisson <- posterior_predict(Poisson_fit, ndraws = 500) \nYrep_negbin <- posterior_predict(negbin_fit, ndraws = 500)\nYrep_dpo <- posterior_predict(DPO_fit, ndraws = 500)\nYrep_gpo <- posterior_predict(GPO_fit, ndraws = 500)\n\ndispersion_coef <- function(y) {\n  quasi_fit <- glm(y ~ dat$X, family = quasipoisson(link = \"log\"))\n  sum(residuals(quasi_fit, type = \"pearson\")^2) / quasi_fit$df.residual\n}\n\ncolor_scheme_set(\"blue\")\nPoisson_disp <- ppc_stat(dat$Y, Yrep_Poisson, stat = dispersion_coef, binwidth = 0.02) + \n  labs(title = \"Poisson\")\n\ncolor_scheme_set(\"purple\")\nnegbin_disp <- ppc_stat(dat$Y, Yrep_negbin, stat = dispersion_coef, binwidth = 0.02) + \n  labs(title = \"Negative-binomial\")\n\ncolor_scheme_set(\"brightblue\")\ndpo_disp <- ppc_stat(dat$Y, Yrep_dpo, stat = dispersion_coef, binwidth = 0.02) + \n  labs(title = \"Double Poisson\")\n\ncolor_scheme_set(\"green\")\ngpo_disp <- ppc_stat(dat$Y, Yrep_gpo, stat = dispersion_coef, binwidth = 0.02) + \n  labs(title = \"Generalized Poisson\")\n\nPoisson_disp / negbin_disp / dpo_disp / gpo_disp &\n  theme_minimal() & \n  xlim(c(0.8, 2.1))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ppc-dispersion-1.png){width=768}\n:::\n:::\n\n\nBoth the double Poisson and the generalized Poisson models generate data with levels of dispersion similar to the observed data. The negative binomial distribution is not noticeably worse.\n\n## Marginal posterior predictive densities\n\nHere's some rootograms for the posterior predictive density of the raw outcomes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolor_scheme_set(\"blue\")\nPoisson_root <- ppc_rootogram(dat$Y, Yrep_Poisson, style = \"hanging\") + labs(title = \"Poisson\")\ncolor_scheme_set(\"purple\")\nnegbin_root <- ppc_rootogram(dat$Y, Yrep_negbin, style = \"hanging\") + labs(title = \"Negative-binomial\")\ncolor_scheme_set(\"brightblue\")\ndpo_root <- ppc_rootogram(dat$Y, Yrep_dpo, style = \"hanging\") + labs(title = \"Double Poisson\")\ncolor_scheme_set(\"green\")\ngpo_root <- ppc_rootogram(dat$Y, Yrep_gpo, style = \"hanging\") + labs(title = \"Generalized Poisson\")\n\nPoisson_root / negbin_root / dpo_root / gpo_root &\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ppd-1.png){width=672}\n:::\n:::\n\nYou can see from these that the Poisson model maybe expects slightly fewer low counts and slightly fewer high counts than are present in the observed data. However, the figure doesn't really capture the degree of mis-fit that is apparent with the dispersion summary statistics. I think this is because the distribution of $Y$ changes so much depending on the value of the predictor $X$. \n\n## Posterior predictive residual densities\n\nOne way to focus in on the distributional assumption is to examine the distribution of residuals rather than raw outcomes. I'll do that here by looking the deviance residuals from the quasi-Poisson GLM model, treating the calculation of the residuals as merely a transformation of the raw data. Here are some posterior predictive density plots of these deviance residuals:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# quasi-Poisson deviance residuals\ndat$resid <- residuals(quasi_fit)\n\n# function to calculate quasi-Poisson deviance residuals\nquasi_residuals <- function(y) as.numeric(residuals(glm(y ~ dat$X, family = quasipoisson(link = \"log\"))))\n\n# transform posterior predictive data into residuals\nR <- 50\nresid_Poisson <- apply(Yrep_Poisson[1:R,], 1, quasi_residuals) |> t()\nresid_negbin <- apply(Yrep_negbin[1:R,], 1, quasi_residuals) |> t()\nresid_dpo <- apply(Yrep_dpo[1:R,], 1, quasi_residuals) |> t()\nresid_gpo <- apply(Yrep_gpo[1:R,], 1, quasi_residuals) |> t()\n\n# make density plots\ncolor_scheme_set(\"blue\")\nPoisson_resid_density <- ppc_dens_overlay(dat$resid, resid_Poisson) + labs(title = \"Poisson\")\n\ncolor_scheme_set(\"purple\")\nnegbin_resid_density <- ppc_dens_overlay(dat$resid, resid_negbin) + labs(title = \"Negative-binomial\")\n\ncolor_scheme_set(\"brightblue\")\ndpo_resid_density <- ppc_dens_overlay(dat$resid, resid_dpo) + labs(title = \"Double Poisson\")\n\ncolor_scheme_set(\"green\")\ngpo_resid_density <- ppc_dens_overlay(dat$resid, resid_gpo) + labs(title = \"Generalized Poisson\")\n\nPoisson_resid_density / negbin_resid_density / dpo_resid_density / gpo_resid_density &\n  theme_minimal() & \n  xlim(c(-3.5, 3.5))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ppd-residuals-1.png){width=576}\n:::\n:::\n\n\nIt's quite a bit clearer from these plots that the DPO and GPO models are closer to replicating the distribution of the data than the Poisson model. \nThe negative binomial model is not obviously mis-specified either. \n\nA notable difference between the negative binomial versus the DPO and GPO distributions is in the form of the mean-variance relationship.\nFor the negative binomial, the variance increases with the square of the mean, whereas for the DPO and GPO, the variance increases in constant proportion to the mean.\nThe residual posterior density plots above don't really capture these mean-variance relationships in an obvious way.\nI took one more crack at a posterior predictive check to get at this. \nBelow is a figure showing the loess smooth of the squared residuals versus $X$ based on the posterior predictive distributions versus the real data. I couldn't find an easy way to do this with the `bayesplot` functions I've used above, so I had to bang it out in regular `ggplot`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nX_grid <- seq(min(dat$X), max(dat$X), length.out = 200)\n\nsmooth_square_resid <- function(r, x_dat, X_pred = X_grid) {\n  loess_fit <- loess(I(r^2) ~ x_dat)\n  predict(loess_fit, newdata = data.frame(x_dat = X_pred))\n}\n\ndat$sm <- smooth_square_resid(r = dat$resid, x_dat = dat$X, X_pred = dat$X)\n\nsmooth_square_resid_ppcs <- function(R, x_dat, X_pred = X_grid) {\n  smooth_list <- apply(R, 1, smooth_square_resid, x_dat = dat$X, X_pred = X_pred, simplify = FALSE)\n  tibble(\n    group = 1:length(smooth_list),\n    X = rep(list(X_pred), length(smooth_list)),\n    sm = smooth_list\n  )\n}\n\nsmooth_MV <- \n  list(\n    Poisson = resid_Poisson, \n    `Negative binomial` = resid_negbin,\n    `Double Poisson` = resid_dpo,\n    `Generalized Poisson` = resid_gpo\n  ) %>%\n  map_dfr(smooth_square_resid_ppcs, x_dat = dat$X, .id = \"distribution\") %>%\n  unnest(X, sm) %>%\n  mutate(\n    distribution = factor(distribution, levels = c(\"Poisson\", \"Negative binomial\",\"Double Poisson\", \"Generalized Poisson\"))\n  )\n\nggplot(smooth_MV, aes(X, sm, group = group, color = distribution)) + \n  geom_line(alpha = 0.4) + \n  geom_line(data = dat, aes(X, sm, group = NULL), color = \"black\", linewidth = 1.25) + \n  scale_color_manual(values = c(\"grey\",\"purple\",\"lightblue\",\"lightgreen\")) + \n  scale_y_continuous(limits = c(0, 9), breaks = seq(0,8,2), expand = expansion(0,0)) + \n  facet_wrap(~ distribution, ncol = 1) + \n  theme_minimal() + \n  theme(legend.position = \"none\") + \n  labs(y = \"Loess smooth of squared residuals\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ppd-residual-smooth-1.png){width=100%}\n:::\n:::\n\nAha! Here we can clearly see that the negative binomial model generates residuals that have more curvature to the mean-variance relationship, and so don't really fit with the observed data. The double Poisson and generalized Poisson both generate residuals that match the observed mean-variance relationship decently well. \n\n# Colophon\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.3.3 (2024-02-29 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22621)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] loo_2.7.0          bayesplot_1.11.1   brms_2.21.0        Rcpp_1.0.12       \n [5] rstan_2.32.6       StanHeaders_2.32.6 gamlss.dist_6.1-1  patchwork_1.2.0   \n [9] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[13] purrr_1.0.2        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[17] ggplot2_3.5.0      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1     farver_2.1.1         fastmap_1.1.1       \n [4] tensorA_0.36.2.1     digest_0.6.35        timechange_0.3.0    \n [7] lifecycle_1.0.4      magrittr_2.0.3       posterior_1.5.0     \n[10] compiler_4.3.3       rlang_1.1.3          tools_4.3.3         \n[13] utf8_1.2.4           yaml_2.3.8           knitr_1.45          \n[16] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n[19] pkgbuild_1.4.4       plyr_1.8.9           BH_1.84.0-0         \n[22] abind_1.4-5          withr_3.0.0          grid_4.3.3          \n[25] stats4_4.3.3         fansi_1.0.6          colorspace_2.1-0    \n[28] inline_0.3.19        scales_1.3.0         MASS_7.3-60.0.1     \n[31] ggridges_0.5.6       cli_3.6.2            mvtnorm_1.2-4       \n[34] rmarkdown_2.26       generics_0.1.3       RcppParallel_5.1.7  \n[37] rstudioapi_0.16.0    reshape2_1.4.4       tzdb_0.4.0          \n[40] splines_4.3.3        parallel_4.3.3       matrixStats_1.2.0   \n[43] vctrs_0.6.5          Matrix_1.6-5         jsonlite_1.8.8      \n[46] hms_1.1.3            glue_1.7.0           codetools_0.2-19    \n[49] distributional_0.4.0 stringi_1.8.3        gtable_0.3.4        \n[52] QuickJSR_1.1.3       munsell_0.5.1        pillar_1.9.0        \n[55] htmltools_0.5.7      Brobdingnag_1.2-9    R6_2.5.1            \n[58] RcppEigen_0.3.4.0.0  evaluate_0.23        lattice_0.22-5      \n[61] backports_1.4.1      renv_1.0.5           rstantools_2.4.0    \n[64] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-164        \n[67] checkmate_2.3.1      mgcv_1.9-1           xfun_0.42           \n[70] pkgconfig_2.0.3     \n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}