{
  "hash": "5c4eca6b444d3d7538bee7102fb9b1fa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Variance stabilization of Cohen's d\ndate: '2025-07-14'\ncategories:\n- effect-size\n- standardized-mean-difference\n- delta-method\nexecute:\n  echo: false\n  message: false\n  warning: false\ncode-tools: true\nbibliography: d-r-z-refs.bib\n---\n\n\nIn a recent _Psychological Methods_ paper, @Haaf2023does suggest conducting meta-analysis of standardized mean differences after transforming them to biserial correlations and then applying Fisher's $z$-transformation. \nThey argue that this leads to a variance-stabilized effect size, which has sampling variance that is constant across varying values of the true parameter $\\delta$. \n@Bartos2023robust cites @Haaf2023does as justification for conducting meta-analysis of standardized mean differences after applying this $d$-to-$r$-to-$z$ transformation.\nAll this surprised me a bit because I think it's usually a good idea to transform $d$ effect sizes into other metrics [cf. @Pustejovsky2014converting] and because the transformation itself was unfamiliar to me.\nIn other work [@Pustejovsky2018testing], I've used the variance-stabilizing transformation given in @Hedges1985statistical, which is not consistent with this approach. \nIs it _really_ variance stabilizing?\n\nThe first step in the transformation proposed by @Haaf2023does depends on the relative sample sizes of the two groups, which I will parameterize as $p = N_1 / (N_1 + N_2)$.\nLetting $a = 1 / [p(1 - p)]$, the transformation function is given by \n$$\nz(d) = \\frac{1}{2}\\left[\\log\\left(\\sqrt{d^2 + a} + d\\right) - \\log\\left(\\sqrt{d^2 + a} - d\\right)\\right]\n$$\n\nThe shape of the transformation is depicted in @fig-Haaf-transform.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![d-to-r-to-z transformation for various allocation fractions $p$. The dashed line is y = x / 2.](index_files/figure-html/fig-Haaf-transform-1.png){#fig-Haaf-transform width=768}\n:::\n:::\n\n\nThe variance-stabilizing transformation given in @Hedges1985statistical is \n$$\nh(d) = \\sqrt{2} \\left(\\frac{d}{|d|}\\right) \\left[\\log\\left(|d| + \\sqrt{d^2 + 2a}\\right) - \\frac{1}{2}\\log\\left(2a\\right)\\right]\n$$\n@fig-transformation-comparison compares the two transformation functions. They're very similar over the range [-2, 2] and only begin to diverge when $|d| > 3$, the realm of what would typically be considered implausibly large effect sizes.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of transformation functions given by Haaf and Rouder (2023) and by Hedges and Olkin (1985)](index_files/figure-html/fig-transformation-comparison-1.png){#fig-transformation-comparison width=768}\n:::\n:::\n\nThis suggests that any differences in the performance of the transformations will be driven by behavior in the extremes of the distribution and will likely be much less pronounced when $N_1$ and $N_2$ are large.\nI will run some quick simulations to \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![True standard errors of untransformed $(d)$ and transformed ($z(d)$ and $h(d)$) effect size estimates](index_files/figure-html/fig-true-SE-1.png){#fig-true-SE width=768}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![True standard errors of transformed ($z(d)$ and $h(d)$) effect size estimates](index_files/figure-html/fig-true-SE-zoom-1.png){#fig-true-SE-zoom width=768}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}