{
  "hash": "928e2f032583058c4d2f4bc765ba669d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Variance stabilization of Cohen's d\ndate: '2025-07-14'\ncategories:\n- effect-size\n- standardized-mean-difference\n- delta-method\nexecute:\n  echo: false\n  message: false\n  warning: false\ncode-tools: true\nbibliography: d-r-z-refs.bib\ndraft: true\n---\n\n\nIn a recent _Psychological Methods_ paper, @Haaf2023does suggest conducting meta-analysis of standardized mean differences after transforming them to point biserial correlations and then applying Fisher's $z$-transformation. \nThey argue that this leads to a variance-stabilized effect size, which has sampling variance that is constant across varying values of the true parameter $\\delta$. \n@Bartos2023robust cites @Haaf2023does as justification for conducting meta-analysis of standardized mean differences after applying this $d$-to-$r$-to-$z$ transformation.\nAll this surprised me a bit because the transformation was unfamiliar, although I've written about these sorts of effect size conversions before [cf. @Pustejovsky2014converting].\nIn other work [@Pustejovsky2018testing], I've used the variance-stabilizing transformation given in @Hedges1985statistical, which is different than this approach. \nWhat gives? Is this $d$-to-$r$-to-$z$ business _really_ variance stabilizing?\n\nThe first step in the transformation proposed by @Haaf2023does depends on the relative sample sizes of the two groups, which I will parameterize as $p = N_1 / (N_1 + N_2)$.\nLetting $a = 1 / [p(1 - p)]$, the transformation function is given by \n$$\nz(d) = \\frac{1}{2}\\left[\\log\\left(\\sqrt{d^2 + a} + d\\right) - \\log\\left(\\sqrt{d^2 + a} - d\\right)\\right]\n$$\n\nThe shape of the transformation is depicted in @fig-Haaf-transform.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![d-to-r-to-z transformation for various allocation fractions $p$. The dashed line is y = x / 2.](index_files/figure-html/fig-Haaf-transform-1.png){#fig-Haaf-transform width=768}\n:::\n:::\n\n\nThe variance-stabilizing transformation given in @Hedges1985statistical is \n$$\nh(d) = \\sqrt{2} \\left(\\frac{d}{|d|}\\right) \\left[\\log\\left(|d| + \\sqrt{d^2 + 2a}\\right) - \\frac{1}{2}\\log\\left(2a\\right)\\right]\n$$\n\n@fig-transformation-comparison compares the two transformation functions. They're very similar over the range [-2, 2] and only begin to diverge when $|d| > 3$, the realm of what would typically be considered implausibly large effect sizes.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of transformation functions given by Haaf and Rouder (2023) and by Hedges and Olkin (1985)](index_files/figure-html/fig-transformation-comparison-1.png){#fig-transformation-comparison width=768}\n:::\n:::\n\nThis suggests that any differences in the performance of the transformations will be driven by behavior in the extremes of the distribution and will likely be less pronounced when $N_1$ and $N_2$ are large.\nI ran some quick simulations to look at how the variance of $d$, $z(d)$, and $h(d)$ change as a function of the true average effect size $\\delta$.\n\n\n\n::: {.cell}\n\n:::\n\n\n@fig-true-SE-fixed\n\n\n::: {.cell}\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates, rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-fixed-1.png){#fig-true-SE-fixed width=768}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}