{
  "hash": "824c6d2588fa8805266dbaf3021e4f22",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Variance stabilization of Cohen's d\ndate: '2025-07-14'\ncategories:\n- effect-size\n- standardized-mean-difference\n- delta-method\nexecute:\n  code-fold: true\n  message: false\n  warning: false\ncode-tools: true\nbibliography: d-r-z-refs.bib\ndraft: true\n---\n\nIn a recent _Psychological Methods_ paper, @Haaf2023does suggest conducting meta-analysis of standardized mean differences after transforming them to point biserial correlations and then applying Fisher's $z$-transformation. \nThey argue that this leads to a variance-stabilized effect size, which has sampling variance that is constant across varying values of the true parameter $\\delta$. \n@Bartos2023robust cites @Haaf2023does as justification for conducting meta-analysis of standardized mean differences after applying this $d$-to-$r$-to-$z$ transformation.\nAll this surprised me a bit because the transformation was unfamiliar, although I've written about these sorts of effect size conversions before [cf. @Pustejovsky2014converting].\nIn other work [@Pustejovsky2018testing], I've used the variance-stabilizing transformation given in @Hedges1985statistical, which is different than this approach. \nWhat gives? Is this $d$-to-$r$-to-$z$ business _really_ variance stabilizing?\n\nThe first step in the transformation proposed by @Haaf2023does depends on the relative sample sizes of the two groups, which I will parameterize as $R = N_1 : N_2$.\nLetting $a = (R + 1)^2 / R$, the transformation function is given by \n$$\nz(d; a) = \\frac{1}{2}\\left[\\log\\left(\\sqrt{d^2 + a} + d\\right) - \\log\\left(\\sqrt{d^2 + a} - d\\right)\\right]\n$$\n\nThe shape of the transformation is depicted in @fig-Haaf-transform.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nd_to_z <- function(d, R) {\n  r <- d / sqrt(d^2 + (R + 1)^2 / R)\n  atanh(r)\n}\n\nd_to_h <- function(d, R) {\n  a <- (R + 1)^2 / R\n  sqrt(2) * sign(d) * (log(abs(d) + sqrt(d^2 + 2 * a)) - log(2 * a) / 2)\n}\n\ntransform_dat <- \n  expand_grid(\n    d = seq(-5,5,0.02),\n    R = 1:3\n  ) |>\n  mutate(\n    z = d_to_z(d, R),\n    h = d_to_h(d, R),\n    R_fac = factor(paste(R,\"1\", sep = \":\")) |> fct_rev()\n  )\n\nggplot(transform_dat) +\n  aes(d, z, color = R_fac) + \n  geom_abline(slope = 1 / 2, intercept = 0, linetype = \"dashed\") + \n  geom_line() + \n  theme_minimal() + \n  labs(color = \"R\") + \n  scale_x_continuous(breaks = seq(-5,5,1), minor_breaks = NULL)\n```\n\n::: {.cell-output-display}\n![d-to-r-to-z transformation for various allocation fractions $p$. The dashed line is y = x / 2.](index_files/figure-html/fig-Haaf-transform-1.png){#fig-Haaf-transform width=768}\n:::\n:::\n\n\nThe variance-stabilizing transformation given in @Hedges1985statistical is \n$$\nh(d; a) = \\sqrt{2} \\left(\\frac{d}{|d|}\\right) \\left[\\log\\left(|d| + \\sqrt{d^2 + 2a}\\right) - \\frac{1}{2}\\log\\left(2a\\right)\\right]\n$$\n\n@fig-transformation-comparison compares the two transformation functions, with $h(z)$ in red and $z(d)$ in blue. The functions are very similar over the range [-2, 2] and only begin to diverge when $|d| > 3$, the realm of what would typically be considered implausibly large effect sizes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransform_dat |>\n  mutate(R_fac = fct_rev(R_fac) |> fct_relabel(\\(x) paste(\"R ==\", x))) |>\n  pivot_longer(cols = c(z, h), names_to = \"stat\", values_to = \"val\") |>\n  ggplot() + \n  aes(d, val, color = stat) + \n  geom_line() + \n  facet_wrap(~ R_fac, labeller = \"label_parsed\") + \n  theme_minimal() + \n  theme(legend.position = c(0.05, 0.9)) + \n  scale_x_continuous(breaks = seq(-4,4,2)) + \n  labs(y = \"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![Comparison of transformation functions given by Haaf and Rouder (2023) and by Hedges and Olkin (1985)](index_files/figure-html/fig-transformation-comparison-1.png){#fig-transformation-comparison width=768}\n:::\n:::\n\nThis suggests that any differences in the performance of the transformations will be driven by behavior in the extremes of the distribution and will likely be less pronounced when $N_1$ and $N_2$ are large.\nI ran some quick simulations to look at how the variance of $d$, $z(d)$, and $h(d)$ change as a function of the true average effect size $\\delta$.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(simhelpers)\nlibrary(future)\nplan(multisession)\n\nr_smd <- function(reps, delta = 0, N = 20, R = 1) {\n  a <- sqrt(N * R / (R + 1)^2)\n  ncp <- delta * a\n  tstats <- rt(reps, df = N - 2, ncp = ncp)\n  d <- tstats / a\n  z <- d_to_z(d, R = R)\n  h <- d_to_h(d, R = R)\n  data.frame(d = d, z = z, h = h)\n}\n\ncalc_M_SE <- function(dat) {\n  M <- colMeans(dat, na.rm = TRUE)\n  SE <- apply(dat, 2, sd, na.rm = TRUE)\n  data.frame(stat = names(dat), M = M, SE = SE)\n}\n\nsim_d_twosample <- compose(calc_M_SE, r_smd)\n\nsim_grid <-\n  expand_grid(\n    N = c(10, 30, 50),\n    R = 1:3,\n    delta = seq(0, 3, 0.1)\n  ) |>\n  mutate(\n    reps = 2e4\n  )\n\nd_twosample_res <- \n  sim_grid |>\n  evaluate_by_row(\n    sim_d_twosample, \n    system_time = FALSE,\n    verbose = FALSE\n  ) |>\n  mutate(\n    R_fac = factor(R) |> fct_relabel(\\(x) paste0(\"R == \", x, \":1\")),\n    N_fac = factor(N) |> fct_relabel(\\(x) paste(\"N ==\", x)),\n    SE_scaled = if_else(stat == \"d\", SE * sqrt((N - 2) * R / (R + 1)^2), sqrt(N - 2) * SE)\n  )\n```\n:::\n\n\n@fig-true-SE-twosample\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d_twosample_res) + \n  aes(delta, SE_scaled, color = stat) + \n  geom_hline(yintercept = 0) + \n  geom_line() + \n  facet_grid(N_fac ~ R_fac, scales = \"free_y\", labeller = \"label_parsed\") + \n  theme_minimal() +\n  labs(\n    x = expression(delta), \n    y = \"True Standard Error (rescaled)\", \n    color = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates under a two-sample homoskedastic normal model. Standard errors are rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-twosample-1.png){#fig-true-SE-twosample width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_bivariate <- function(\n  reps, delta = 0, N = 20, R = 1, fixed = TRUE\n) {\n  require(mvtnorm)\n  rho <- delta / sqrt(delta^2 + (R + 1)^2 / R)\n  Sigma <- rho + diag(1 - rho, nrow = 2L)\n  d <- replicate(reps, {\n    Z <- rmvnorm(n = N, mean = c(0,0), sigma = Sigma)\n    \n    if (fixed) {\n      X <- ifelse(Z[,1] <= qnorm(R / (R + 1)), \"A\",\"B\")\n      Xtb <- table(X)\n      if (any(Xtb == 0)) return(NA_real_)\n    } else {\n      X <- ifelse(rank(Z[,1]) <= N * R / (R + 1), \"A\",\"B\")\n      Xtb <- table(X)\n      R <- Xtb[1] / Xtb[2]\n    }\n    \n    M <- tapply(Z[,2], X, mean)\n    V <- tapply(Z[,2], X, var)\n    Vpool <- sum((Xtb - 1) * V) / (N - 2)\n    as.numeric(diff(M)) / sqrt(Vpool)\n  }, simplify = FALSE) |>\n    unlist()\n  z <- d_to_z(d, R = R)\n  h <- d_to_h(d, R = R)\n  data.frame(d = d, z = z, h = h)\n}\n\nsim_bivariate <- compose(calc_M_SE, r_bivariate)\n\nd_bivariate <- \n  sim_grid |>\n  mutate(reps = 2e2) |> \n  cross_join(tibble(fixed = c(TRUE, FALSE))) |> \n  evaluate_by_row(\n    sim_bivariate,\n    system_time = FALSE,\n    verbose = FALSE\n  ) |>\n  mutate(\n    R_fac = factor(R) |> fct_relabel(\\(x) paste0(\"R == \", x, \":1\")),\n    N_fac = factor(N) |> fct_relabel(\\(x) paste(\"N ==\", x)),\n    SE_scaled = if_else(stat == \"d\", SE * sqrt((N - 2) * R / (R + 1)^2), sqrt(N - 2) * SE)\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_bivariate |>\n  filter(fixed) |>\nggplot() + \n  aes(delta, SE_scaled, color = stat) + \n  geom_hline(yintercept = 0) + \n  geom_line() + \n  facet_grid(N_fac ~ R_fac, scales = \"free_y\", labeller = \"label_parsed\") + \n  theme_minimal() +\n  labs(\n    x = expression(delta), \n    y = \"True Standard Error (rescaled)\", \n    color = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates under a dichotomized bivariate normal model with a fixed threshold. Standard errors are rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-bivariate-fixed-1.png){#fig-true-SE-bivariate-fixed width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_bivariate |>\n  filter(!fixed) |>\nggplot() + \n  aes(delta, SE_scaled, color = stat) + \n  geom_hline(yintercept = 0) + \n  geom_line() + \n  facet_grid(N_fac ~ R_fac, scales = \"free_y\", labeller = \"label_parsed\") + \n  theme_minimal() +\n  labs(\n    x = expression(delta), \n    y = \"True Standard Error (rescaled)\", \n    color = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates under a dichotomized bivariate normal model with a sample threshold. Standard errors are rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-bivariate-sampled-1.png){#fig-true-SE-bivariate-sampled width=768}\n:::\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}