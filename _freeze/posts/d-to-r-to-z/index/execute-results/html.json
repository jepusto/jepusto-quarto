{
  "hash": "8147e4ed1bb7ff8a747c599ef2fa428d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Variance stabilization of Cohen's d\ndate: '2025-07-23'\ncategories:\n- effect-size\n- standardized-mean-difference\n- delta-method\ncode-fold: true\ncode-tools: true\ntoc: true\nbibliography: d-r-z-refs.bib\ncsl: \"../apa.csl\"\n---\n\nIn a recent _Psychological Methods_ paper, @Haaf2023does suggest conducting meta-analysis of standardized mean differences after transforming them to point biserial correlations and then applying Fisher's $z$-transformation. \nThey argue that this leads to a variance-stabilized effect size estimator, which has sampling variance that is constant across varying values of the true parameter $\\delta$. \n@Bartos2023robust cites @Haaf2023does as justification for conducting meta-analysis of standardized mean differences after applying this $d$-to-$r$-to-$z$ transformation.\nAll this surprised me a bit because the transformation was unfamiliar, although I've written about these sorts of effect size conversions before [cf. @Pustejovsky2014converting].\nIn other work [@Pustejovsky2018testing], I've used the variance-stabilizing transformation given in @Hedges1985statistical, which is different than this approach. \nWhat gives? Is this $d$-to-$r$-to-$z$ business _really_ variance stabilizing?\n\n## $z(d)$\nThe first step in the transformation proposed by @Haaf2023does depends on the relative sample sizes of the two groups, which I will parameterize as $R = N_1 : N_2$.\nLetting $a = (R + 1)^2 / R$, the transformation function is given by \n$$\nz(d; a) = \\frac{1}{2}\\left[\\log\\left(\\sqrt{d^2 + a} + d\\right) - \\log\\left(\\sqrt{d^2 + a} - d\\right)\\right]\n$$\n\nThe shape of the transformation is depicted in @fig-Haaf-transform.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nd_to_z <- function(d, R) {\n  r <- d / sqrt(d^2 + (R + 1)^2 / R)\n  atanh(r)\n}\n\nd_to_h <- function(d, R) {\n  a <- (R + 1)^2 / R\n  sqrt(2) * sign(d) * (log(abs(d) + sqrt(d^2 + 2 * a)) - log(2 * a) / 2)\n}\n\ntransform_dat <- \n  expand_grid(\n    d = seq(-5,5,0.02),\n    R = 1:3\n  ) |>\n  mutate(\n    a = (R + 1)^2 / R,\n    z = d_to_z(d, R),\n    h = d_to_h(d, R),\n    R_fac = factor(paste(R,\"1\", sep = \":\"))\n  )\n\nggplot(transform_dat) +\n  aes(d, z, color = R_fac) + \n  geom_abline(slope = 1 / 2, intercept = 0, linetype = \"dashed\") + \n  geom_line() + \n  theme_minimal() + \n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.2)) + \n  labs(color = \"R\") + \n  scale_x_continuous(breaks = seq(-5,5,1), minor_breaks = NULL)\n```\n\n::: {.cell-output-display}\n![d-to-r-to-z transformation for various allocation fractions $p$. The dashed line is y = x / 2.](index_files/figure-html/fig-Haaf-transform-1.png){#fig-Haaf-transform width=768}\n:::\n:::\n\nOne way to check whether this transformation is variance-stabilizing is by finding the [delta-method approximation](/posts/Multivariate-delta-method/) to its variance.\nI find the first derivative of $z(d)$ to be\n$$\nz'(d; a) = \\frac{1}{\\sqrt{d^2 + a}},\n$$\nand so\n$$\n\\begin{aligned}\n\\text{Var}(z(d)) &\\approx \\left( z'(\\delta; a) \\right)^2 \\times \\text{Var}(d) \\\\\n&= \\frac{1}{\\delta^2 + a} \\times \\frac{1}{N} \\left(a + \\frac{\\delta^2}{2}\\right) \\\\\n&= \\frac{1}{N} \\left(\\frac{a + \\frac{1}{2}\\delta^2}{a + \\delta^2}\\right).\n\\end{aligned}\n$$\nThis looks like the following:\n\n::: {.cell}\n\n```{.r .cell-code}\ntransform_dat %>%\n  mutate(\n    Vz = (a + d^2 / 2) / (a + d^2)\n  ) %>%\nggplot() +\n  aes(d, Vz, color = R_fac) + \n  geom_hline(yintercept = 1) + \n  geom_line() + \n  theme_minimal() + \n  theme(legend.position = \"inside\", legend.position.inside = c(0.9, 0.8)) + \n  labs(x = expression(delta), y = expression(N %*% Var(z)), color = \"R\") + \n  scale_x_continuous(breaks = seq(-5,5,1), minor_breaks = NULL)\n```\n\n::: {.cell-output-display}\n![Delta method approximation for the variance of $z(d)$.](index_files/figure-html/fig-Var-z-1.png){#fig-Var-z width=768}\n:::\n:::\n\nBased on this approximation, $\\text{Var}(z(d))$ is not independent of $\\delta$ and is instead _decreasing_ in the magnitude of the true effect size.\n\n## $h(z)$\n\nThe variance-stabilizing transformation given in @Hedges1985statistical [see also @Pustejovsky2018testing] is \n$$\nh(d; a) = \\sqrt{2} \\times \\text{sgn}(d) \\times \\text{sinh}^{-1}\\left(\\frac{|d|}{\\sqrt{2a}}\\right) = \\sqrt{2} \\left(\\frac{d}{|d|}\\right) \\left[\\log\\left(|d| + \\sqrt{d^2 + 2a}\\right) - \\frac{1}{2}\\log\\left(2a\\right)\\right].\n$$\nThis transformation has derivative\n$$\nh'(d; a) = \\frac{2}{\\sqrt{d^2 + 2a}},\n$$\nand so\n$$\n\\text{Var}(h(d)) \\approx \\left( h'(\\delta; a) \\right)^2 \\times \\text{Var}(d) = \\frac{2}{\\delta^2 + 2a} \\times \\frac{1}{N} \\left(a + \\frac{\\delta^2}{2}\\right) = \\frac{1}{N}.\n$$\n\n\n@fig-transformation-comparison compares the two transformation functions, with $h(z)$ in red and $z(d)$ in blue. The functions are very similar over the range [-2, 2] and only begin to diverge when $|d| > 3$, the realm of what would typically be considered _very_ large effect sizes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransform_dat |>\n  mutate(R_fac = fct_rev(R_fac) |> fct_relabel(\\(x) paste(\"R ==\", x))) |>\n  pivot_longer(cols = c(z, h), names_to = \"stat\", values_to = \"val\") |>\n  ggplot() + \n  aes(d, val, color = stat) + \n  geom_line() + \n  facet_wrap(~ R_fac, labeller = \"label_parsed\") + \n  theme_minimal() + \n  theme(legend.position = \"inside\", legend.position.inside = c(0.05, 0.9)) + \n  scale_x_continuous(breaks = seq(-4,4,2)) + \n  labs(y = \"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![Comparison of transformation functions given by Haaf and Rouder (2023) and by Hedges and Olkin (1985)](index_files/figure-html/fig-transformation-comparison-1.png){#fig-transformation-comparison width=768}\n:::\n:::\n\n\nThis suggests that any differences in the performance of the transformations will be driven by behavior in the extremes of the distribution and will thus be less pronounced when $N_1$ and $N_2$ are large.\n\n# Two-sample simulations\n\nI ran some quick simulations to look at how the sampling variance of $d$, $z(d)$, and $h(d)$ change as a function of the true average effect size $\\delta$. \nThese simulations are based on a data-generating process that is consistent with the stated assumptions of @Haaf2023does, in which two independent samples are drawn from normally distributed populations with a standardized mean difference of $\\delta$, with total sample size $N$ and allocation ratio of $R = N_1:N_2$.\nA variance-stabilizing transformation should produce an estimator with true standard error (i.e., square root of the sampling variance) that is constant, not depending on $\\delta$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(simhelpers)\nlibrary(future)\nplan(multisession)\n\n# Generate standardized mean differences d, z(d), h(d)\n\nr_smd <- function(reps, delta = 0, N = 20, R = 1) {\n  a <- sqrt(N * R / (R + 1)^2)\n  ncp <- delta * a\n  tstats <- rt(reps, df = N - 2, ncp = ncp)\n  d <- tstats / a\n  z <- d_to_z(d, R = R)\n  h <- d_to_h(d, R = R)\n  data.frame(d = d, z = z, h = h)\n}\n\n# Summarize mean and variance\ncalc_M_SE <- function(dat) {\n  M <- colMeans(dat, na.rm = TRUE)\n  SE <- apply(dat, 2, sd, na.rm = TRUE)\n  data.frame(stat = names(dat), M = M, SE = SE)\n}\n\n# Simulation driver\nsim_d_twosample <- compose(calc_M_SE, r_smd)\n\n# Parameter grid\nsim_grid <-\n  expand_grid(\n    N = c(10, 30, 50),\n    R = 1:3,\n    delta = seq(0, 3, 0.1)\n  ) |>\n  mutate(\n    reps = 2e4\n  )\n\n# Execute simulations\nd_twosample_res <- \n  sim_grid |>\n  evaluate_by_row(\n    sim_d_twosample, \n    system_time = FALSE,\n    verbose = FALSE\n  ) |>\n  mutate(\n    R_fac = factor(R) |> fct_relabel(\\(x) paste0(\"R == \", x, \":1\")),\n    N_fac = factor(N) |> fct_relabel(\\(x) paste(\"N ==\", x)),\n    SE_scaled = if_else(stat == \"d\", SE * sqrt((N - 2) * R / (R + 1)^2), sqrt(N - 2) * SE)\n  )\n```\n:::\n\n\n\n@fig-true-SE-twosample shows the relationship between the parameter $\\delta$ and the true standard error of the standardized mean difference estimator $d$, along with the true standard errors of the transformed effect size estimators $z(d)$ and $h(d)$. \nTo facilitate comparison between the raw and transformed estimators, I have re-scaled the standard errors according to their values when $\\delta = 0$ (multiplying by $\\sqrt{(N - 2) R / (R + 1)^2}$ for $d$ and by $\\sqrt{N - 2}$ for $z(d)$ and $h(d)$).\n\n\n::: {.cell .column-body-outset lightbox='true'}\n\n```{.r .cell-code}\nggplot(d_twosample_res) + \n  aes(delta, SE_scaled, color = stat) + \n  geom_hline(yintercept = 0) + \n  geom_line() + \n  facet_grid(N_fac ~ R_fac, scales = \"free_y\", labeller = \"label_parsed\") + \n  theme_minimal() +\n  labs(\n    x = expression(delta), \n    y = \"True Standard Error (rescaled)\", \n    color = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates under a two-sample homoskedastic normal model. Standard errors are rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-twosample-1.png){#fig-true-SE-twosample width=100%}\n:::\n:::\n\n\nConsistent with the delta method approximation, it is evident that the sampling variance of $z(d)$ is not constant, but rather is _decreasing_ in $\\delta$.\nFor instance, when $R = 1:1$ and $N = 50$, the true SE of $z(d)$ decreases to 87% of its null value as $\\delta$ increases to 2. \nThis pattern is the opposite of what we see for the raw effect size $d$, which has standard error that increases to 125% of its null value under the same conditions.\nBetween these two, the transformed $h(d)$ effect sizes have stable SEs across the range of $\\delta$.\nThus, $h(d)$ is variance stabilizing but $z(d)$ is not.\n\n# Dichotomized bivariate normal simulations\n\nIn @Pustejovsky2014converting, I argued that the appropriateness of $d$-to-$r$-to-$z$ transformations and the specific form of transformation to use both depend on features of the study's design. \nThe two-sample normal model would be relevant for experimental studies, and it seems that the $z(d)$ transformation is not variance-stabilizing there.\nBut perhaps it would work for other study designs and data-generating processes?\nIn @Pustejovsky2014converting, I also looked at extreme groups designs and \"dichotomization\" designs, where a researcher is interested in the correlation between two continuous variables, one of which has been dichotomized based on some quantile of its distribution. \nJust out of curiosity, I will check whether the $r$-to-$z$ transformation works for a dichotomization design.\n\nThere are several ways to simulate a dichotomization design, which vary depending on a) whether you use a threshold defined by a population quantile or a sample quantile and b) whether, with the population quantile approach, you hold the per-group sample sizes fixed or only the total sample size (both are naturally fixed when defining the threshold based on a sample quantile).\nI will simulate using either population and sample quantiles, in each case while holding the total sample size fixed.^[Interested readers could modify the code to handle the further case, with population quantile thresholds and sample sizes fixed per-group, by generating observations from skew-normal distributions for each group. See @Azzalini2005skewnormal and the `rsn()` function from the `{sn}` package.]\nThis creates a complication with small sample sizes because it's possible to generate data where all of the observations fall above or below the threshold, so the standardized mean difference is undefined. \nI will handle this by just excluding such cases (i.e., conditioning on $N_1 > 0$ and $N_2 > 0$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate standardized mean differences d, z(d), h(d)\n\nr_bivariate <- function(\n  reps, delta = 0, N = 20, R = 1, threshold = \"population\"\n) {\n  require(mvtnorm)\n  rho <- delta / sqrt(delta^2 + (R + 1)^2 / R)\n  Sigma <- rho + diag(1 - rho, nrow = 2L)\n  d <- replicate(reps, {\n    Z <- rmvnorm(n = N, mean = c(0,0), sigma = Sigma)\n    \n    if (threshold == \"population\") {\n      X <- ifelse(Z[,1] <= qnorm(R / (R + 1)), \"A\",\"B\")\n      Xtb <- table(X)\n      if (any(Xtb == 0)) return(NA_real_)\n    } else {\n      X <- ifelse(rank(Z[,1]) <= N * R / (R + 1), \"A\",\"B\")\n      Xtb <- table(X)\n      R <- Xtb[1] / Xtb[2]\n    }\n    \n    M <- tapply(Z[,2], X, mean)\n    V <- tapply(Z[,2], X, var)\n    Vpool <- sum((Xtb - 1) * V) / (N - 2)\n    as.numeric(diff(M)) / sqrt(Vpool)\n  }, simplify = FALSE) |>\n    unlist()\n  z <- d_to_z(d, R = R)\n  h <- d_to_h(d, R = R)\n  data.frame(d = d, z = z, h = h)\n}\n\n# Simulation driver\nsim_bivariate <- compose(calc_M_SE, r_bivariate)\n\n# Execute simulations\nd_bivariate <- \n  sim_grid |>\n  cross_join(tibble(threshold = c(\"population\",\"sample\"))) |> \n  evaluate_by_row(\n    sim_bivariate,\n    system_time = FALSE,\n    verbose = FALSE\n  ) |>\n  mutate(\n    R_fac = factor(R) |> fct_relabel(\\(x) paste0(\"R == \", x, \":1\")),\n    N_fac = factor(N) |> fct_relabel(\\(x) paste(\"N ==\", x)),\n    SE_scaled = if_else(stat == \"d\", SE * sqrt((N - 2) * R / (R + 1)^2), sqrt(N - 2) * SE)\n  )\n```\n:::\n\n\nThe figures below show the true standard errors of $d$, $z(d)$, and $h(d)$ as a function of the standardized mean difference parameter $\\delta$. \nThey are constructed using the same layout as @fig-true-SE-twosample (click on the tab for \"population\" or \"sample\" to see the results for your preferred form of dichotomization).\nIs $d$-to-$r$-to-$z$ variance stabilizing for the dichotomization design? In short, nope. Applying it here leads to an even stronger mean-variance relation than in the two-sample data-generating process, where larger means produce effect sizes with smaller sampling variation.\nBut the $h(d)$ transformation does not really work either.\nIt too exhibits a negative relation between true SE and $\\delta$, though less pronounced than that of $z(d)$.\nThe untransformed effect size $d$ still shows a positive relation between true SE and $\\delta$ under some conditions, but it is weaker than under the two-sample data-generating process.\nFor all three effect sizes, the strength of the relation changes depending on sample size---something that was not evident in the two-sample data-generating process.\n\n::: {.panel-tabset}\n\n## Population\n\n\n::: {.cell .column-body-outset lightbox='true'}\n\n```{.r .cell-code}\nd_bivariate |>\n  filter(threshold == \"population\") |>\nggplot() + \n  aes(delta, SE_scaled, color = stat) + \n  geom_hline(yintercept = 0) + \n  geom_hline(yintercept = 1, color = \"grey\") + \n  geom_line() + \n  facet_grid(N_fac ~ R_fac, scales = \"free_y\", labeller = \"label_parsed\") + \n  theme_minimal() +\n  labs(\n    x = expression(delta), \n    y = \"True Standard Error (rescaled)\", \n    color = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates under a dichotomized bivariate normal model with a population quantile threshold. Standard errors are rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-bivariate-population-1.png){#fig-true-SE-bivariate-population width=100%}\n:::\n:::\n\n\n## Sample\n\n\n::: {.cell .column-body-outset lightbox='true'}\n\n```{.r .cell-code}\nd_bivariate |>\n  filter(threshold == \"sample\") |>\nggplot() + \n  aes(delta, SE_scaled, color = stat) + \n  geom_hline(yintercept = 0) + \n  geom_hline(yintercept = 1, color = \"grey\") + \n  geom_line() + \n  facet_grid(N_fac ~ R_fac, scales = \"free_y\", labeller = \"label_parsed\") + \n  theme_minimal() +\n  labs(\n    x = expression(delta), \n    y = \"True Standard Error (rescaled)\", \n    color = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![True standard errors of untransformed $d$ and transformed ($z(d)$ and $h(d)$) effect size estimates under a dichotomized bivariate normal model with a sample quantile threshold. Standard errors are rescaled so that SE = 1 when $\\delta$ = 0.](index_files/figure-html/fig-true-SE-bivariate-sampled-1.png){#fig-true-SE-bivariate-sampled width=100%}\n:::\n:::\n\n\n:::\n\n# Observations\n\nIn neither data-generating processes does the $d$-to-$r$-to-$z$ transformation lead to variance stabilization.\nFor effect sizes that are any less than very large, the transformations appear to be quite close to linear.\nHere is a zoomed-in view of both transformations:\n\n::: {.cell}\n\n```{.r .cell-code}\ntransform_dat |>\n  mutate(R_fac = fct_rev(R_fac) |> fct_relabel(\\(x) paste(\"R ==\", x))) |>\n  pivot_longer(cols = c(z, h), names_to = \"stat\", values_to = \"val\") |>\n  filter(abs(d) < 1.5) |>\n  ggplot() + \n  aes(d, val, color = stat) + \n  geom_line() + \n  facet_wrap(~ R_fac, labeller = \"label_parsed\") + \n  theme_minimal() + \n  theme(legend.position = \"inside\", legend.position.inside = c(0.05, 0.9)) + \n  scale_x_continuous(breaks = -1:1) + \n  scale_y_continuous(breaks = -seq(-0.5,0.5,0.5)) + \n  labs(y = \"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![Comparison of transformation functions given by Haaf and Rouder (2023) and by Hedges and Olkin (1985), over the range [-1.5, 1.5].](index_files/figure-html/fig-transformation-comparison-zoom-1.png){#fig-transformation-comparison-zoom width=768}\n:::\n:::\n\nIt would seem that applying _either_ transformation will often be inconsequential for one's conclusions except in meta-analyses with quite large effect size estimates.\nIn meta-analyses where the transformation is consequential, its performance seems to be contingent on the assumed data-generating process, yet meta-analysts rarely have sufficient information to assess distributional assumptions about the individual-level outcomes in primary studies.\n\nA further difficulty with both of the transformations is that they depend on the allocation ratio $R$.\nIn some meta-analyses of experimental studies, it may be that most or all primary studies have equally sized groups.\nBut this will not always be the case. \nIn meta-analyses where primary studies have varied sample sizes, one is then faced with the question of how to apply the transformation: should you use the correct variance-stabilizing transformation for each effect size, which then puts each primary study _on a different metric_, or should you use a common transformation (i.e., the same value of $a$) and then accept that the transformation will not stabilize all of the effects?\nPersonally, I would opt for neither.\n\nIn my view, using a variance-stabilizing transformation of $d$ from an experimental study seems like extra work and more hassle than it's worth.\nIt adds an additional layer of technical complication to a meta-analysis, and the potential gains (in terms of variance-stabilization) are contingent on assumptions that one is rarely in position to adequately assess.\nBetter to work with untransformed effect sizes, acknowledging the extent of the approximations involved and, when necessary, finding other ways to deal with the mean-variance relation of standardized mean differences.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}