{
  "hash": "650338e5a75d9f5bcd5cdf68e2165005",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bootstrap confidence interval variations\ndate: '2025-01-11'\ncategories:\n- programming\n- Rstats\n- bootstrap\ncode-fold: show\ncode-tools: true\ntoc: true\nbibliography: \"references.bib\"\ncsl: \"../apa.csl\"\n---\n\n\nI recently added some new utilities for calculating bootstrap confidence intervals to the [`simhelpers` package](https://meghapsimatrix.github.io/simhelpers/). \nThe functions are designed to make it a bit more convenient to implement Monte Carlo simulations of bootstrap CIs, including when using an extrapolation technique suggested by @boos2000MonteCarloEvaluation, which [I wrote about a while ago](/posts/Simulating-bootstrap-CIs/). \nWith the latest update, the package now provides options for a bunch of different variants of bootstrap CIs, including:\n\n* the normal CI, which uses bootstrapping to estimate a standard error and then takes plus or minus a normal critical value times the SE;\n* the studentized CI, which uses the bootstrap distribution of a t-statistic rather than the point estimator;\n* the percentile CI, which takes percentiles of the bootstrap distribution as the end-points of the CI;\n* the so-called \"basic\" CI, which is similar to the percentile CI but pivots the bootstrap distribution around the point estimator;\n* a bias-corrected version of the percentile CI;\n* Efron's [-@efron1987better] bias-corrected-and-accelerated CI, which provides more accurate coverage levels than alternative CIs for some classes of estimators. \n\nThese CI variants are also implemented in other packages. \nMost notably, all of them are implemented in [`boot`](https://cran.r-project.org/package=boot) [@bootpkg], the venerable R package companion to the @Davison1997bootstrap book on bootstrapping.\nAlthough very full-featured and widely used, the `boot` package does not offer a super-friendly user experience. \nIts output is a unwieldy, there are several quirks to its naming conventions, and its function for confidence interval calculations require the user to implement the bootstrap resampling calculations through `boot::boot()`, which is sometimes a bit awkward.\nNewer packages that provide some of the methods include [`infer`](https://infer.netlify.app/) [@Couch2021infer] and [`rsample`](https://rsample.tidymodels.org/) [@rsamplepkg].\nBoth of these offer pipe-friendly workflows, but neither provides the full slate of CI variants. \nAs with `boot`, these packages also lock in the user to the package's resampling tools. \nAnd none of the packages support a workflow for the @boos2000MonteCarloEvaluation extrapolation technique. \n\nIn this post, I'll demonstrate these different CI variants with an example, compare the results to implementations in other packages, and then show how the `simhelpers` implementation can be used for the  @boos2000MonteCarloEvaluation extrapolation technique.\n\n# Bootstrap confidence intervals for a mean\n\nLet me demonstrate the confidence intervals using a simple example of estimating a correlation. For illustrative purposes, I'll use the `swiss` dataset of various socio-demographic measures of provinces in Switzerland from the late 19th century. I'll look at the correlation between level of education and a measure of fertility:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ndata(\"swiss\")\nggplot(swiss) + \n  aes(x = Education, y = Fertility) + \n  geom_point() + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=75%}\n:::\n:::\n\nHere is a function to calculate the sample correlation and its standard error (which is necessary for the studentized CIs):\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_cor <- function(x) {\n  r <- cor(x$Education, x$Fertility) \n  n <- nrow(x)\n  c(r = r, SE = sqrt((1 - r^2)^2 / (n - 1)))\n}\n\nest <- calc_cor(swiss)\nest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          r          SE \n-0.66378886  0.08247672 \n```\n\n\n:::\n:::\n\n\nUsing this function, we can generate a sample from the bootstrap distribution of the mean:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- nrow(swiss)\ncors_boot <- replicate(999, {\n  i <- sample(1:N, replace = TRUE, size = N)\n  calc_cor(swiss[i,])\n}) |>\n  t() |>\n  as.data.frame()\n```\n:::\n\n\nThe bootstrap distribution of the sample correlations is clearly skewed and non-normal:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cors_boot) + \n  aes(r) + \n  geom_density(fill = \"blue\", alpha = 0.5) + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=75%}\n:::\n:::\n\nAs a consequence of the asymmetry and non-normality of the bootstrap distribution, the different CI variants will produce discrepant intervals.\nThe simhelpers function for calculating these intervals is as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(simhelpers)\n\nbootstrap_CIs(\n  boot_est = cors_boot$r,\n  boot_se = cors_boot$SE,\n  est = est[\"r\"],\n  se = est[\"SE\"],\n  CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\",\"bias-corrected\"),\n  format = \"long\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  bootstraps           type      lower      upper\n1        999         normal -0.9134463 -0.4654707\n2        999          basic -0.9631355 -0.5333635\n3        999        student -0.8568854 -0.4661907\n4        999     percentile -0.7942143 -0.3644423\n5        999 bias-corrected -0.7975866 -0.3752406\n```\n\n\n:::\n:::\n\nFor the bias-corrected-and-accelerated interval, the function requires the user to provide a vector of the empirical influence values of each observation. I'll calculate these using a jack-knife:\n\n::: {.cell}\n\n```{.r .cell-code}\n# leave-one-out jack-knife\njacks <- sapply(1:N, \\(x) calc_cor(swiss[-x,])[\"r\"])\n# empirical influence\ninf_vals <- est[\"r\"] - jacks\n\n# Now recalculate the bootstrap CIs\nmy_boot_CIs <- bootstrap_CIs(\n  boot_est = cors_boot$r,\n  boot_se = cors_boot$SE,\n  est = est[\"r\"],\n  se = est[\"SE\"],\n  influence = inf_vals,\n  CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\",\"bias-corrected\",\"BCa\"),\n  format = \"long\",\n  seed = 20250111\n)\n```\n:::\n\nFor sample correlation coefficients, another way to compute a confidence interval is via Fisher's z-transformation, which is both normalizing and variance-stabilizing (so that the standard error of the point estimator does not depend on the parameter) under bivariate normality. The end-points of the CI on the Fisher z scale can then be back-transformed to the original scale. Here's my \"by-hand\" calculation of this interval:\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- atanh(est[\"r\"])\nSE_z <- 1 / sqrt(N - 3)\nCI_z <- z + c(-1, 1) * qnorm(0.975) * SE_z\nCI_r <- data.frame(\n  type = \"Fisher z\",\n  lower = tanh(CI_z[1]),\n  upper = tanh(CI_z[2])\n)\n\nCI_r\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      type      lower      upper\n1 Fisher z -0.7987075 -0.4653206\n```\n\n\n:::\n:::\n\nHow do these various CIs compare? Here's a graph illustrating all of the intervals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCI_r$bootstraps <- 0\nall_CIs <- rbind(my_boot_CIs, CI_r)\nall_CIs$type <- factor(all_CIs$type, levels = c(\"Fisher z\",\"BCa\",\"bias-corrected\",\"percentile\",\"basic\",\"student\",\"normal\"))\n\nggplot(all_CIs) +\n  aes(xmin = lower, xmax = upper, y = type, color = type) + \n  geom_errorbar() + \n  theme_minimal() + \n  theme(legend.position = \"none\") + \n  labs(y = \"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=75%}\n:::\n:::\n\nThe various bootstrap intervals differ by quite a bit. \nThe percentile and bias-corrected percentile intervals are wide and extend to smaller correlations than the other intervals. \nThe basic interval is markedly different than the others, extending to much higher correlations than any of the others. \nThe studentized and BCa intervals are closer to each other and come closer to matching the end-points of the Fisher z interval.\nIt's not necessarily the case that Fisher's z interval is correct or optimal, unless the observations actually are drawn from a bivariate normal distribution.\nBut it does seem suggestive that the studentized and BCa intervals are closer to agreeing with Fisher.\n\n# Comparison to other packages\n\n## `boot`\n\nComparing the above calculations to what can be done with other packages is useful both as a validation exercise and as an illustration of the differences in workflow. \nPerhaps the most widely known R package for bootstrapping is Canty and Ripley's [`boot`](https://cran.r-project.org/package=boot) package. \nUsing it to obtain confidence intervals for a correlation requires running the bootstrap resampling process through its `boot()` function, which takes a bit of fiddling.\nFirst, I have to revise my `calc_cor()` function to take a subsetting index and to return the sampling variance instead of the standard error:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(boot) \n\ncalc_cor <- function(x, i = 1:nrow(x)) {\n  r <- cor(x$Education[i], x$Fertility[i]) \n  n <- nrow(x[i,])\n  c(r = r, V = (1 - r^2)^2 / (n - 1))\n}\n```\n:::\n\nNow I can run it through `boot()` and compute some confidence intervals:\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20250111)\nswiss_boots <- boot(swiss, calc_cor, R = 999)\nboot_boot_CIs <- boot.ci(swiss_boots, type = \"all\")\nboot_boot_CIs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = swiss_boots, type = \"all\")\n\nIntervals : \nLevel      Normal              Basic             Studentized     \n95%   (-0.8854, -0.4754 )   (-0.9211, -0.5268 )   (-0.8362, -0.4502 )  \n\nLevel     Percentile            BCa          \n95%   (-0.8008, -0.4065 )   (-0.8111, -0.4518 )  \nCalculations and Intervals on Original Scale\n```\n\n\n:::\n:::\n\nThe package does not have an option for bias-corrected intervals (without acceleration) but it can be hacked by feeding a symmetrically distributed vector of influence points:\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_BC_CI <- boot.ci(swiss_boots, type = \"bca\", L = -1:1)\nboot_BC_CI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = swiss_boots, type = \"bca\", L = -1:1)\n\nIntervals : \nLevel       BCa          \n95%   (-0.8027, -0.4128 )  \nCalculations and Intervals on Original Scale\n```\n\n\n:::\n:::\n\nThese results will not align with those reported above because they're based on a different sample from the bootstrap distribution. \nTo allow for direct comparison, I'll recompute the intervals using the bootstrap sample stored in `swiss_boots` (and computing the influence values using the same method as used implicitly by `boot.ci()`:\n\n::: {.cell}\n\n```{.r .cell-code}\nemp_inf_vals <- empinf(swiss_boots)\n\nmy_boot_CIs <- bootstrap_CIs(\n  boot_est = swiss_boots$t[,1],\n  boot_se = sqrt(swiss_boots$t[,2]),\n  est = swiss_boots$t0[1],\n  se = sqrt(swiss_boots$t0[2]),\n  influence = emp_inf_vals,\n  CI_type = c(\"normal\",\"basic\",\"student\",\"percentile\",\"bias-corrected\",\"BCa\"),\n  format = \"long\"\n)\n```\n:::\n\nIt'd be nice to put the results from `boot.ci()` into a table to ease comparison with the output of `bootstrap_CIs()`, but its output is fairly untidy. Wrangling it takes a bit of work:\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_boot_CI_tab <- data.frame(\n  type = c(\"normal\",\"basic\",\"student\",\"percentile\",\"bias-corrected\",\"BCa\"),\n  boot_lower = c(\n    boot_boot_CIs$normal[2],\n    boot_boot_CIs$basic[4],\n    boot_boot_CIs$student[4],\n    boot_boot_CIs$percent[4],\n    boot_BC_CI$bca[4],\n    boot_boot_CIs$bca[4]\n  ),\n  boot_upper = c(\n    boot_boot_CIs$normal[3],\n    boot_boot_CIs$basic[5],\n    boot_boot_CIs$student[5],\n    boot_boot_CIs$percent[5],\n    boot_BC_CI$bca[5],\n    boot_boot_CIs$bca[5]\n  )\n)\n\ncbind(my_boot_CIs, boot_boot_CI_tab[,2:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  bootstraps           type      lower      upper boot_lower boot_upper\n1        999         normal -0.8854201 -0.4754233 -0.8854201 -0.4754233\n2        999          basic -0.9210706 -0.5268220 -0.9210706 -0.5268220\n3        999        student -0.8361986 -0.4502460 -0.8361986 -0.4502460\n4        999     percentile -0.8007557 -0.4065071 -0.8007557 -0.4065071\n5        999 bias-corrected -0.8017628 -0.4135041 -0.8027344 -0.4127751\n6        999            BCa -0.8110222 -0.4519353 -0.8111334 -0.4517669\n```\n\n\n:::\n:::\n\nThe first four intervals exactly match across packages. \nThe bias-corrected and BCa intervals differ slightly because the packages use different interpolation methods for calculating percentiles that don't correspond to integer positions in the sorted bootstrap sample. \n\n## `infer`\n\nThe [`infer`](https://infer.netlify.app/) package aims to provide a coherent grammar for statistical inference (including hypothesis testing and confidence intervals) based on resampling methods, following principles of tidy data and offering a pipe-friendly workflow. Again, I'll need to repeat the bootstrap re-sampling in the package's idiom:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(infer)\nset.seed(20250111)\n\n# Compute point estimate\ncorrelation_hat <- swiss |>\n   specify(Fertility ~ Education) |>\n   calculate(stat = \"correlation\")\n\n# Compute bootstrap distribution\ninfer_boot <- \n  swiss |>\n   specify(Fertility ~ Education) |>\n   generate(reps = 999, type = \"bootstrap\") |>\n   calculate(stat = \"correlation\")\n```\n:::\n\nI can then calculate studentized, percentile, and bias-corrected bootstrap CIs:\n\n::: {.cell}\n\n```{.r .cell-code}\nCI_normal <- get_confidence_interval(\n  infer_boot, type = \"se\", \n  point_estimate = correlation_hat, level = 0.95\n)\n\nCI_percentile <- get_confidence_interval(\n  infer_boot, type = \"percentile\", \n  level = 0.95\n)\n\nCI_biascorrected <- get_confidence_interval(\n  infer_boot, type = \"bias-corrected\", \n  point_estimate = correlation_hat, level = 0.95\n)\n\ninfer_CIs <- \n  bind_rows(\n    normal = CI_normal,\n    percentile = CI_percentile,\n    `bias-corrected` = CI_biascorrected,\n    .id = \"type\"\n  )\n```\n:::\n\nFor comparison purposes, I'll once again need to re-compute the intervals with `bootstrap_CIs()`, this time with the `infer` bootstrap sample:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_infer_CIs <- bootstrap_CIs(\n  boot_est = infer_boot$stat,\n  est = correlation_hat$stat,\n  CI_type = c(\"normal\",\"percentile\",\"bias-corrected\"),\n  format = \"long\"\n)\n\ninner_join(my_infer_CIs, infer_CIs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  bootstraps           type      lower      upper   lower_ci   upper_ci\n1        999         normal -0.9052953 -0.4614019 -0.8857356 -0.4418421\n2        999     percentile -0.8030248 -0.3487307 -0.8027752 -0.3507277\n3        999 bias-corrected -0.8027620 -0.3487307 -0.8027066 -0.3504208\n```\n\n\n:::\n:::\n\nThe results do not exactly match across packages. For the normal interval, the difference occurs because the `simhelpers` implementation (like the `boot` implementation) includes a bias-correction term that shifts the interval by the difference between the point estimate and the average bootstrap estimate, which `infer` does not do.\nThe very small differences in the percentile and bias-corrected intervals are due to the use of different interpolation methods for calculating percentiles. \n\n## `rsample`\n\nOkay, one last time, this time using the [`rsample`](https://rsample.tidymodels.org/) package by @rsamplepkg. \nI'll first need to re-work my correlation calculation to provide a `data.frame` with columns called `term`, `estimate`, and `std.error`, and also ensure that the function allows for extra arguments with `...`.\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_cor <- function(split, ...) {\n  x <- analysis(split)\n  n <- nrow(x)\n  r <- cor(x$Education, x$Fertility)\n  tibble(\n    term = \"corr\",\n    estimate = r,\n    std.error = sqrt((1 - r^2)^2 / (n - 1))\n  )\n}\n```\n:::\n\nNow I can generate a bootstrap distribution using `bootstraps`, setting `apparent = TRUE` to include calculation of the point estimate and analytical standard error. I'll use about 2000 bootstraps here to avoid an automated warning message.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(rsample)\n\nset.seed(20250111)\nrsample_boots <- \n  swiss %>%\n  bootstraps(1999, apparent = TRUE) %>%\n  mutate(r = map(splits, calc_cor))\n```\n:::\n\nThe `resample` package provides functions for calculating percentile, studentized, and BCa intervals. I'll do all three:\n\n::: {.cell}\n\n```{.r .cell-code}\nrsample_CIs <- bind_rows(\n  int_pctl(rsample_boots, statistics = r),\n  int_t(rsample_boots, statistics = r),\n  int_bca(rsample_boots, statistics = r, .fn = calc_cor)\n) %>%\n  select(type = .method, .lower, .upper) %>%\n  mutate(\n    type = recode(type, `student-t` = \"student\")\n  )\n```\n:::\n\nNow I'll redo the interval calculations with `bootstrap_CIs()`:\n\n::: {.cell}\n\n```{.r .cell-code}\n# just the point estimate\nrsample_apparent <- \n  rsample_boots %>%\n  filter(id == \"Apparent\") %>%\n  unnest(r)\n\n# just the bootstraps\nrsample_boots <-\n  rsample_boots %>%\n  filter(id != \"Apparent\") %>%\n  unnest(r)\n\n# jack-knife to get empirical influence values\ninf_vals <- \n  swiss %>%\n  loo_cv() %>%\n  mutate(r = map(splits, calc_cor)) %>%\n  unnest(r) %>%\n  mutate(\n    inf_val = rsample_apparent$estimate - estimate\n  ) %>%\n  pull(inf_val)\n\n# calculate bootstrap CIs  \nmy_rsample_CIs <- \n  bootstrap_CIs(\n    boot_est = rsample_boots$estimate,\n    boot_se = rsample_boots$std.error,\n    est = rsample_apparent$estimate,\n    se = rsample_apparent$std.error,\n    influence = inf_vals,\n    CI_type = c(\"student\",\"percentile\",\"BCa\"),\n    format = \"long\"\n  )\n\n# Compare\ninner_join(my_rsample_CIs, rsample_CIs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  bootstraps       type      lower      upper     .lower     .upper\n1       1999    student -0.8529496 -0.4470351 -0.8526882 -0.4484207\n2       1999 percentile -0.8020261 -0.3725691 -0.8014797 -0.3731069\n3       1999        BCa -0.8194484 -0.4326284 -0.8191845 -0.4324908\n```\n\n\n:::\n:::\n\nAll checks out, with small differences due to the method used to interpolate percentiles and how the acceleration constant is calculated.\n\nAlthough `rsample` does not provide the full set of bootstrap CI variants, the three it does include are probably the most useful ones. \nThe option to include the original sample estimate as an additional result in the `bootstraps` object is also quite nice. \nHowever, the workflow enforced by `rsample` does seem to have a big downside with respect to memory management. \nTaking a bootstrap sample with $B$ replications creates $B$ new datasets (stored in a nested list). \nSimilarly, running `loo_cv()` creates a near-copy of the dataset for every row of the original dataset.\nThese could get to be quite large objects:\n\n::: {.cell}\n\n```{.r .cell-code}\nobject.size(swiss)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6464 bytes\n```\n\n\n:::\n\n```{.r .cell-code}\nobject.size(loo_cv(swiss))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n403696 bytes\n```\n\n\n:::\n\n```{.r .cell-code}\nobject.size(bootstraps(swiss, times = 999))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n8561488 bytes\n```\n\n\n:::\n:::\n\nEspecially for large datasets, it would be much more memory-efficient to roll together the re-sampling step and the estimation step.\n\n# Extrapolating coverage rates a la Boos and Zhang\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr_dat <- function(n, rho, df = 10) {\n  require(mvtnorm)\n  Sigma <- rho + diag(1 - rho, nrow = 2)\n  rmvt(n = n, sigma = Sigma, df = 10)\n}\n\ncalc_cor <- \\(x) cor(x[,1], x[,2])\n\nr_dat(30, rho = 0.8) |> calc_cor()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7456072\n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}