{
  "hash": "58adecf283823ed4f59eff4cba193ba8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Computing covariance matrices for meta-analysis of dependent effect size estimates\ndate: '2024-05-18'\ndraft: true\ncategories:\n- effect size\n- distribution theory\n- meta-analysis\ncode-tools: true\n---\n\n\n[A while back](/posts/correlations-between-SMDs/), I wrote up formulas for the sampling covariances between standardized mean differences that are calculated from multi-arm experiments, including experiments with multiple outcomes. Along with the sampling variances of effect size estimates, the covariances are also needed for conducting a meta-analysis of dependent effect size data. However, it's often hard to get all the information you need to actually apply the formulas in practice, and so we end up relying on simplified, rough approximations (and sensitivity analysis) for the covariance terms. A few years after the post above, [I sketched out some functions](/posts/imputing-covariance-matrices-for-multi-variate-meta-analysis/) for building these sort of quick-and-dirty covariance matrices, and eventually added them to the `clubSandwich package` as `impute_covariance_matrix()` and `pattern_covariance_matrix()`. Although they're certainly convenient, and can handle situations where you'd like to assume different correlations for different pairs of outcomes, the covariance matrices you can generate with these functions don't really handle the situation where you've got effect size estimates from multi-arm experiments.\n\nThen a few years ago, Wolfgang Viechtbauer added a function called `vcalc()` to the `metafor` package, which does everything that `impute_covariance_matrix()` and `pattern_covariance_matrix()` can do, but with even more features and nuance. The `vcalc()` doesn't implement the exact formulas for covariances between standardized mean differences, but it does implement a close approximation that also generalizes readily to other effect size metrics. Consequently, I think it's really time to retire (or at least deprecate) the clubSandwich functions. To mark the occasion (and hopefully encourage users of `clubSandwich::impute_covariance_matrix()` to make the switch), I'm going to use this post to demonstrate some of the nice features of `metafor::vcalc()`.\n\n## Multi-arm trials\n\nHere's some made-up datasets from two hypothetical studies, where the first study has three treatment arms and the second has two treatment arms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Kaplan (2011)\n\nKaplan_dat <- tibble(\n  Condition = c(\"Business as usual\", \"Social media diet\",\"Social media encouragement\"),\n  N = c(36, 49, 72),\n  FOMO_Mean = c(39.7, 40.7,48.6),\n  FOMO_SD = c(17.2, 13.5, 14.9),\n  CESD_Mean = c(10.1, 9.8, 11.2),\n  CESD_SD = c(5.7,7.1,8.3)\n)\n\n# Pre-process for effect size calculations\n\nKaplan_long <-\n  Kaplan_dat %>%\n  pivot_longer(\n    FOMO_Mean:CESD_SD, \n    names_to = c(\"outcome\",\".value\"),\n    names_pattern = c(\"(.+)_(.+)\")\n  )\n\nKaplan_BAU <- \n  Kaplan_long %>%\n  filter(Condition == \"Business as usual\") \n\nKaplan_ES <-\n  Kaplan_long %>%\n  filter(Condition != \"Business as usual\") %>%\n  inner_join(Kaplan_BAU, by = \"outcome\", suffix = c(\"_T\",\"_C\")) %>%\n  mutate(study = \"Kaplan (2011)\")\n\n\n# Kim & Wollack (2013)\nKim_dat <- tibble(\n  Condition = c(\"Business as usual\", \"Social media diet\"),\n  N = c(14, 34),\n  FOMO_Mean = c(22.83, 20.22),\n  FOMO_SD = c(8.3, 9.7),\n  BDI_Mean = c(34.28, 35.55),\n  BDI_SD = c(12.1, 13.3)\n)\n\nKim_ES <- \n  Kim_dat %>%\n  mutate(\n    study = \"Kim (2011)\",\n    arm = c(\"C\",\"T\")\n  ) %>%\n  pivot_longer(\n    FOMO_Mean:BDI_SD, \n    names_to = c(\"outcome\",\".value\"),\n    names_pattern = c(\"(.+)_(.+)\")\n  ) %>%\n  pivot_wider(\n    names_from = arm,\n    values_from = c(Condition, N, Mean, SD)\n  )\n```\n:::\n\nWe can compute effect size estimates[^pooling] and variances from the summary statistics as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(metafor)\n\nES_dat <-\n  bind_rows(Kaplan_ES, Kim_ES) %>%\n  escalc(\n    data = .,\n    measure = \"SMD\",\n    n1i = N_T, n2i = N_C,\n    m1i = Mean_T, m2i = Mean_C,\n    sd1i = SD_T, sd2i = SD_C\n  )\n\nES_dat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n                 Condition_T N_T outcome Mean_T SD_T       Condition_C N_C \n1          Social media diet  49    FOMO  40.70 13.5 Business as usual  36 \n2          Social media diet  49    CESD   9.80  7.1 Business as usual  36 \n3 Social media encouragement  72    FOMO  48.60 14.9 Business as usual  36 \n4 Social media encouragement  72    CESD  11.20  8.3 Business as usual  36 \n5          Social media diet  34    FOMO  20.22  9.7 Business as usual  14 \n6          Social media diet  34     BDI  35.55 13.3 Business as usual  14 \n  Mean_C SD_C         study      yi     vi \n1  39.70 17.2 Kaplan (2011)  0.0653 0.0482 \n2  10.10  5.7 Kaplan (2011) -0.0454 0.0482 \n3  39.70 17.2 Kaplan (2011)  0.5630 0.0431 \n4  10.10  5.7 Kaplan (2011)  0.1448 0.0418 \n5  22.83  8.3    Kim (2011) -0.2753 0.1016 \n6  34.28 12.1    Kim (2011)  0.0963 0.1009 \n```\n\n\n:::\n:::\n\n\n[^pooling]: Detail-oriented readers might note that the standardized mean differences calculated here are from multi-arm trials, but the effects are calculated using denominator standard deviations that only pool across pairs of arms, rather than across _all_ arms in the sample. The latter is usually better (because it keeps the scaling of the outcome constant across all the effects from the sample), but I'm too lazy to handle this particular wrinkle right now.\n\nUsing `impute_covariance_matrix()` on this dataset will return a set of covariance matrices for each sample, where there is a constant correlation between pairs of effect sizes from the same study (here I use a correlation of 0.7):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(clubSandwich)\n\nV_icm <- with(ES_dat, \n  impute_covariance_matrix(\n    vi = vi,\n    cluster = study,\n    r = 0.7\n  )\n)\n\nV_icm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Kaplan (2011)`\n           [,1]       [,2]       [,3]       [,4]\n[1,] 0.04821104 0.03374319 0.03192133 0.03141023\n[2,] 0.03374319 0.04819807 0.03191704 0.03140601\n[3,] 0.03192133 0.03191704 0.04313398 0.02971034\n[4,] 0.03141023 0.03140601 0.02971034 0.04176377\n\n$`Kim (2011)`\n           [,1]       [,2]\n[1,] 0.10162970 0.07089791\n[2,] 0.07089791 0.10093693\n```\n\n\n:::\n\n```{.r .cell-code}\nlapply(V_icm, cov2cor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Kaplan (2011)`\n     [,1] [,2] [,3] [,4]\n[1,]  1.0  0.7  0.7  0.7\n[2,]  0.7  1.0  0.7  0.7\n[3,]  0.7  0.7  1.0  0.7\n[4,]  0.7  0.7  0.7  1.0\n\n$`Kim (2011)`\n     [,1] [,2]\n[1,]  1.0  0.7\n[2,]  0.7  1.0\n```\n\n\n:::\n:::\n\nThat degree of correlation isn't really right---it's too high, for one, and it shouldn't be constant across all three pairs of effects from study 1 because the treatment groups have different sample sizes. In fact, the covariances among these effects can be [calculated based on the available information](/posts/correlations-between-SMDs/), without the need to impute anything. A closer approximation is possible with `vcalc()`. \n\nTo use `vcalc()`, we'll need to provide a bit of additional information about the structure of the arms within each study (in the arguments `grp1` and `grp2`) and the sample sizes of each arm (in the arguments `w1` and `w2`):\n\n::: {.cell}\n\n```{.r .cell-code}\nV_vcalc <- vcalc(\n  data = ES_dat,        # dataset\n  vi = vi,              # sampling variances\n  cluster = study,      # identifier for each unique sample\n  obs = outcome,        # identifier for each unique outcome within a study\n  grp1 = Condition_T,   # identifier for unique treatment arms\n  w1 = N_T,             # effective sample size of each treatment arm\n  grp2 = Condition_C,   # identifier for unique contro arms\n  w2 = N_C,             # effective sample size of each control arm\n  rho = 0.7,            # assumed correlation between outcomes within a study\n  sparse = TRUE         # return a sparse matrix\n)\n\n# look at the blocks for each sample\nV_vcalc_list <- blsplit(V_vcalc, ES_dat$study) \nV_vcalc_list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Kaplan (2011)`\n4 x 4 sparse Matrix of class \"dgCMatrix\"\n                                                \n[1,] 0.04821104 0.03374319 0.02827001 0.01947216\n[2,] 0.03374319 0.04819807 0.01978635 0.02781363\n[3,] 0.02827001 0.01978635 0.04313398 0.02971034\n[4,] 0.01947216 0.02781363 0.02971034 0.04176377\n\n$`Kim (2011)`\n2 x 2 sparse Matrix of class \"dgCMatrix\"\n                          \n[1,] 0.10162970 0.07089791\n[2,] 0.07089791 0.10093693\n```\n\n\n:::\n:::\n\nThese covariances have smaller correlations between effect sizes for different arms (closer to 0.5 or less):\n\n::: {.cell}\n\n```{.r .cell-code}\nblsplit(V_vcalc, ES_dat$study) |> \n  lapply(cov2cor)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Kaplan (2011)`\n4 x 4 sparse Matrix of class \"dsCMatrix\"\n                                            \n[1,] 1.0000000 0.7000000 0.6199304 0.4339513\n[2,] 0.7000000 1.0000000 0.4339513 0.6199304\n[3,] 0.6199304 0.4339513 1.0000000 0.7000000\n[4,] 0.4339513 0.6199304 0.7000000 1.0000000\n\n$`Kim (2011)`\n2 x 2 sparse Matrix of class \"dsCMatrix\"\n            \n[1,] 1.0 0.7\n[2,] 0.7 1.0\n```\n\n\n:::\n:::\n\n\nWhat's going on here? The code inside `metafor::vcalc()` contains one of the hairiest messes of `ifelse` statements I've ever encountered, but I think the gist of it is that the covariance terms are calculated differently depending on whether different rows within a cluster share the same `grp1`  or `grp2` identifier. Say that study $j$ has $k_j$ effect sizes, indexed by $i=1,...,k_j$, that the covariance between effects $h$ and $i$ is $V_{hi,j}$, that the weights corresponding to effect $i$ are $\\eta_{1ij}$ and $\\eta_{2ij}$, and that the group identifiers are $g_{1ij}$ and $g_{2ij}$. Assuming that the set of `grp1` identifiers does not overlap with the set of `grp2` identifiers, then the covariance between effect sizes $h$ and $i$ in study $j$ is taken to be\n$$\nV_{hi,j} = \\left(I(g_{1hj} = g_{1ij}) \\sqrt{\\frac{\\frac{1}{\\eta_{1hj}}}{\\frac{1}{\\eta_{1hj}} + \\frac{1}{\\eta_{2hj}}} \\times \\frac{\\frac{1}{\\eta_{1ij}}}{\\frac{1}{\\eta_{1ij}} + \\frac{1}{\\eta_{2ij}}}} + I(g_{2hj} = g_{2ij}) \\sqrt{\\frac{\\frac{1}{\\eta_{2hj}}}{\\frac{1}{\\eta_{2hj}} + \\frac{1}{\\eta_{2hj}}} \\times \\frac{\\frac{1}{\\eta_{1ij}}}{\\frac{1}{\\eta_{1ij}} + \\frac{1}{\\eta_{2ij}}}}\\right) \\times \\sqrt{V_{hh,j}  V_{ii,j}}.\n$$\nFor many effect size metrics, the sampling variance has a form like\n$V_{ii,j} = \\frac{\\sigma_{1ij}}{\\eta_{1ij}} + \\frac{\\sigma_{2ij}{\\eta_{2ij}}$, and so the covariance formula above will effectively pull off the part of the sampling variance that corresponds to a group shared in common by effect sizes $h$ and $i$, and will end up reducing to the sampling variance when $h = i$. \n\nThe formula for the sampling variance of a standardized mean difference (based on a simple comparison of group means) is \n$$\\text{Var}(d_{ij}) \\approx V_{ii,j} = \\frac{1}{n_{C,ij}} + \\frac{1}{n_{T,ij}} + \\frac{d_{ij}^2}{2 \\nu},$$\nwhere $n_{C,ij}$ and $n_{T,ij}$ are the sample sizes in the two groups being compared and $\\nu$ is the degrees of freedom of the denominator standard deviation. This doesn't exactly have the proportional form above, but unless $\\nu$ is really small, $V_{ii,j}$ is going to be very close to $\\frac{1}{n_{C,ij}} + \\frac{1}{n_{T,ij}}$. Taking $\\eta_{1,ij} = n_{T,ij}$ and $\\eta_{2,ij} = n_{C,ij}$, the covariance formula implemented in `vcalc` ends up giving something quite close to\n$$V_{hi,j} \\approx \\frac{I(g_{2hj} = g_{2ij})}{n_{C,ij}} + \\frac{I(g_{1hj} = g_{1ij})}{n_{T,ij}}.$$\nSince the covariance formulas I reviewed in my old post are approximations anyways, this further simplification seems pretty much okay. \n\nHere's a \"by-hand\" implementation of the covariance formula from my old post:\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(dplyr)\n# V_hand <- \n#   ES_dat %>% \n#   mutate(df = n_T + n_C - 2) %>%\n#   group_by(sampleID) %>% \n#   group_map(~ (diag(1 / .x$n_T) + 1 / .x$n_C + tcrossprod(.x$yi / sqrt(.x$df))) * (1 - 3 / (4 * .x$df - 1))^2)\n```\n:::\n\nThe `vcalc()` approximation gets very close:\n\n::: {.cell}\n\n```{.r .cell-code}\n# round(V_hand[[1]] - V_vcalc_list[[1]], 4)\n# round(V_hand[[2]] - V_vcalc_list[[2]], 4)\n```\n:::\n\n\n## Now with multiple outcomes\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}