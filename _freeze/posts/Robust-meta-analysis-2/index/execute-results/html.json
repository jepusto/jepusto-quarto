{
  "hash": "d259588ef335bf918a207b8e2733f753",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Another meta-sandwich\ndate: '2014-04-23'\ncategories:\n- meta-analysis\n- sandwiches\n- Rstats\n- robust variance estimation\ncode-tools: true\n---\n\n\nIn [a previous post](/posts/Robust-meta-analysis-1/), I provided some code to do robust variance estimation with `metafor` and `sandwich`. \nHere's another example, replicating some more of the calculations from [Tanner-Smith & Tipton (2013)](http://doi.org/10.1002/jrsm.1091). \n([See here](https://gist.github.com/jepusto/11147304) for the complete code.)\n\nAs a starting point, here are the results produced by the `robumeta` package:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(grid)\nlibrary(robumeta)\n\ndata(corrdat)\nrho <- 0.8\n\nHTJ <- robu(effectsize ~ males + college + binge,\n            data = corrdat, \n            modelweights = \"CORR\", rho = rho,\n            studynum = studyid,\n            var.eff.size = var, small = FALSE)\nHTJ\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRVE: Correlated Effects Model  \n\nModel: effectsize ~ males + college + binge \n\nNumber of studies = 39 \nNumber of outcomes = 172 (min = 1 , mean = 4.41 , median = 4 , max = 18 )\nRho = 0.8 \nI.sq = 75.08352 \nTau.sq = 0.1557714 \n\n               Estimate  StdErr t-value dfs P(|t|>) 95% CI.L 95% CI.U Sig\n1 X.Intercept.  0.31936 0.27784   1.149  35   0.258  -0.2447  0.88340    \n2        males -0.00331 0.00376  -0.882  35   0.384  -0.0109  0.00431    \n3      college  0.41226 0.18685   2.206  35   0.034   0.0329  0.79159  **\n4        binge  0.13774 0.12586   1.094  35   0.281  -0.1178  0.39326    \n---\nSignif. codes: < .01 *** < .05 ** < .10 *\n---\n```\n\n\n:::\n:::\n\n\nTo exactly re-produce the results with `metafor`, I'll need to use the weights proposed by HTJ. In their approach to the correlated effects case, effect size $i$ from study $j$ receives weight equal to $\\left[\\left(v_{\\cdot j} + \\hat\\tau^2\\right)(1 + (k_j - 1) \\rho)\\right]^{-1}$, where $v_{\\cdot j}$ is the average sampling variance of the effect sizes from study $j$, $\\hat\\tau^2$ is an estimate of the between-study variance, $k_j$ is the number of correlated effects in study $j$, and $\\rho$ is a user-specified value of the intra-study correlation. However, it appears that `robumeta` actually uses a slightly different set weights, which are equivalent to taking $\\rho = 1$. I calculate the latter weights, fit the model in `metafor`, and output the robust standard errors and $t$-tests:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::source_gist(id = \"11144005\", filename = \"metafor-sandwich.R\")\n\ncorrdat <- within(corrdat, {\n  var_mean <- tapply(var, studyid, mean)[studyid]\n  k <- table(studyid)[studyid]\n  var_HTJ <- as.numeric(k * (var_mean + as.numeric(HTJ$mod_info$tau.sq)))\n})\n\nmeta1 <- rma.mv(effectsize ~ males + college + binge, \n                V = var_HTJ, \n                data = corrdat, method = \"FE\")\nmeta1$cluster <- corrdat$studyid\nRobustResults(meta1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nt test of coefficients:\n\n          Estimate Std. Error t value Pr(>|t|)  \nintrcpt  0.3193586  0.2778360  1.1494  0.25816  \nmales   -0.0033143  0.0037573 -0.8821  0.38374  \ncollege  0.4122631  0.1868489  2.2064  0.03401 *\nbinge    0.1377393  0.1258637  1.0944  0.28127  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nOne could specify a similar (though not exactly identical model) in `metafor` as follows. In the HTJ approach, $\\rho$ represents the total correlation induced by both the within-study sampling error and intra-study correlation in true effects. In contrast, the `metafor` approach would take $\\rho$ to be correlation due to within-study sampling error alone. I'll first need to create a block-diagonal covariance matrix given a user-specified value of $\\rho$. \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Matrix)\nequicorr <- function(x, rho) {\n  corr <- rho + (1 - rho) * diag(nrow = length(x))\n  tcrossprod(x) * corr \n} \ncovMat <- as.matrix(bdiag(with(corrdat, tapply(var_mean, studyid, equicorr, rho = 0.8, simplify = FALSE))))\n```\n:::\n\n\nPassing this block-diagonal covariance matrix to `rma.mv`, I now estimate the model \n\n$$T_{ij} = \\mathbf{X}_{ij} \\beta + \\nu_i + e_{ij},$$\n\nwhere $Var(\\nu_i) = \\sigma^2$, $Var(e_{ij}) = v_{ij}$, and $Cor(e_{ij}, e_{ik}) = \\rho$. Note that $\\sigma^2$ is now estimated via REML.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeta2 <- rma.mv(yi = effectsize ~ males + college + binge, \n                V = covMat, random = ~ 1 | studyid, \n                data = corrdat,\n                method = \"REML\")\nc(sigma.sq = meta2$sigma2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n sigma.sq \n0.2477825 \n```\n\n\n:::\n:::\n\n\nThe between-study heterogeneity estimate is considerably larger than the moment estimate from `robumeta`. Together with the difference in weighting, this leads to some changes in the coefficient estimates and their estimated precision:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRobustResults(meta2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nt test of coefficients:\n\n          Estimate Std. Error t value Pr(>|t|)   \nintrcpt -0.8907096  0.4148219 -2.1472 0.038783 * \nmales    0.0163074  0.0055805  2.9222 0.006052 **\ncollege  0.3180139  0.2273396  1.3988 0.170658   \nbinge   -0.0984026  0.0897269 -1.0967 0.280265   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nIt is important to keep in mind that the estimate of between-study heterogeneity depends on the posited model for the covariance structure, including the assumed value of $\\rho$. HTJ recommend conducting sensitivity analysis across a range of values for the within-study effect correlation. Re-calculating the value of $\\sigma^2$ for $\\rho$ between 0.0 and 0.9 yields the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma2 <- function(rho) {\n  covMat <- as.matrix(bdiag(with(corrdat, tapply(var_mean, studyid, equicorr, rho = rho, simplify = FALSE))))\n  rma.mv(yi = effectsize ~ males + college + binge, \n                  V = covMat, random = ~ 1 | studyid, \n                  data = corrdat,\n                  method = \"REML\")$sigma2\n}\nrho_sens <- seq(0,0.9,0.1)\nsigma2_sens <- sapply(rho_sens, sigma2)\ncbind(rho = rho_sens, sigma2 = round(sigma2_sens, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      rho sigma2\n [1,] 0.0 0.2519\n [2,] 0.1 0.2513\n [3,] 0.2 0.2507\n [4,] 0.3 0.2502\n [5,] 0.4 0.2497\n [6,] 0.5 0.2492\n [7,] 0.6 0.2487\n [8,] 0.7 0.2482\n [9,] 0.8 0.2478\n[10,] 0.9 0.2474\n```\n\n\n:::\n:::\n\n\nThe between-study heterogeneity is quite insensitive to the assumed value of $\\rho$. \n\nThe difference between the results based on `metafor` versus on `robumeta` appears to be due to the subtle difference in the weighting approach: `metafor` uses block-diagonal weights that contain off-diagonal terms for effects drawn from a common study, whereas `robumeta` uses entirely diagonal weights.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}