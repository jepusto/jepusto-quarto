{
  "hash": "8194975a7e4ccee500e31c4d3408302e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Beta-density selection models for meta-analysis\ndate: '2024-10-23'\ndraft: true\ncategories:\n- effect size\n- distribution theory\n- selective reporting\nexecute:\n  echo: false\ncode-fold: true\nbibliography: \"../selection-references.bib\"\ncsl: \"../apa.csl\"\nlink-citations: true\ncode-tools: true\ntoc: true\ncss: styles.css\ncrossref: \n  eq-prefix: \"\"\n---\n\n\nI still have meta-analytic selection models on my mind. \nAs part of [an IES-funded project](https://ies.ed.gov/funding/grantsearch/details.asp?ID=5730) with [colleagues from the American Institutes for Research](https://www.air.org/mosaic/experts), I've been working on developing methods for estimating selection models that can accommodate dependent effect sizes.\nWe're looking at two variations of p-value selection models: step-function selection models  similar to those proposed by @hedges1992modeling and @vevea1995general and beta-density models as developed in @Citkowicz2017parsimonious. \nBoth models fall within the broader class of $p$-value selection models, which make explicit assumptions about the probability of observing an effect size, given its statistical significance level and sign. \nI've already described how step-function models work (see [this previous post](/posts/step-function-selection-models/)) and, as a bit of a detour, I also took a stab at demystifying the [Copas selection model](/posts/Copas-selection-models). \nIn this post, I'll look at the beta-density model,  highlight how it differs from step-function models, and explain some of the tweaks to the model that we're examining as part of the project. \n\n# The beta-density selection model \n\nThe beta-density selection model is another entry in the class of $p$-value selection models. \nLike the step-function model, it consists of a set of assumptions about\nhow effect size estimates are generated prior to selection (the _evidence-generation process_), and a set of assumptions about how selective reporting happens as a function of the effect size estimates (the _selective reporting process_).\nIn both the beta-density and step-function models, the evidence-generating process is a random effects model:\n$$\nT_i^* | \\sigma_i^* \\sim N\\left(\\mu, \\tau^2 + \\left(\\sigma_i^*\\right)^2\\right),\n$$ {#eq-evidence-generation}\nwhere $T_i^*$ denotes an effect size estimate prior to selective reporting and $\\sigma_i^*$ denotes its (known) standard error.[^metareg]\n\n[^metareg]: With either model, the evidence-generating process can be extended to include a meta-regression with predictors of the average effect size. This amounts to replacing $\\mu$ with $\\beta_0 + \\beta_1 x_{1i} + \\cdots + \\beta_p x_{pi}$ for some set of predictors $x_{1i},...,x_{pi}$. In this post I'm not going to worry about this additional complexity.\n\nThe only difference between the beta-density and step-function selection models is the functional form of the selective reporting process. \nLetting $O_i^*$ be an indicator equal to 1 if $T_i^*$ is reported and $p_i^* = 1 - \\Phi\\left(T_i^* / \\sigma_i^*\\right)$ be the one-sided p-value corresponding to the effect size estimate, \nthe selective reporting process describes the shape of $\\text{Pr}(O_i^* = 1 | p_i^*)$.\nThe step-function model uses a piece-wise constant function with level shifts at specific, analyst-specified significance thresholds (see @fig-step-fun). \nThe beta-density model instead uses...wait for it...a beta density kernel function, which can take on a variety of smooth shapes over the unit interval (see @fig-beta-dens).\n\n::: {.column-page-inset-right layout-ncol=2}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Two-step selection model with $\\lambda_1 = 0.6, \\lambda_2 = 0.4$](index_files/figure-html/fig-step-fun-1.png){#fig-step-fun width=480}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Beta-density selection model with $\\lambda_1 = 0.5, \\lambda_2 = 0.9$](index_files/figure-html/fig-beta-dens-1.png){#fig-beta-dens width=480}\n:::\n:::\n\n\n:::\n\nIn the original formulation of the beta density model, the selection function is given by\n$$\n\\text{Pr}(O_i^* = 1 | p_i^*) \\propto \\left(p_i^*\\right)^{(\\lambda_1 - 1)} \\left(1 - p_i^*\\right)^{(\\lambda_2 - 1)},\n$$\nwhere the parameters $\\lambda_1$ and $\\lambda_2$ must be strictly greater than zero, and $\\lambda_1 = \\lambda_2 = 1$ corresponds to a constant probability of selection (i.e., no selective reporting bias).\nIn proposing the model, @Citkowicz2017parsimonious argued that the beta-density function provides a parsimonious expression of more complex forms of selective reporting than can easily be captured by a step function. \nFor instance, the beta density in @fig-beta-dens is smoothly declining from $p < .005$ through the psychologically salient thresholds $p = .025$ and $p = .05$ and beyond. In order to approximate such a smooth curve with a step function, one would have to use many thresholds and therefore many more than the two parameters of the beta density.\n\n# A truncated beta-density\n\nAlthough using smoothly varying selection probabilities may seem appealing, the beta density also comes with an important limitation, highlighted in a commentary by @hedges2017plausibility. For some parameter values, the beta density implies selection probabilities that differ by many orders of magnitude. These extreme differences in selection probability can imply implausible selection processes, in which hundreds of non-significant effect size estimates would need to go unreported to observe a sample of a few dozen findings. Extreme differences in selection probabilities make the model highly sensitive to the inclusion or exclusion of some effect size estimates because the influence of each estimate is driven by the inverse of its selection probability [@hedges2017plausibility]. \n\nTo address this issue, we consider a modification of the beta density where the function is truncated at $p$-values larger or smaller than certain thresholds. \nFor user-specified thresholds $\\alpha_1$ and $\\alpha_2$, let $\\tilde{p}_i^* = \\min\\{\\max\\{\\alpha_1, p_i^*\\}, \\alpha_2\\}$. The truncated beta density is then \n$$\n\\text{Pr}(O_i^* = 1 | p_i^*) \\propto (\\tilde{p}_i^*)^{(\\lambda_1 - 1)} \\left(1 - \\tilde{p}_i^*\\right)^{(\\lambda_2 - 1)},\n$$ {#eq-selection-process}\nSetting the truncation thresholds at psychologically salient levels such as $\\alpha_1 = .025$ and $\\alpha_2 = .975$ (which correspond to positive and negative effects that are statistically significant based on two-sided tests with $\\alpha = .05$) gives something kind of like the step-function selection model, but with smoothly varying selection probabilities in the interior. \nAlternately, one could set the second threshold at $\\alpha_2 = .500$ (corresponding to an effect of zero) so that all negative effect size estimates have a constant probability of selection, but positive effect size estimates that are non-significant have smoothly varying selection probabilities, up to the point where $p_i^* = .025$.\n\n# Distribution of observed effect sizes\n\nJust as with the step-function selection model, the assumptions of the evidence-generating process (@eq-evidence-generation) and the selection process (@eq-selection-process) can be combined to obtain the distribution of observed effect sizes, \nwith \n$$\n\\begin{aligned}\n\\Pr(T_i = t | \\sigma_i) &\\propto \\Pr\\left(O_i^* = 1| p_i^*\\right) \\times \\Pr(T_i^*  = t| \\sigma_i^* = \\sigma_i) \\\\\n&\\propto \\frac{(\\tilde{p}_i^*)^{(\\lambda_1 - 1)} \\left(1 - \\tilde{p}_i^*\\right)^{(\\lambda_2 - 1)}}{\\sqrt{\\tau^2 + \\sigma_i^2}}\\times \\phi\\left(\\frac{t - \\mu}{\\sqrt{\\tau^2 + \\sigma_i^2}}\\right)\n\\end{aligned}\n$$\n\nHere is an interactive graph showing the distribution of the effects prior to selection (in grey) and the distribution of observed effect sizes (in blue) based on the truncated beta-density selection model. Initially, the truncation points are set at $\\alpha_1 = .025$ and $\\alpha_2 = .975$ and the selection parameters are set to $\\lambda_1 = 0.6$ and $\\lambda_2 = 0.9$, but you can change these however you like.\nBelow the effect size distribution are the moments of the distribution (computed numerically) and a graph of the truncated beta density that determines the selection probabilities.\n\n\n```{ojs}\nmath = require(\"mathjs\")\nnorm = import('https://unpkg.com/norm-dist@3.1.0/index.js?module')\n\nfunction findprob(p, alp1, alp2, lam1, lam2) {\n  let p_ = math.min(math.max(p, alp1), alp2);\n  let prob = (p_)**(lam1 - 1) * (1 - p_)**(lam2 - 1);\n  return prob;\n}\n\neta = math.sqrt(tau**2 + sigma**2)\n\nmax_p = {\n  if (lambda1 + lambda2 > 2) {\n    return (lambda1 - 1) / (lambda1 + lambda2 - 2);\n  } else if (lambda1 > lambda2) {\n    return alpha2;\n  } else {\n    return alpha1;\n  }\n}\n\nmax_prob = findprob(max_p, alpha1, alpha2, lambda1, lambda2)\n\n```\n\n```{ojs}\npts = 201\n\ndat = Array(pts).fill().map((element, index) => {\n  let t = mu - 3 * eta + index * eta * 6 / (pts - 1);\n  let p = 1 - norm.cdf(t / sigma);\n  let dt = norm.pdf((t - mu) / eta) / eta;\n  let prob = findprob(p, alpha1, alpha2, lambda1, lambda2);\n  return ({\n    t: t,\n    d_unselected: dt,\n    d_selected: prob * dt / max_prob\n  })\n})\n\nselfundat = Array(pts).fill().map((element, index) => {\n  let p = index / (pts - 1);\n  let prob = findprob(p, alpha1, alpha2, lambda1, lambda2);\n  return ({\n    p: p,\n    prob: prob\n  })\n})\n\nmoments = {\n  let prob = 0;\n  let ET = 0;\n  let ET2 = 0;\n  for (let i = 0; i < pts; i++) {\n    prob += dat[i].d_selected;\n  \tET += dat[i].t * dat[i].d_selected;\n    ET2 += dat[i].t**2 * dat[i].d_selected;\n  }\n  let ET_val = ET / prob;\n  let VT_val = ET2 / prob - ET_val**2;\n  return ({\n    Ai: prob * 6 * eta / (pts - 1),\n    ET: ET_val,\n    SDT: math.sqrt(VT_val)\n  })\n}\n\neta_toprint = eta.toFixed(3)\nAi_toprint = moments.Ai.toFixed(3)\nET_toprint = moments.ET.toFixed(3)\nSDT_toprint = moments.SDT.toFixed(3)\n\n```\n\n\n:::::: {.grid .column-page}\n\n::::: {.g-col-8 .center}\n\n\n```{ojs}\nPlot.plot({\n  height: 300,\n  width: 700,\n  y: {\n    grid: false,\n    label: \"Density\"\n  },\n  x: {\n    label: \"Effect size estimate (Ti)\"\n  },   \n  marks: [\n    Plot.ruleY([0]),\n    Plot.ruleX([0]),\n    Plot.areaY(dat, {x: \"t\", y: \"d_unselected\", fillOpacity: 0.3}),\n    Plot.areaY(dat, {x: \"t\", y: \"d_selected\", fill: \"blue\", fillOpacity: 0.5}),\n    Plot.lineY(dat, {x: \"t\", y: \"d_selected\", stroke: \"blue\"})\n  ]\n})\n```\n\n\n:::: {.grid}\n\n:::{.g-col-4 .moments}\n \n\n```{ojs}\ntex`\n\\begin{aligned}\n\\Pr(O_i^* = 1) &= ${Ai_toprint} \\\\\n\\mu &= ${mu} \\\\\n\\mathbb{E}\\left(T_i\\right) &= ${ET_toprint} \\\\ \n\\eta_i &= ${eta_toprint} \\\\\n\\sqrt{\\mathbb{V}\\left(T_i\\right)} &= ${SDT_toprint}\n\\end{aligned}`\n```\n\n\n:::\n\n::: {.g-col-8 .center}\n\n\n```{ojs}\nPlot.plot({\n  height: 200,\n  width: 400,\n  y: {\n    grid: false,\n    label: \"Selection probability\"\n  },\n  x: {\n    label: \"p-value (one-sided)\"\n  },   \n  marks: [\n    Plot.ruleY([0]),\n    Plot.ruleX([0,1]),\n    Plot.areaY(selfundat, {x: \"p\", y: \"prob\", fill: \"green\", fillOpacity: 0.5}),\n    Plot.lineY(selfundat, {x: \"p\", y: \"prob\", stroke: \"green\"})\n  ]\n})\n```\n\n\n:::\n\n::::\n\n:::::\n\n::::: {.g-col-4}\n\n\n```{ojs}\n//| panel: input\n\nviewof mu = Inputs.range(\n  [-2, 2], \n  {value: 0.15, step: 0.01, label: tex`\\mu`}\n)\n\nviewof tau = Inputs.range(\n  [0, 2], \n  {value: 0.10, step: 0.01, label: tex`\\tau`}\n)\n\nviewof sigma = Inputs.range(\n  [0, 1], \n  {value: 0.20, step: 0.01, label: tex`\\sigma_i`}\n)\n\nviewof alpha1 = Inputs.range(\n  [0, 1],\n  {value: 0.025, step: 0.005, label: tex`\\alpha_1`}\n)\n\nviewof alpha2 = Inputs.range(\n  [0, 1],\n  {value: 0.975, step: 0.005, label: tex`\\alpha_2`}\n)\n\nviewof lambda1 = Inputs.range(\n  [0, 5],\n  {value: 0.60, step: 0.01, label: tex`\\lambda_1`}\n)\n\nviewof lambda2 = Inputs.range(\n  [0, 5],\n  {value: 0.90, step: 0.01, label: tex`\\lambda_2`}\n)\n\n```\n\n\n:::::\n\n::::::\n\n# Empirical example\n\n@Citkowicz2017parsimonious presented an example of a meta-analysis where applying the original form of the beta-density selection model led to dramatically different findings from the summary meta-analysis. The data come from a synthesis by @baskerville2012systematic that examined the effects of practice facilitation on the uptake of evidence-based practices (EBPs) in primary care settings. The original meta-analysis found a large average effect indicating that facilitation improves adoption of EBPs, although there were also indications of publication bias based on an Egger's regression test. Fitting the beta-density model leads to much smaller effects.\nHowever, @hedges2017plausibility criticized the beta-density results as involving an implausibly large degree of selection and noted that the estimated average effect is very sensitive to high-influence observations.\nDoes using a more strongly truncated beta density change this picture? I'll first work through the previously presented analyses, then examine how using truncation points for the beta density changes the picture.\n\n## Summary random effects model\n\nHere are the random effects meta-analysis results, estimated using maximum likelihood for consistency with subsequent modeling:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(metafor)\n\nBaskerville <- tribble(\n  ~ SMD, ~ V, ~ Blinded,\n  1.01,\t0.2704,\t'B',\n  0.82,\t0.2116,\t'O',\n  0.59,\t0.0529,\t'O',\n  0.44,\t0.0324,\t'O',\n  0.84,\t0.0841,\t'B',\n  0.73,\t0.0841,\t'O',\n  1.12,\t0.1296,\t'B',\n  0.04,\t0.1369,\t'B',\n  0.24,\t0.0225,\t'O',\n  0.32,\t0.1600,\t'O',\n  1.04,\t0.1024,\t'O',\n  1.31,\t0.3249,\t'B',\n  0.59,\t0.0841,\t'B',\n  0.66,\t0.0361,\t'O',\n  0.62,\t0.0961,\t'B',\n  0.47,\t0.0729,\t'B',\n  1.08,\t0.1024,\t'O',\n  0.98,\t0.1024,\t'B',\n  0.26,\t0.0324,\t'B',\n  0.39,\t0.0324,\t'B',\n  0.60,\t0.0961,\t'B',\n  0.94,\t0.2809,\t'B',\n  0.11,\t0.0729,\t'B'\n)\n\nRE_fit <- rma(yi = SMD, vi = V, data = Baskerville, method = \"ML\")\nRE_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRandom-Effects Model (k = 23; tau^2 estimator: ML)\n\ntau^2 (estimated amount of total heterogeneity): 0.0162 (SE = 0.0236)\ntau (square root of estimated tau^2 value):      0.1274\nI^2 (total heterogeneity / total variability):   18.64%\nH^2 (total variability / sampling variability):  1.23\n\nTest for Heterogeneity:\nQ(df = 22) = 27.5518, p-val = 0.1910\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.5552  0.0633  8.7751  <.0001  0.4312  0.6792  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nThe average effect estimate is $\\hat\\mu = 0.555$, with a 95% CI of $[0.431, 0.679]$. Here is a funnel plot of the effect size estimates against standard errors, with contours indicating regions of statistical significance for positive and negative estimates:\n\n::: {.cell}\n\n```{.r .cell-code}\nfunnel(RE_fit, refline = 0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=75%}\n:::\n:::\n\nThere's clearly asymmetry in the funnel plot, which can be an indication of selective reporting.\n\n## Original beta-density model\n\n@Citkowicz2017parsimonious fit the original form of the beta-density model to the data. This is now quite easy to do with the `metafor` package:\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_fit <- selmodel(RE_fit, type = \"beta\")\nbeta_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRandom-Effects Model (k = 23; tau^2 estimator: ML)\n\ntau^2 (estimated amount of total heterogeneity): 0.0000\ntau (square root of estimated tau^2 value):      0.0016\n\nTest for Heterogeneity:\nLRT(df = 1) = 0.0088, p-val = 0.9252\n\nModel Results:\n\nestimate      se    zval    pval    ci.lb   ci.ub    \n  0.1147  0.1664  0.6895  0.4905  -0.2114  0.4409    \n\nTest for Selection Model Parameters:\nLRT(df = 2) = 7.8469, p-val = 0.0198\n\nSelection Model Results:\n\n         estimate      se     zval    pval   ci.lb   ci.ub    \ndelta.1    0.4731  0.2352  -2.2397  0.0251  0.0120  0.9342  * \ndelta.2    4.4613  2.1842   1.5847  0.1130  0.1803  8.7423    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\nThe overall average effect size in the un-selected population is now estimated to be $\\hat\\mu = 0.115$, 95% CI $[-0.211, 0.441]$, with selection parameters (called $\\delta_1$ and $\\delta_2$ in metafor) estimated as $\\hat\\lambda_1 = 0.473$ and $\\hat\\lambda_2 = 4.461$. \n\nThe same model can also be fit using our `metaselection` package:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(metaselection)\nBaskerville$se <- sqrt(Baskerville$V)\nBaskerville$pi <- with(Baskerville, pnorm(SMD / se, lower.tail = FALSE))\n\nbeta_sel <- selection_model(\n  data = Baskerville,\n  yi = SMD,\n  sei = se,\n  selection_type = \"beta\",\n  steps = c(1e-5, 1 - 1e-5),\n  vcov_type = \"model-based\",\n  theta = c(0.55, log(0.0162), 0, 0)\n)\n\nsummary(beta_sel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBeta Density Model \n \nCall: \nselection_model(data = Baskerville, yi = SMD, sei = se, selection_type = \"beta\", \n    steps = c(1e-05, 1 - 1e-05), vcov_type = \"model-based\", theta = c(0.55, \n        log(0.0162), 0, 0))\n\nNumber of effects = 23\n\nSteps: 1e-05, 0.99999 \nEstimator: maximum likelihood \nVariance estimator: model-based \n\nLog composite likelihood of selection model: -2.79229\n\nMean effect estimates:                                        \n                            Large Sample\n Coef. Estimate Std. Error  Lower  Upper\n  beta    0.115      0.166 -0.211   0.44\n\nHeterogeneity estimates:                                            \n                              Large   Sample\n Coef. Estimate Std. Error    Lower    Upper\n  tau2 3.61e-11   1.25e-20 3.61e-11 3.61e-11\n\nSelection process estimates:                                          \n                              Large Sample\n    Coef. Estimate Std. Error Lower  Upper\n lambda_1    0.473      0.235 0.179   1.25\n lambda_2    4.461      2.184 1.709  11.65\n```\n\n\n:::\n:::\n\nI will stick with the `metaselection` package for subsequent analysis because it allows the user to specify their own truncation points for the beta-density model. It also has some helper functions such as `selection_plot()` for graphing the estimated selection function:\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_plot(beta_sel)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=70%}\n:::\n:::\n\n\n## Hedges' critiques\n\n::: {.column-margin}\n\n::: {#tbl-selection-probs .cell tbl-cap='Probabilities of selection relative to $\\text{Pr}(O_i = 1 \\vert p_i = .0005)$'}\n::: {.cell-output-display}\n\n\n| $p_i$| $\\text{Pr}(O_i = 1 \\vert p_i)$|\n|-----:|------------------------------:|\n| 0.001|                          0.693|\n| 0.005|                          0.293|\n| 0.010|                          0.200|\n| 0.025|                          0.117|\n| 0.050|                          0.074|\n| 0.100|                          0.043|\n| 0.500|                          0.002|\n\n\n:::\n:::\n\n:::\n\n@hedges2017plausibility noted that the beta-density model for these data generates very extreme selection probabilities. Following along with his numerical example, @tbl-selection-probs reports the probability of observing effects for several different $p$-values, relative to the probability of observing a highly significant effect with $p = .0005$.\nNotably, based on the estimated selection function, an effect with one-sided $p_i = .0005$ is over eight times more likely to be reported than an effect with $p = .025$ and nearly 500 times more likely to be reported than an effect of zero with $p_i = .500$. Quoth @hedges2017plausibility: \"This seems like an extraordinarily high degree of selection\" (p. 43).\n\nHedges goes on to explain how the estimated selection parameters can be used to infer the total number of effect sizes that would need to be _generated_ in order to obtain a sample of $k = 23$ observed effect sizes. The calculation involves the quantity \n$$\nA_i = \\text{Pr}(O_i^* = 1 | \\sigma_i^*) = \\text{E}\\left[\\left.\\Pr\\left(O_i^* = 1| p_i^*\\right) \\right| \\sigma_i^*\\right],\n$$\nwhich is the overall probability of observing an effect size estimate in a study with standard error $\\sigma_i^*$.[^Hedges-notation]\nThe inverse of $A_i$ is the expected number of effect size estimates that would need to be generated (including both observed and unobserved) in order to obtain one observed estimate. \nEstimates of $A_i$ can be computed given the parameter estimates $\\hat\\mu$, $\\hat\\tau$, $\\hat\\lambda_1$, $\\hat\\lambda_2$. These are reported in \nTaking the sum across the sample of observed effect sizes, we can find an estimate of the number of effect sizes that would need to be generated:\n$$\nk_{generated} = \\sum_{i=1}^{k} \\frac{1}{\\hat{A}_i}.\n$$\n\nIn the Baskerville data and using the beta-density parameter estimates obtained from meta-selection, I find \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n              p           wt       wt_14     inv_sel        Ai     Ai_inv\n1  0.0260499312 0.0144764348 0.080093512   69.077782  7.627772 0.13109989\n2  0.0373250117 0.0115044362 0.063650389   86.922990  8.010013 0.12484374\n3  0.0051555590 0.0365793246 0.202381775   27.337848 12.193200 0.08201293\n4  0.0072537711 0.0303342933 0.167830002   32.965990 15.368417 0.06506851\n5  0.0018864422 0.0628368433 0.347656280   15.914230 10.254220 0.09752083\n6  0.0059138884 0.0339382576 0.187769591   29.465272 10.254220 0.09752083\n7  0.0009319240 0.0914136775 0.505762819   10.939282  9.007062 0.11102399\n8  0.4569549683 0.0004237456 0.002344449 2359.906763  8.876900 0.11265194\n9  0.0547992917 0.0088198518 0.048797437  113.380589 19.000341 0.05263063\n10 0.2118553986 0.0023062307 0.012759641  433.607961  8.534442 0.11717228\n11 0.0005770250 0.1178233521 0.651879154    8.487282  9.633389 0.10380562\n12 0.0107739070 0.0243261656 0.134588942   41.107999  7.380586 0.13549059\n13 0.0209514726 0.0165328351 0.091470921   60.485694 10.254220 0.09752083\n14 0.0002566824 0.1807441631 1.000000000    5.532682 14.532336 0.06881206\n15 0.0227501319 0.0157303197 0.087030858   63.571499  9.822971 0.10180220\n16 0.0408645168 0.0108292426 0.059914757   92.342562 10.772007 0.09283322\n17 0.0003690785 0.1492094741 0.825528590    6.701987  9.633389 0.10380562\n18 0.0010974824 0.0838195811 0.463747098   11.930387  9.633389 0.10380562\n19 0.0743069982 0.0069892837 0.038669485  143.076177 15.368417 0.06506851\n20 0.0151301400 0.0200328442 0.110835359   49.918024 15.368417 0.06506851\n21 0.0264654730 0.0143350412 0.079311226   69.759130  9.822971 0.10180220\n22 0.0380659181 0.0113556105 0.062826983   88.062197  7.573945 0.13203159\n23 0.3418543937 0.0009604306 0.005313757 1041.199635 10.772007 0.09283322\n```\n\n\n:::\n:::\n\n\n\n[^Hedges-notation]: @hedges2017plausibility denotes this quantity $g_i(T_i)$.\n\n\n- inverse selection weights\n\n## Sensitivity to truncation points",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}