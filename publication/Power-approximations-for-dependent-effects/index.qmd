---
title: Power approximations for overall average effects in meta-analysis of dependent
  effect sizes
authors:
- Mikkel H. Vembye
- admin
- Terri D. Pigott
date: 2022-10-17T00:00:00
publish_date: 2022-10-17T00:00:00
publication_type: Journal article
publication: _Journal of Educational and Behavioral Statistics, 48_(1), 70-102
categories:
- power
- meta-analysis
- dependent effect sizes
- robust variance estimation
image: Power difference between approximated and true (simulated) power versus approximated
  power for the C(H)E working models, across different methods of sampling study characteristics.
links:
- text: Journal
  url: https://doi.org/10.3102/10769986221127379
  icon: fa newspaper
- text: Supplementary materials
  url: https://osf.io/q84dv/
- text: R package
  url: https://mikkelvembye.github.io/POMADE/
  icon: fa gift
- icon: fa lock-open
  text: Pre-Print
  url: https://osf.io/preprints/metaarxiv/6tp9y/
- icon: fa code
  text: Code
  url: https://osf.io/yhkq4/

---
{{< include '../_publication_header.qmd' >}}


Meta-analytic models for dependent effect sizes have grown increasingly sophisticated over the last few decades, which has created challenges for a priori power calculations. We introduce power approximations for tests of average effect sizes based upon several common approaches for handling dependent effect sizes. In a Monte Carlo simulation, we show that the new power formulas can accurately approximate the true power of meta-analytic models for dependent effect sizes. Lastly, we investigate the Type I error rate and power for several common models, finding that tests using robust variance estimation provide better Type I error calibration than tests with model-based variance estimation. We consider implications for practice with respect to selecting a working model and an inferential approach.

