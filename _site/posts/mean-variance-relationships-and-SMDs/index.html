<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-11-02">
<meta name="description" content="A question came up on the R-SIG-meta-analysis listserv about whether it was reasonable to use the standardized mean difference metric for synthesizing studies where the outcomes are measured as proportions. I think this is an interesting question because, while the SMD could work perfectly fine as an effect size metric for proportions, there are also other alternatives that could be considered, such as odds ratios or response ratios or raw differences in proportions. Further, there are some situations where the SMD has disadvantages for synthesizing contrasts between proportions. Thus, it’s a situation where one has to make a choice about the effect size metric, and where the most common metric (the SMD) might not be the right answer. In this post, I want to provide a bit more detail regarding why I think mean-variance relationships in raw data can signal that the standardized mean differences might be less useful as an effect size metric compared to alternatives.">

<title>James E. Pustejovsky - Implications of mean-variance relationships for standardized mean differences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">James E. Pustejovsky</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../presentations.html"> 
<span class="menu-text">Presentations</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../people.html"> 
<span class="menu-text">People</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Implications of mean-variance relationships for standardized mean differences</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          A question came up on the R-SIG-meta-analysis listserv about whether it was reasonable to use the standardized mean difference metric for synthesizing studies where the outcomes are measured as proportions. I think this is an interesting question because, while the SMD could work perfectly fine as an effect size metric for proportions, there are also other alternatives that could be considered, such as odds ratios or response ratios or raw differences in proportions. Further, there are some situations where the SMD has disadvantages for synthesizing contrasts between proportions. Thus, it’s a situation where one has to make a choice about the effect size metric, and where the most common metric (the SMD) might not be the right answer. In this post, I want to provide a bit more detail regarding why I think mean-variance relationships in raw data can signal that the standardized mean differences might be less useful as an effect size metric compared to alternatives.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">standardized mean difference</div>
                <div class="quarto-category">response ratio</div>
                <div class="quarto-category">distribution theory</div>
                <div class="quarto-category">meta-analysis</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>admin </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 2, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>I spend more time than I probably should discussing meta-analysis problems on the <a href="https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis">R-SIG-meta-analysis listserv</a>. The questions that folks pose there are often quite interesting—especially when they’re motivated by issues that they’re wrestling with while trying to complete meta-analysis projects in their diverse fields. For those interested in meta-analytic methodology, I think perusing the mailing list is a good way to get a bit of ground sense about problems that come up in practice and places where there is a need for new methodological work, or at least further methodological guidance.</p>
<p>Recently, a <a href="https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003318.html">question came up</a> on the listserv about whether it was reasonable to use the standardized mean difference metric for synthesizing studies where the outcomes are measured as proportions. Luke Martinez wrote:</p>
<blockquote class="blockquote">
<p>I’m doing a meta-analysis where the papers report only “mean” and “sd” of some form of proportion and/or “mean” and “sd” of corresponding raw frequencies. (For context, the papers ask students to read, find, and correct the wrong words in a text.) … My question is given that all these studies only report “mean” and “sd”, can I simply use a SMD effect size?</p>
</blockquote>
<p>I think this is an interesting question because, while the <a href="https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003320.html">SMD could work perfectly fine</a> as an effect size metric for proportions, there are also other alternatives that could be considered, such as odds ratios or response ratios or raw differences in proportions. Further, there are some situations where the SMD has disadvantages for synthesizing contrasts between proportions. Thus, it’s a situation where one has to make a choice about the effect size metric, and where the most common metric (the SMD) might not be the right answer. As <a href="https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003331.html">I wrote in reply</a>:</p>
<blockquote class="blockquote">
<p>I would suggest that you could also consider other effect measures besides the SMD. For example, the response ratio is also a scale-free metric that could work with the proportion outcomes that you’ve described, and would also be appropriate for raw frequency counts as long as the total number possible is the same for the groups being compared within a given study.</p>
<p>Whether the response ratio would be more appropriate than the SMD is hard to gauge. One would need to know more about how the proportions were assessed and how the assessment procedures varied from study to study. For instance, did some studies use passages with many possible errors to be corrected while other studies used passages with just a few errors? Did the difficulty of the passages differ from study to study? Were there very low or very high mean proportions in any studies? Does there seem to be a relationship between the means and the variances of the proportions of a given group?</p>
</blockquote>
<p>In a <a href="https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003361.html">follow-up</a>, I elaborated on some potential problems with using the SMD:</p>
<blockquote class="blockquote">
<ul>
<li><p>Variation in the number of possible errors (and perhaps also in the length of the time provided for the test?) suggests that the measures from different studies may have varying degrees of reliability. Varying reliability introduces heterogeneity in the SMD (because the denominator is inflated or shrunk by the degree of reliability).</p></li>
<li><p>A relationship between the M and SD of the proportions for a given group suggests that the distribution of the individual-level outcomes might also exhibit mean-variance relationships. (I say “suggests” rather than implies because there’s an ecological inference here, i.e., assuming something about individual-level variation on the basis of group-level variation.) If this supposition is reasonable, then that introduces a further potential source of heterogeneity in the SMDs (study-to-study variation in the M for the reference group influences the SD of the reference group, thereby inflating or shrinking the SMDs).</p></li>
</ul>
</blockquote>
<p>And I suggested a possible work-flow for examining the choice of effect size metric:</p>
<blockquote class="blockquote">
<p>Here’s how I might proceed if I were conducting this analysis:</p>
<ol type="1">
<li>Calculate <em>both</em> SMDs and log-transformed response ratios for the full set of studies.</li>
<li>Examine the distribution of effect size estimates for each metric (using histograms or funnel plots). If one of the distributions is skewed or has extreme outliers, take that as an indication that the metric might not be appropriate.</li>
<li>Fit meta-analytic models to summarize the distribution of effect sizes in each metric, using a model that appropriately describes the dependence structure of the estimates. Calculate I-squared statistics, give preference to the metric with lower I-squared.</li>
<li>If (2) and (3) don’t lead to a clearly preferable metric, then choose between SMD and RR based on whichever will make the synthesis results easier to explain to people.</li>
<li>(Optional/extra credit) Whichever metric you choose, repeat your main analyses using the other metric and stuff all those results in supplementary materials, to satisfy any inveterate statistical curmudgeons who might review/read your synthesis.</li>
</ol>
</blockquote>
<p>(When I referred to “inveterate statistical curmudgeons”, I mostly had myself in mind.)</p>
<p>In this post, I want to provide a bit more detail regarding why I think mean-variance relationships in raw data can signal that the standardized mean differences might be less useful as an effect size metric compared to alternatives. The concern is actually broader than meta-analyses of outcomes measured as proportions, so I’ll start with a different case and then return to a situation similar to the one described in the original question.</p>
<section id="mean-variance-relationships-can-induce-heterogeneity" class="level2">
<h2 class="anchored" data-anchor-id="mean-variance-relationships-can-induce-heterogeneity">Mean-variance relationships can induce heterogeneity</h2>
<p>The standardized mean difference parameter for a given study can be defined as: <span class="math display">\[
\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sigma_{Ai}},
\]</span> where <span class="math inline">\(\mu_{Ai}\)</span> and <span class="math inline">\(\mu_{Bi}\)</span> are the (population) mean outcomes in group <span class="math inline">\(A\)</span> and group <span class="math inline">\(B\)</span> of study <span class="math inline">\(i\)</span> and <span class="math inline">\(\sigma_{Ai}\)</span> is the (population) standard deviation in group <span class="math inline">\(A\)</span> of study <span class="math inline">\(i\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> The ideal case for using the SMD metric is when the outcomes in different studies are linearly equatable, so that the outcome scale in one study can be directly translated into the outcome scale of another study. However, if outcomes exhibit mean-variance relationships, linearly equatability seems rather implausible, and we might expect that SMDs will display heterogeneity across studies as a result.</p>
<p>Let me lay out an example of a situation where the outcomes exhibit mean-variance relationships and where, as a consequence, the SMD metric becomes heterogeneous. Suppose that we have <span class="math inline">\(k\)</span> studies, each involving a two-group comparison, with groups of equal size. In study <span class="math inline">\(i\)</span>, the outcomes in group <span class="math inline">\(A\)</span> follow a poisson distribution with mean <span class="math inline">\(\mu_{Ai}\)</span>, so that the variance of the outcomes in group <span class="math inline">\(A\)</span> is also <span class="math inline">\(\mu_{Ai}\)</span>, for <span class="math inline">\(i = 1,...,k\)</span>. The outcomes in group <span class="math inline">\(B\)</span> follow a poisson distribution with mean <span class="math inline">\(\mu_{Bi}\)</span>, so the variance is also <span class="math inline">\(\mu_{Bi}\)</span>. Now, suppose that there is a fixed, proportional relationship between <span class="math inline">\(\mu_{Bi}\)</span> and <span class="math inline">\(\mu_{Ai}\)</span>, so that <span class="math inline">\(\mu_{Bi} = \lambda \mu_{Ai}\)</span> for some <span class="math inline">\(\lambda &gt; 0\)</span>. In other words, the treatment contrast is <em>constant</em> on the scale of the response ratio. However, the means in group <span class="math inline">\(A\)</span> vary from study to study. To make things concrete, let’s assume that the means in group <span class="math inline">\(A\)</span> follow a gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and rate parameter <span class="math inline">\(\beta\)</span>: <span class="math display">\[
\mu_{Ai} \sim \Gamma(\alpha, \beta).
\]</span> What does this model imply about the distribution of standardized mean differences across this set of studies?</p>
<p>Under this model, the SMD parameter for study <span class="math inline">\(i\)</span> is: <span class="math display">\[
\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sqrt{\mu_{Ai}}} = (\lambda - 1) \times \sqrt{\mu_{Ai}}.
\]</span> The first term in the above expression is a constant that only depend on the size of the response ratio, but the second term is random because we have assumed that the group <span class="math inline">\(A\)</span> means vary from study to study. It will therefore create heterogeneity in the SMD parameters—the greater the variance of the <span class="math inline">\(\mu_{Ai}\)</span>’s, the greater the heterogeneity in <span class="math inline">\(\delta_i\)</span>. Specifically, under the above assumptions, the effect size parameters follow a <a href="https://en.wikipedia.org/wiki/Nakagami_distribution">Nakagami distribution</a>: <span class="math display">\[
\delta_i \sim \text{Nakagami}\left(m = \alpha, \Omega = \frac{(\lambda - 1)^2 \alpha}{\beta}\right)
\]</span> Thus, even though we have a model where there is an underlying fixed relationship between <span class="math inline">\(\mu_{Ai}\)</span> and <span class="math inline">\(\mu_{Bi}\)</span>, using the SMD metric for synthesis will lead to a situation with heterogeneous effects (even if all of the studies had large sample sizes and so effect sizes in individual studies are precisely estimated).</p>
</section>
<section id="an-example-with-proportions" class="level2">
<h2 class="anchored" data-anchor-id="an-example-with-proportions">An example with proportions</h2>
<p>This sort of behavior is not restricted to the poisson-gamma model I sketched above. The key features of that example are a) the assumption that the outcomes have a strong mean-variance relationship and b) the assumption that the <span class="math inline">\(\mu_{Ai}\)</span>’s are heterogeneous across studies. If both of these hold, then the resulting SMDs will also be heterogeneous. I’ll now describe a similar model, but where the outcomes within each study are proportions.</p>
<p>As before, suppose that we have <span class="math inline">\(k\)</span> studies, each involving a two-group comparison, with groups of equal size. In study <span class="math inline">\(i\)</span>, the outcomes in group <span class="math inline">\(A\)</span> follow a binomial distribution with mean proportion <span class="math inline">\(\pi_{Ai}\)</span> and <span class="math inline">\(T_i\)</span> trials, so that the variance of the outcomes in group <span class="math inline">\(A\)</span> is <span class="math inline">\(\pi_{Ai}\left(1 - \pi_{Ai}\right) T_i\)</span>, for <span class="math inline">\(i = 1,...,k\)</span>. The outcomes in group <span class="math inline">\(B\)</span> also follow a binomial distribution, this one with mean proportion <span class="math inline">\(\pi_{Bi}\)</span> and <span class="math inline">\(T_i\)</span> trials, so the variance is <span class="math inline">\(\pi_{Bi}\left(1 - \pi_{Bi}\right) T_i\)</span>. Next, to induce variation in the group-<span class="math inline">\(A\)</span> means, let’s assume that the mean proportions follow a beta distribution: <span class="math display">\[
\pi_{Ai} \sim \text{Beta}(\alpha, \beta).
\]</span></p>
<p>Finally, suppose that <span class="math inline">\(\pi_{Bi} = \lambda_i \pi_{Ai}\)</span> for some <span class="math inline">\(\lambda_i &gt; 0\)</span>.</p>
<p>Under these assumptions, the SMD parameter for study <span class="math inline">\(i\)</span> is: <span class="math display">\[
\delta_i = \frac{\pi_{Bi}T_i - \pi_{Ai} T_i}{\sqrt{\pi_{Ai} (1 - \pi_{Ai}) T_i}} = (\lambda_i - 1) \times \sqrt{T_i} \times \sqrt{\frac{\pi_{Ai}}{1 - \pi_{Ai}}}.
\]</span> From the above expression, it can be seen that there are three potential sources of variation in <span class="math inline">\(\delta_i\)</span>: variation in the study-specific response ratio <span class="math inline">\(\lambda_i\)</span>, variation in the group-<span class="math inline">\(A\)</span> proportions <span class="math inline">\(\pi_{Ai}\)</span>, and variation in the number of trials <span class="math inline">\(T_i\)</span>. The total heterogeneity in <span class="math inline">\(\delta_i\)</span> will depend on all three, as well as on the co-variation between <span class="math inline">\(\lambda_i\)</span>, <span class="math inline">\(\pi_{Ai}\)</span>, and <span class="math inline">\(T_i\)</span>.</p>
<p>To make this concrete, let me simulate some meta-analytic data that follows the above model. To do so, I’ll need to make some additional distributional assumptions<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<ol type="1">
<li>that <span class="math inline">\(\lambda_i\)</span> is log-normally distributed such that <span class="math inline">\(\ln \lambda_i \sim N(\ln \Lambda, \tau^2)\)</span>;</li>
<li>that the number of trials is uniformly distributed on the integers between <span class="math inline">\(t_{min}\)</span> and <span class="math inline">\(t_{max}\)</span>;</li>
<li>that <span class="math inline">\(N_i\)</span>, the number of observations per group in study <span class="math inline">\(i\)</span>, is uniformly distributed on the integers between <span class="math inline">\(n_{min}\)</span> and <span class="math inline">\(n_{max}\)</span>; and</li>
<li>that <span class="math inline">\(\pi_{Ai}\)</span>, <span class="math inline">\(\lambda_i\)</span>, <span class="math inline">\(T_i\)</span>, and <span class="math inline">\(N_i\)</span> are mutually independent.</li>
</ol>
<p>Here’s a function that generates study-specific parameter values and sample proportions:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>sim_binom_summary <span class="ot">&lt;-</span> <span class="cf">function</span>(pi_i, T_i, n_i) {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_i, <span class="at">size =</span> T_i, <span class="at">prob =</span> pi_i) <span class="sc">/</span> T_i</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">M =</span> <span class="fu">mean</span>(y), <span class="at">SD =</span> <span class="fu">sd</span>(y))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>sim_props <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  k, <span class="co"># number of studies</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  alpha, beta, <span class="co"># parameters of pi_Ai distribution,</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  Lambda, tau, <span class="co"># parameters of lambda_i distribution</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  t_min, t_max, <span class="co"># parameters of T_i distribution</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  n_min, n_max <span class="co"># parameters of the sample size distribution</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>) {</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simulate parameters</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  pi_Ai <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(k, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  lambda_i <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(k, <span class="at">mean =</span> <span class="fu">log</span>(Lambda), <span class="at">sd =</span> tau))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  pi_Bi <span class="ot">&lt;-</span> lambda_i <span class="sc">*</span> pi_Ai</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  T_i <span class="ot">&lt;-</span> <span class="fu">sample</span>(t_min<span class="sc">:</span>t_max, <span class="at">size =</span> k, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  delta_i <span class="ot">&lt;-</span> (pi_Bi <span class="sc">-</span> pi_Ai) <span class="sc">*</span> T_i <span class="sc">/</span> <span class="fu">sqrt</span>(pi_Ai <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> pi_Ai) <span class="sc">*</span> T_i)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  n_i <span class="ot">&lt;-</span> <span class="fu">sample</span>(n_min<span class="sc">:</span>n_max, <span class="at">size =</span> k, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simulate data</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  stats_A <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">pmap_dfr</span>(<span class="fu">list</span>(<span class="at">pi_i =</span> pi_Ai, <span class="at">T_i =</span> T_i, <span class="at">n_i =</span> n_i),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                             sim_binom_summary) </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                             </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  stats_B <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">pmap_dfr</span>(<span class="fu">list</span>(<span class="at">pi_i =</span> pi_Bi, <span class="at">T_i =</span> T_i, <span class="at">n_i =</span> n_i),</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                             sim_binom_summary)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compile</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">pi_Ai =</span> pi_Ai, <span class="at">pi_Bi =</span> pi_Bi, </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">lambda_i =</span> lambda_i, <span class="at">T_i =</span> T_i, </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">delta_i =</span> delta_i, <span class="at">n_i =</span> n_i,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">mA =</span> stats_A<span class="sc">$</span>M, <span class="at">sdA =</span> stats_A<span class="sc">$</span>SD,</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">mB =</span> stats_B<span class="sc">$</span>M, <span class="at">sdB =</span> stats_B<span class="sc">$</span>SD</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># effect size calculations</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> metafor<span class="sc">::</span><span class="fu">escalc</span>(</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> res, <span class="at">measure =</span> <span class="st">"ROM"</span>, <span class="at">var.names =</span> <span class="fu">c</span>(<span class="st">"lRR"</span>, <span class="st">"V_lRR"</span>),</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">m1i =</span> mB, <span class="at">m2i =</span> mA, </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd1i =</span> sdB, <span class="at">sd2i =</span> sdA,</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">n1i =</span> n_i, <span class="at">n2i =</span> n_i</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> metafor<span class="sc">::</span><span class="fu">escalc</span>(</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> res, <span class="at">measure =</span> <span class="st">"SMD"</span>, <span class="at">var.names =</span> <span class="fu">c</span>(<span class="st">"d"</span>, <span class="st">"V_d"</span>),</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">m1i =</span> mB, <span class="at">m2i =</span> mA, </span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd1i =</span> sdB, <span class="at">sd2i =</span> sdA,</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">n1i =</span> n_i, <span class="at">n2i =</span> n_i</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>  res</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20211024</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">sim_props</span>(<span class="at">k =</span> <span class="dv">60</span>, <span class="at">alpha =</span> <span class="dv">12</span>, <span class="at">beta =</span> <span class="dv">4</span>, </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>                 <span class="at">Lambda =</span> <span class="fl">0.7</span>, <span class="at">tau =</span> .<span class="dv">05</span>,</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>                 <span class="at">t_min =</span> <span class="dv">5</span>, <span class="at">t_max =</span> <span class="dv">18</span>,</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>                 <span class="at">n_min =</span> <span class="dv">10</span>, <span class="at">n_max =</span> <span class="dv">40</span>)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
      pi_Ai     pi_Bi  lambda_i T_i    delta_i n_i        mA       sdA 
1 0.7584480 0.5836965 0.7695933  11 -1.3540950  24 0.7500000 0.1080650 
2 0.7359047 0.4950740 0.6727420  16 -2.1851474  24 0.7786458 0.1222235 
3 0.7132014 0.4773027 0.6692398  12 -1.8068471  10 0.7333333 0.1097134 
4 0.6223653 0.4627406 0.7435193   9 -0.9877857  30 0.6666667 0.1399386 
5 0.5916619 0.4205407 0.7107787   6 -0.8527716  28 0.5833333 0.2103299 
6 0.7266748 0.5014601 0.6900751   9 -1.5160305  35 0.7619048 0.1209466 
         mB       sdB     lRR  V_lRR       d    V_d 
1 0.6174242 0.1285066 -0.1945 0.0027 -1.0983 0.0959 
2 0.5260417 0.1275776 -0.3922 0.0035 -1.9888 0.1245 
3 0.3583333 0.1622089 -0.7161 0.0227 -2.5934 0.3681 
4 0.4555556 0.1943213 -0.3808 0.0075 -1.2306 0.0793 
5 0.4583333 0.2060055 -0.2412 0.0119 -0.5921 0.0746 
6 0.4920635 0.1793349 -0.4372 0.0045 -1.7447 0.0789 </code></pre>
</div>
</div>
<p>For the specified parameter values, there is only a small amount of true heterogeneity in the log of the response ratios (the blue density). Of course, there is further heterogeneity in the log response ratio estimates (the green density) due to sampling error:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat) <span class="sc">+</span> </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="fu">log</span>(lambda_i), ..scaled..), <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(lRR, ..scaled..), <span class="at">fill =</span> <span class="st">"green"</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span> </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>A random effects meta-analysis confirms that there is only a modest degree of true heterogeneity in the log response ratios:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(metafor)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(<span class="at">yi =</span> lRR, <span class="at">vi =</span> V_lRR, <span class="at">data =</span> dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Random-Effects Model (k = 60; tau^2 estimator: REML)

tau^2 (estimated amount of total heterogeneity): 0.0028 (SE = 0.0013)
tau (square root of estimated tau^2 value):      0.0529
I^2 (total heterogeneity / total variability):   42.01%
H^2 (total variability / sampling variability):  1.72

Test for Heterogeneity:
Q(df = 59) = 100.6304, p-val = 0.0006

Model Results:

estimate      se      zval    pval    ci.lb    ci.ub      
 -0.3498  0.0111  -31.5751  &lt;.0001  -0.3715  -0.3281  *** 

---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Contrast this with what we get from using the standardized mean difference metric. The distributions of true effect sizes (blue) and of effect size estimates (light purple) have large spread as well as strong left skew:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat) <span class="sc">+</span> </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(delta_i, ..scaled..), <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span> </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(d, ..scaled..), <span class="at">fill =</span> <span class="st">"purple"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>A random effects meta-analysis of the standardized mean differences shows a greater degree of true heterogeneity, both in terms of the estimated <span class="math inline">\(\tau\)</span> and in <span class="math inline">\(I^2\)</span>, or the proportion of total variance in the effect size estimates that is attributable to true heterogeneity:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(<span class="at">yi =</span> d, <span class="at">vi =</span> V_d, <span class="at">data =</span> dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Random-Effects Model (k = 60; tau^2 estimator: REML)

tau^2 (estimated amount of total heterogeneity): 0.2838 (SE = 0.0743)
tau (square root of estimated tau^2 value):      0.5327
I^2 (total heterogeneity / total variability):   72.61%
H^2 (total variability / sampling variability):  3.65

Test for Heterogeneity:
Q(df = 59) = 203.0513, p-val &lt; .0001

Model Results:

estimate      se      zval    pval    ci.lb    ci.ub      
 -1.5967  0.0824  -19.3771  &lt;.0001  -1.7582  -1.4352  *** 

---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section>
<section id="diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="diagnostics">Diagnostics</h2>
<p>The code above more-or-less implements the workflow I suggested for deciding between the standardized mean difference or response ratio metric (for proportions, we could also add further comparisons with log odds ratios and with raw differences in proportions). But is there further diagnostic information in the data that could provide a better sense of what is going on? I think there are a few things that might be helpful to consider.</p>
<p>First, the issues I’m concerned with here will arise when there are mean-variance relationships in the outcomes. To get at that, we can simply plot the means and SDs of each group. In the code below, I re-structure the data so that there is one row per group per study. I then plot the SD versus the mean of each group:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>long_summary_stats <span class="ot">&lt;-</span> </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  dat <span class="sc">%&gt;%</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(n_i, T_i, mA, sdA, mB, sdB) <span class="sc">%&gt;%</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(mA, sdA, mB, sdB), </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="fu">c</span>(<span class="st">".value"</span>,<span class="st">"group"</span>),</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_pattern =</span> <span class="st">"(m|sd)(A|B)"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(long_summary_stats,</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(m, sd, <span class="at">color =</span> group)) <span class="sc">+</span> </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span> </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand_limits</span>(<span class="at">y =</span> <span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p>The plot above does suggest a mean-variance relationship, though it’s a bit messy. We can do better by using the scaled SD, after adjusting for the degree of spread that we would expect given <span class="math inline">\(T_i\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>long_summary_stats <span class="sc">%&gt;%</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd_scaled =</span> sd <span class="sc">*</span> <span class="fu">sqrt</span>(T_i)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(m, sd_scaled, <span class="at">color =</span> group)) <span class="sc">+</span> </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">sqrt</span>(x <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> x)),</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span> </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span> </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand_limits</span>(<span class="at">y =</span> <span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p>From the above, it does appear that there could be a relationship between the scaled SD and the mean. The black curve indicates the theoretical mean-variance relationship that would be expected under the binomial distribution, and indeed the empirical relationship appears to be quite similar. This suggests that mean-variance relationships might be at play (a correct supposition, since of course we know the true data-generating process here).</p>
<p>Second, since the outcomes in each group are all proportions, we can simply plot the mean in group <span class="math inline">\(B\)</span> versus the mean in group <span class="math inline">\(A\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(mA, mB)) <span class="sc">+</span> </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span> </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">expand =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p>This plot shows that there is a strong linear relationship between the two means, with a best-fit line that might go through the origin. This suggests that the response ratio might be an appropriate metric (although the difference in proportions might also be appropriate here, since a line with unit slope would probably fit quite well).</p>
<p>Third (and most speculatively/hand-wavily), I think exploratory moderator analysis can be useful here, but interpreted in a non-typical way. Under the model I’ve sketched, we would expect that the standardized mean difference estimates should be systematically associated with the group-<span class="math inline">\(A\)</span> means, as well as with the number of trials used to assess outcomes. The scatter-plots below show that this is indeed the case (the right-hand plot shows <span class="math inline">\(d_i\)</span> versus <span class="math inline">\(\sqrt{T_i}\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>mA_d_plot <span class="ot">&lt;-</span> </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(mA, d)) <span class="sc">+</span> </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>) <span class="sc">+</span> </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span> </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>Ti_d_plot <span class="ot">&lt;-</span> </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(<span class="fu">sqrt</span>(T_i), d)) <span class="sc">+</span> </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>) <span class="sc">+</span> </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>mA_d_plot <span class="sc">+</span> Ti_d_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>This impression is also born out by a meta-regression that includes the group-<span class="math inline">\(A\)</span> means and <span class="math inline">\(\sqrt{T_i}\)</span> as moderators:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(d <span class="sc">~</span> mA <span class="sc">+</span> <span class="fu">sqrt</span>(T_i), <span class="at">vi =</span> V_d, <span class="at">data =</span> dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Mixed-Effects Model (k = 60; tau^2 estimator: REML)

tau^2 (estimated amount of residual heterogeneity):     0.0238 (SE = 0.0238)
tau (square root of estimated tau^2 value):             0.1544
I^2 (residual heterogeneity / unaccounted variability): 18.12%
H^2 (unaccounted variability / sampling variability):   1.22
R^2 (amount of heterogeneity accounted for):            91.60%

Test for Residual Heterogeneity:
QE(df = 57) = 68.9706, p-val = 0.1330

Test of Moderators (coefficients 2:3):
QM(df = 2) = 110.9125, p-val &lt; .0001

Model Results:

           estimate      se     zval    pval    ci.lb    ci.ub      
intrcpt      2.5225  0.3964   6.3632  &lt;.0001   1.7455   3.2995  *** 
mA          -2.8326  0.4336  -6.5321  &lt;.0001  -3.6825  -1.9827  *** 
sqrt(T_i)   -0.6109  0.0756  -8.0855  &lt;.0001  -0.7590  -0.4628  *** 

---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Here are the same plots as above, but using the log of the response ratio as the effect size metric:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>mA_lRR_plot <span class="ot">&lt;-</span> </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(mA, lRR)) <span class="sc">+</span> </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>) <span class="sc">+</span> </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span> </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>Ti_lRR_plot <span class="ot">&lt;-</span> </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(dat, <span class="fu">aes</span>(<span class="fu">sqrt</span>(T_i), lRR)) <span class="sc">+</span> </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"green"</span>) <span class="sc">+</span> </span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>) <span class="sc">+</span> </span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>mA_lRR_plot <span class="sc">+</span> Ti_lRR_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>In the left-hand plot, there does not appear to be any relationship between the effect size estimates and the group-<span class="math inline">\(A\)</span> means. In the right-hand plot, there does seem to be a mild relationship between the effect size estimates and <span class="math inline">\(\sqrt{T_i}\)</span>, which is a bit surprising, although the strength of the relationship is much weaker than what we saw with the standardized mean differences. Meta-regression analysis supports these interpretations:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(lRR <span class="sc">~</span>  mA <span class="sc">+</span> <span class="fu">sqrt</span>(T_i), <span class="at">vi =</span> V_lRR, <span class="at">data =</span> dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Mixed-Effects Model (k = 60; tau^2 estimator: REML)

tau^2 (estimated amount of residual heterogeneity):     0.0019 (SE = 0.0011)
tau (square root of estimated tau^2 value):             0.0439
I^2 (residual heterogeneity / unaccounted variability): 32.87%
H^2 (unaccounted variability / sampling variability):   1.49
R^2 (amount of heterogeneity accounted for):            31.30%

Test for Residual Heterogeneity:
QE(df = 57) = 84.4977, p-val = 0.0105

Test of Moderators (coefficients 2:3):
QM(df = 2) = 10.6344, p-val = 0.0049

Model Results:

           estimate      se     zval    pval    ci.lb    ci.ub     
intrcpt     -0.2362  0.0950  -2.4864  0.0129  -0.4224  -0.0500   * 
mA           0.1061  0.0948   1.1196  0.2629  -0.0796   0.2918     
sqrt(T_i)   -0.0553  0.0179  -3.0852  0.0020  -0.0904  -0.0202  ** 

---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Now, you might think that a meta-analyst should get excited about the standardized mean difference results, since they’ve uncovered two systematic predictors of effect size magnitude. However, both of these factors are purely operational, arbitrary features of the (simulated) study designs, rather than theoretically or substantively interesting features of the studies. Considered in this light, the finding that they each moderate the magnitude of the standardized mean differences is, more than anything else, <em>annoying</em>. If we wanted to examine other more theoretically interesting moderators, we’d have to do so in a way that accounts for these methodological predictors. At minimum, that would mean including them all in a meta-regression (leading to a model with 3+ predictors). Further, we would have to worry about whether the functional form of the regression is reasonable. Simply adding the theoretical moderator to the model amounts to assuming that it predicts effect size magnitude in a linear, additive fashion, but what if that’s not the right model? Since we know the true data-generating process here, we can see that the linear, additive model <em>would not</em> be correct. But in practice, when we don’t know the true process, this would be much murkier.</p>
<p>The general principle that I’m suggesting here is that effect sizes should ideally be on a metric that is <em>independent</em> of arbitrary methodological factors because this should <em>reduce</em> overall heterogeneity and <em>simplify</em> the model, making it easier to detect real relations of interest. If one has a choice between several different effect size metrics, then a metric that shows clear associations with methodological factors should be discounted in favor of metrics that do not show such associations or show them only weakly. How to fully operationalize this sort of decision (as one would need to when writing a protocol for a meta-analysis, for example), I’m not yet sure about. It seems like a useful avenue for further methodological work.</p>


<!-- -->

</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Yes, there are other ways to define the SMD. Yes, usually we use the standard deviation pooled across both groups. I’m going to use the standard deviation in group <span class="math inline">\(A\)</span> alone because it simplifies some of the mathy bits. Please feel free to work through the case with a pooled SD for yourself.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>One of the vexing things about simulations is that you often end up needing to specify a bunch of assumptions about auxiliary quantities, beyond those of the model you’re actually interested in investigating.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Implications of mean-variance relationships for standardized mean differences</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">authors:</span><span class="co"> admin</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> '2021-11-02'</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">- standardized mean difference</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">- response ratio</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">- distribution theory</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">- meta-analysis</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> A question came up on the R-SIG-meta-analysis listserv about whether</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">  it was reasonable to use the standardized mean difference metric for synthesizing</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">  studies where the outcomes are measured as proportions. I think this is an interesting</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">  question because, while the SMD could work perfectly fine as an effect size metric</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">  for proportions, there are also other alternatives that could be considered, such</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">  as odds ratios or response ratios or raw differences in proportions. Further, there</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">  are some situations where the SMD has disadvantages for synthesizing contrasts between</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">  proportions. Thus, it's a situation where one has to make a choice about the effect</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">  size metric, and where the most common metric (the SMD) might not be the right answer.</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">  In this post, I want to provide a bit more detail regarding why I think mean-variance</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">  relationships in raw data can signal that the standardized mean differences might</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co">  be less useful as an effect size metric compared to alternatives.</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, echo = FALSE}</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.retina = 2)</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>I spend more time than I probably should discussing meta-analysis problems on the <span class="co">[</span><span class="ot">R-SIG-meta-analysis listserv</span><span class="co">](https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis)</span>. The questions that folks pose there are often quite interesting---especially when they're motivated by issues that they're wrestling with while trying to complete meta-analysis projects in their diverse fields. For those interested in meta-analytic methodology, I think perusing the mailing list is a good way to get a bit of ground sense about problems that come up in practice and places where there is a need for new methodological work, or at least further methodological guidance.</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>Recently, a <span class="co">[</span><span class="ot">question came up</span><span class="co">](https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003318.html)</span> on the listserv about whether it was reasonable to use the standardized mean difference metric for synthesizing studies where the outcomes are measured as proportions. Luke Martinez wrote:</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I'm doing a meta-analysis where the papers report only "mean" and "sd" of some form of proportion and/or "mean" and "sd" of corresponding raw frequencies. (For context, the papers ask students to read, find, and correct the wrong words in a text.) ... My question is given that all these studies only report "mean" and "sd", can I simply use a SMD effect size?</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>I think this is an interesting question because, while the <span class="co">[</span><span class="ot">SMD could work perfectly fine</span><span class="co">](https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-September/003320.html)</span> as an effect size metric for proportions, there are also other alternatives that could be considered, such as odds ratios or response ratios or raw differences in proportions. Further, there are some situations where the SMD has disadvantages for synthesizing contrasts between proportions. Thus, it's a situation where one has to make a choice about the effect size metric, and where the most common metric (the SMD) might not be the right answer. As <span class="co">[</span><span class="ot">I wrote in reply</span><span class="co">](https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003331.html)</span>: </span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; I would suggest that you could also consider other effect measures besides the SMD. For example, the response ratio is also a scale-free metric that could work with the proportion outcomes that you've described, and would also be appropriate for raw frequency counts as long as the total number possible is the same for the groups being compared within a given study.</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Whether the response ratio would be more appropriate than the SMD is hard to gauge. One would need to know more about how the proportions were assessed and how the assessment procedures varied from study to study. For instance, did some studies use passages with many possible errors to be corrected while other studies used passages with just a few errors? Did the difficulty of the passages differ from study to study? Were there very low or very high mean proportions in any studies? Does there seem to be a relationship between the means and the variances of the proportions of a given group?</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>In a <span class="co">[</span><span class="ot">follow-up</span><span class="co">](https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2021-October/003361.html)</span>, I elaborated on some potential problems with using the SMD:</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; * Variation in the number of possible errors (and perhaps also in the length of the time provided for the test?) suggests that the measures from different studies may have varying degrees of reliability. Varying reliability introduces heterogeneity in the SMD (because the denominator is inflated or shrunk by the degree of reliability).</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; * A relationship between the M and SD of the proportions for a given group suggests that the distribution of the individual-level outcomes might also exhibit mean-variance relationships. (I say "suggests" rather than implies because there's an ecological inference here, i.e., assuming something about individual-level variation on the basis of group-level variation.) If this supposition is reasonable, then that introduces a further potential source of heterogeneity in the SMDs (study-to-study variation in the M for the reference group influences the SD of the reference group, thereby inflating or shrinking the SMDs).</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>And I suggested a possible work-flow for examining the choice of effect size metric: </span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Here's how I might proceed if I were conducting</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="at">this analysis:</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1. Calculate *both* SMDs and log-transformed response ratios for the full set of studies.</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2. Examine the distribution of effect size estimates for each metric (using histograms or funnel plots). If one of the distributions is skewed or has extreme outliers, take that as an indication that the metric might not be appropriate.</span></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3. Fit meta-analytic models to summarize the distribution of effect sizes in each metric, using a model that appropriately describes the dependence structure of the estimates. Calculate I-squared statistics, give preference to the metric with lower I-squared.</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4. If (2) and (3) don't lead to a clearly preferable metric, then choose between SMD and RR based on whichever will make the synthesis results easier to explain to people.</span></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5. (Optional/extra credit) Whichever metric you choose, repeat your main analyses using the other metric and stuff all those results in supplementary materials, to satisfy any inveterate statistical curmudgeons who might review/read your synthesis.</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>(When I referred to "inveterate statistical curmudgeons", I mostly had myself in mind.)</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>In this post, I want to provide a bit more detail regarding why I think  mean-variance relationships in raw data can signal that the standardized mean differences might be less useful as an effect size metric compared to alternatives. The concern is actually broader than meta-analyses of outcomes measured as proportions, so I'll start with a different case and then return to a situation similar to the one described in the original question. </span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mean-variance relationships can induce heterogeneity</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>The standardized mean difference parameter for a given study can be defined as:</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sigma_{Ai}}, </span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>where $\mu_{Ai}$ and $\mu_{Bi}$ are the (population) mean outcomes in group $A$ and group $B$ of study $i$ and $\sigma_{Ai}$ is the (population) standard deviation in group $A$ of study $i$.<span class="ot">[^nitpicking]</span> </span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>The ideal case for using the SMD metric is when the outcomes in different studies are linearly equatable, so that the outcome scale in one study can be directly translated into the outcome scale of another study. However, if outcomes exhibit mean-variance relationships, linearly equatability seems rather implausible, and we might expect that SMDs will display heterogeneity across studies as a result.</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a><span class="ot">[^nitpicking]: </span>Yes, there are other ways to define the SMD. Yes, usually we use the standard deviation pooled across both groups. I'm going to use the standard deviation in group $A$ alone because it simplifies some of the mathy bits. Please feel free to work through the case with a pooled SD for yourself. </span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>Let me lay out an example of a situation where the outcomes exhibit mean-variance relationships and where, as a consequence, the SMD metric becomes heterogeneous. Suppose that we have $k$ studies, each involving a two-group comparison, with groups of equal size. In study $i$, the outcomes in group $A$ follow a poisson distribution with mean $\mu_{Ai}$, so that the variance of the outcomes in group $A$ is also $\mu_{Ai}$, for $i = 1,...,k$. The outcomes in group $B$ follow a poisson distribution with mean $\mu_{Bi}$, so the variance is also $\mu_{Bi}$. Now, suppose that there is a fixed, proportional relationship between $\mu_{Bi}$ and $\mu_{Ai}$,</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>so that $\mu_{Bi} = \lambda \mu_{Ai}$ for some $\lambda &gt; 0$. In other words, the treatment contrast is *constant* on the scale of the response ratio.</span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>However, the means in group $A$ vary from study to study. To make things concrete, let's assume that the means in group $A$ follow a gamma distribution with shape parameter $\alpha$ and rate parameter $\beta$:</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>\mu_{Ai} \sim \Gamma(\alpha, \beta).</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>What does this model imply about the distribution of standardized mean differences across this set of studies?</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>Under this model, the SMD parameter for study $i$ is:</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>\delta_i = \frac{\mu_{Bi} - \mu_{Ai}}{\sqrt{\mu_{Ai}}} = (\lambda - 1) \times \sqrt{\mu_{Ai}}.</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>The first term in the above expression is a constant that only</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>depend on the size of the response ratio, but the second term is random because we have assumed that the group $A$ means vary from study to study. It will therefore create heterogeneity in the SMD parameters---the greater the variance of the $\mu_{Ai}$'s, the greater the heterogeneity in $\delta_i$. Specifically, under the above assumptions, the effect size parameters follow a <span class="co">[</span><span class="ot">Nakagami distribution</span><span class="co">](https://en.wikipedia.org/wiki/Nakagami_distribution)</span>: </span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>\delta_i \sim \text{Nakagami}\left(m = \alpha, \Omega = \frac{(\lambda - 1)^2 \alpha}{\beta}\right)</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>Thus, even though we have a model where there is an underlying fixed relationship between $\mu_{Ai}$ and $\mu_{Bi}$, using the SMD metric for synthesis will lead to a situation with heterogeneous effects (even if all of the studies had large sample sizes and so effect sizes in individual studies are precisely estimated).</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a><span class="fu">## An example with proportions</span></span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>This sort of behavior is not restricted to the poisson-gamma model I sketched above. The key features of that example are a) the assumption that the outcomes have a strong mean-variance relationship and b) the assumption that the $\mu_{Ai}$'s are heterogeneous across studies. If both of these hold, then the resulting SMDs will also be heterogeneous. I'll now describe a similar model, but where the outcomes within each study are proportions. </span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>As before, suppose that we have $k$ studies, each involving a two-group comparison, with groups of equal size. In study $i$, the outcomes in group $A$ follow a binomial distribution with mean proportion $\pi_{Ai}$ and $T_i$ trials, so that the variance of the outcomes in group $A$ is $\pi_{Ai}\left(1 - \pi_{Ai}\right) T_i$, for $i = 1,...,k$. The outcomes in group $B$ also follow a binomial distribution, this one with mean proportion $\pi_{Bi}$ and $T_i$ trials, so the variance is $\pi_{Bi}\left(1 - \pi_{Bi}\right) T_i$. Next, to induce variation in the group-$A$ means, let's assume that the mean proportions follow a beta distribution:</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>\pi_{Ai} \sim \text{Beta}(\alpha, \beta).</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>Finally, suppose that $\pi_{Bi} = \lambda_i \pi_{Ai}$ for some $\lambda_i &gt; 0$. </span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>Under these assumptions, the SMD parameter for study $i$ is:</span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>\delta_i = \frac{\pi_{Bi}T_i - \pi_{Ai} T_i}{\sqrt{\pi_{Ai} (1 - \pi_{Ai}) T_i}} = (\lambda_i - 1) \times \sqrt{T_i} \times \sqrt{\frac{\pi_{Ai}}{1 - \pi_{Ai}}}.</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>From the above expression, it can be seen that there are three potential sources of variation in $\delta_i$: variation in the study-specific response ratio $\lambda_i$, variation in the group-$A$ proportions $\pi_{Ai}$, and variation in the number of trials $T_i$. The total heterogeneity in $\delta_i$ will depend on all three, as well as on the co-variation between $\lambda_i$, $\pi_{Ai}$, and $T_i$. </span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>To make this concrete, let me simulate some meta-analytic data that follows the above model. To do so, I'll need to make some additional distributional assumptions<span class="ot">[^vexing]</span>: </span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>that $\lambda_i$ is log-normally distributed such that $\ln \lambda_i \sim N(\ln \Lambda, \tau^2)$; </span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>that the number of trials is uniformly distributed on the integers between $t_{min}$ and $t_{max}$; </span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>that $N_i$, the number of observations per group in study $i$, is uniformly distributed on the integers between $n_{min}$ and $n_{max}$; and </span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>that $\pi_{Ai}$, $\lambda_i$, $T_i$, and $N_i$ are mutually independent. </span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a><span class="ot">[^vexing]: </span>One of the vexing things about simulations is that you often end up needing to specify a bunch of assumptions about auxiliary quantities, beyond those of the model you're actually interested in investigating. </span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>Here's a function that generates study-specific parameter values and sample proportions:</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>sim_binom_summary <span class="ot">&lt;-</span> <span class="cf">function</span>(pi_i, T_i, n_i) {</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_i, <span class="at">size =</span> T_i, <span class="at">prob =</span> pi_i) <span class="sc">/</span> T_i</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">M =</span> <span class="fu">mean</span>(y), <span class="at">SD =</span> <span class="fu">sd</span>(y))</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>sim_props <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>  k, <span class="co"># number of studies</span></span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a>  alpha, beta, <span class="co"># parameters of pi_Ai distribution,</span></span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a>  Lambda, tau, <span class="co"># parameters of lambda_i distribution</span></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a>  t_min, t_max, <span class="co"># parameters of T_i distribution</span></span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>  n_min, n_max <span class="co"># parameters of the sample size distribution</span></span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a>) {</span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simulate parameters</span></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>  pi_Ai <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(k, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta)</span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a>  lambda_i <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(k, <span class="at">mean =</span> <span class="fu">log</span>(Lambda), <span class="at">sd =</span> tau))</span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>  pi_Bi <span class="ot">&lt;-</span> lambda_i <span class="sc">*</span> pi_Ai</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a>  T_i <span class="ot">&lt;-</span> <span class="fu">sample</span>(t_min<span class="sc">:</span>t_max, <span class="at">size =</span> k, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a>  delta_i <span class="ot">&lt;-</span> (pi_Bi <span class="sc">-</span> pi_Ai) <span class="sc">*</span> T_i <span class="sc">/</span> <span class="fu">sqrt</span>(pi_Ai <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> pi_Ai) <span class="sc">*</span> T_i)</span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a>  n_i <span class="ot">&lt;-</span> <span class="fu">sample</span>(n_min<span class="sc">:</span>n_max, <span class="at">size =</span> k, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simulate data</span></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>  stats_A <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">pmap_dfr</span>(<span class="fu">list</span>(<span class="at">pi_i =</span> pi_Ai, <span class="at">T_i =</span> T_i, <span class="at">n_i =</span> n_i),</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a>                             sim_binom_summary) </span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a>                             </span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a>  stats_B <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">pmap_dfr</span>(<span class="fu">list</span>(<span class="at">pi_i =</span> pi_Bi, <span class="at">T_i =</span> T_i, <span class="at">n_i =</span> n_i),</span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>                             sim_binom_summary)</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compile</span></span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>    <span class="at">pi_Ai =</span> pi_Ai, <span class="at">pi_Bi =</span> pi_Bi, </span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a>    <span class="at">lambda_i =</span> lambda_i, <span class="at">T_i =</span> T_i, </span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>    <span class="at">delta_i =</span> delta_i, <span class="at">n_i =</span> n_i,</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>    <span class="at">mA =</span> stats_A<span class="sc">$</span>M, <span class="at">sdA =</span> stats_A<span class="sc">$</span>SD,</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>    <span class="at">mB =</span> stats_B<span class="sc">$</span>M, <span class="at">sdB =</span> stats_B<span class="sc">$</span>SD</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a>  <span class="co"># effect size calculations</span></span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> metafor<span class="sc">::</span><span class="fu">escalc</span>(</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> res, <span class="at">measure =</span> <span class="st">"ROM"</span>, <span class="at">var.names =</span> <span class="fu">c</span>(<span class="st">"lRR"</span>, <span class="st">"V_lRR"</span>),</span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>    <span class="at">m1i =</span> mB, <span class="at">m2i =</span> mA, </span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd1i =</span> sdB, <span class="at">sd2i =</span> sdA,</span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>    <span class="at">n1i =</span> n_i, <span class="at">n2i =</span> n_i</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> metafor<span class="sc">::</span><span class="fu">escalc</span>(</span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> res, <span class="at">measure =</span> <span class="st">"SMD"</span>, <span class="at">var.names =</span> <span class="fu">c</span>(<span class="st">"d"</span>, <span class="st">"V_d"</span>),</span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>    <span class="at">m1i =</span> mB, <span class="at">m2i =</span> mA, </span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd1i =</span> sdB, <span class="at">sd2i =</span> sdA,</span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>    <span class="at">n1i =</span> n_i, <span class="at">n2i =</span> n_i</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a>  res</span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20211024</span>)</span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">sim_props</span>(<span class="at">k =</span> <span class="dv">60</span>, <span class="at">alpha =</span> <span class="dv">12</span>, <span class="at">beta =</span> <span class="dv">4</span>, </span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a>                 <span class="at">Lambda =</span> <span class="fl">0.7</span>, <span class="at">tau =</span> .<span class="dv">05</span>,</span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a>                 <span class="at">t_min =</span> <span class="dv">5</span>, <span class="at">t_max =</span> <span class="dv">18</span>,</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a>                 <span class="at">n_min =</span> <span class="dv">10</span>, <span class="at">n_max =</span> <span class="dv">40</span>)</span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dat)</span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a>For the specified parameter values, there is only a small amount of true heterogeneity in the log of the response ratios (the blue density). Of course, there is further heterogeneity in the log response ratio estimates (the green density) due to sampling error:</span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 6, fig.height = 2.5}</span></span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a><span class="in">library(ggplot2)</span></span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot(dat) + </span></span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_density(aes(log(lambda_i), ..scaled..), fill = "blue", alpha = 0.5) + </span></span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_density(aes(lRR, ..scaled..), fill = "green", alpha = 0.2) + </span></span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a>A random effects meta-analysis confirms that there is only a modest degree of true heterogeneity in the log response ratios:</span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(metafor)</span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(<span class="at">yi =</span> lRR, <span class="at">vi =</span> V_lRR, <span class="at">data =</span> dat)</span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>Contrast this with what we get from using the standardized mean difference metric. The distributions of true effect sizes (blue) and of effect size estimates (light purple) have large spread as well as strong left skew:</span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 6, fig.height = 2.5}</span></span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a><span class="in">library(ggplot2)</span></span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot(dat) + </span></span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_density(aes(delta_i, ..scaled..), fill = "blue", alpha = 0.2) + </span></span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_density(aes(d, ..scaled..), fill = "purple", alpha = 0.5) + </span></span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a>A random effects meta-analysis of the standardized mean differences shows a greater degree of true heterogeneity, both in terms of the estimated $\tau$ and in $I^2$, or the proportion of total variance in the effect size estimates that is attributable to true heterogeneity:</span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(<span class="at">yi =</span> d, <span class="at">vi =</span> V_d, <span class="at">data =</span> dat)</span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a><span class="fu">## Diagnostics</span></span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a>The code above more-or-less implements the workflow I suggested for deciding between the standardized mean difference or response ratio metric (for proportions, we could also add further comparisons with log odds ratios and with raw differences in proportions). But is there further diagnostic information in the data that could provide a better sense of what is going on? I think there are a few things that might be helpful to consider.</span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a>First, the issues I'm concerned with here will arise when there are mean-variance relationships in the outcomes. To get at that, we can simply plot the means and SDs of each group. In the code below, I re-structure the data so that there is one row per group per study. I then plot the SD versus the mean of each group:</span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 5, fig.height = 3.5}</span></span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="in">library(dplyr)</span></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidyr)</span></span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a><span class="in">long_summary_stats &lt;- </span></span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a><span class="in">  dat %&gt;%</span></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a><span class="in">  select(n_i, T_i, mA, sdA, mB, sdB) %&gt;%</span></span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a><span class="in">  pivot_longer(cols = c(mA, sdA, mB, sdB), </span></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a><span class="in">               names_to = c(".value","group"),</span></span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a><span class="in">               names_pattern = "(m|sd)(A|B)")</span></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot(long_summary_stats,</span></span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a><span class="in">       aes(m, sd, color = group)) + </span></span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE) + </span></span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + </span></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a><span class="in">  expand_limits(y = 0) + </span></span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal() + </span></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(legend.position = c(0.1, 0.9))</span></span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a>The plot above does suggest a mean-variance relationship, though it's a bit messy. We can do better by using the scaled SD, after adjusting for the degree of spread that we would expect given $T_i$:</span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 5, fig.height = 3.5}</span></span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a><span class="in">long_summary_stats %&gt;%</span></span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(</span></span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a><span class="in">    sd_scaled = sd * sqrt(T_i)</span></span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a><span class="in">  ) %&gt;%</span></span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(aes(m, sd_scaled, color = group)) + </span></span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE) + </span></span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_function(fun = function(x) sqrt(x * (1 - x)),</span></span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a><span class="in">                color = "black") + </span></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + </span></span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a><span class="in">  expand_limits(y = 0) + </span></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal() + </span></span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a><span class="in">  theme(legend.position = c(0.1, 0.9))</span></span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a>From the above, it does appear that there could be a relationship between the scaled SD and the mean. The black curve indicates the theoretical mean-variance relationship that would be expected under the binomial distribution, and indeed the empirical relationship appears to be quite similar. This suggests that mean-variance relationships might be at play (a correct supposition, since of course we know the true data-generating process here). </span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a>Second, since the outcomes in each group are all proportions, we can simply plot the mean in group $B$ versus the mean in group $A$: </span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 5, fig.height = 4}</span></span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a><span class="in">ggplot(dat, aes(mA, mB)) + </span></span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE, color = "green") + </span></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(method = "lm", formula = y ~ x) + </span></span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a><span class="in">  coord_cartesian(xlim = c(0,1), ylim = c(0,1), expand = FALSE) + </span></span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a>This plot shows that there is a strong linear relationship between the two means, with a best-fit line that might go through the origin. This suggests that the response ratio might be an appropriate metric (although the difference in proportions might also be appropriate here, since a line with unit slope would probably fit quite well).</span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a>Third (and most speculatively/hand-wavily), I think exploratory moderator analysis can be useful here, but interpreted in a non-typical way. Under the model I've sketched, we would expect that the standardized mean difference estimates should be systematically associated with the group-$A$ means, as well as with the number of trials used to assess outcomes. The scatter-plots below show that this is indeed the case (the right-hand plot shows $d_i$ versus $\sqrt{T_i}$). </span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 7, fig.height = 3.5, out.width = "100%"}</span></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a><span class="in">library(patchwork)</span></span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a><span class="in">mA_d_plot &lt;- </span></span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(dat, aes(mA, d)) + </span></span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE, color = "green") + </span></span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(method = "lm") + </span></span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + </span></span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a><span class="in">Ti_d_plot &lt;- </span></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(dat, aes(sqrt(T_i), d)) + </span></span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE, color = "green") + </span></span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(method = "lm") + </span></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a><span class="in">mA_d_plot + Ti_d_plot</span></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a>This impression is also born out by a meta-regression that includes the group-$A$ means and $\sqrt{T_i}$ as moderators:</span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(d <span class="sc">~</span> mA <span class="sc">+</span> <span class="fu">sqrt</span>(T_i), <span class="at">vi =</span> V_d, <span class="at">data =</span> dat)</span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a>Here are the same plots as above, but using the log of the response ratio as the effect size metric:</span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 7, fig.height = 3.5, out.width = "100%"}</span></span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a><span class="in">mA_lRR_plot &lt;- </span></span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(dat, aes(mA, lRR)) + </span></span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE, color = "green") + </span></span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(method = "lm") + </span></span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a><span class="in">  scale_x_continuous(limits = c(0, 1), expand = c(0,0)) + </span></span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a><span class="in">Ti_lRR_plot &lt;- </span></span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(dat, aes(sqrt(T_i), lRR)) + </span></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point() + </span></span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(se = FALSE, color = "green") + </span></span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_smooth(method = "lm") + </span></span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a><span class="in">  theme_minimal()</span></span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a><span class="in">mA_lRR_plot + Ti_lRR_plot</span></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>In the left-hand plot, there does not appear to be any relationship between the effect size estimates and the group-$A$ means. In the right-hand plot, there does seem to be a mild relationship between the effect size estimates and $\sqrt{T_i}$, which is a bit surprising, although the strength of the relationship is much weaker than what we saw with the standardized mean differences. Meta-regression analysis supports these interpretations:</span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a><span class="fu">rma</span>(lRR <span class="sc">~</span>  mA <span class="sc">+</span> <span class="fu">sqrt</span>(T_i), <span class="at">vi =</span> V_lRR, <span class="at">data =</span> dat)</span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a>Now, you might think that a meta-analyst should get excited about the standardized mean difference results, since they've uncovered two systematic predictors of effect size magnitude. However, both of these factors are purely operational, arbitrary features of the (simulated) study designs, rather than theoretically or substantively interesting features of the studies. Considered in this light, the finding that they each moderate the magnitude of the standardized mean differences is, more than anything else, _annoying_. If we wanted to examine other more theoretically interesting moderators, we'd have to do so in a way that accounts for these methodological predictors. At minimum, that would mean including them all in a meta-regression (leading to a model with 3+ predictors). Further, we would have to worry about whether the functional form of the regression is reasonable. Simply adding the theoretical moderator to the model amounts to assuming that it predicts effect size magnitude in a linear, additive fashion, but what if that's not the right model? Since we know the true data-generating process here, we can see that the linear, additive model _would not_ be correct. But in practice, when we don't know the true process, this would be much murkier.</span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a>The general principle that I'm suggesting here is that effect sizes should ideally be on a metric that is _independent_ of arbitrary methodological factors because this should _reduce_ overall heterogeneity and _simplify_ the model, making it easier to detect real relations of interest. If one has a choice between several different effect size metrics, then a metric that shows clear associations with methodological factors should be discounted in favor of metrics that do not show such associations or show them only weakly. How to fully operationalize this sort of decision (as one would need to when writing a protocol for a meta-analysis, for example), I'm not yet sure about. It seems like a useful avenue for further methodological work.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>