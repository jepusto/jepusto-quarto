---
title: Copas selection models for meta-analysis
date: '2024-07-21'
categories:
- effect size
- distribution theory
- selective reporting
draft: true
execute:
  echo: false
bibliography: "../selection-references.bib"
csl: "../apa.csl"
link-citations: true
code-tools: true
toc: true
css: styles.css
crossref: 
  eq-prefix: ""
---

Recently, I've been working a lot on models for selective reporting of study results in meta-analysis.
I've mostly focused on [step-function selection models](/posts/step-function-selection-models/) [@hedges1992modeling; @vevea1995general; @Hedges1996estimating; @vevea2005publication], which assume that selective reporting of study results is driven fully by the $p$-values of the reported effect size estimates (and specifically, where those $p$-values fall relative to certain thresholds).
This is not the only form of selection model, though.
One prominent alternative model, usually referred to as the Copas selection model, is based on subtly different assumptions than the step-function model.
This model was described in a series of papers by John Copas and colleagues [@copas1997inference; @copas1999what; @copas2000metaanalysis; @Copas2001sensitivity] and has received quite a lot of attention in the literature on meta-analysis of medical and epidemiological research, but relatively little attention from folks focused on meta-analysis of social science research. 
In this post, I'll give an overview of the Copas model and highlight some of the ways that it differs from step function models.

# The Copas selection model 

Similar to the step function selection model, the Copas model is composed of two components: an _evidence-generating process_ that describes the distribution of effect size estimates prior to selection and a _selective reporting process_ that describes how selective reporting happens as a function of the effect size estimates. 
The evidence-generating process is (once again) just a conventional random effects model. 
Letting $T_i^*$ denote an effect size estimate prior to selective reporting, $\theta_i^*$ denote the corresponding effect size parameter, and $\sigma_i^*$ denote its (known) standard error, we assume that effect size estimate $i$ is drawn from a normal distribution with mean $\theta_i^*$ and standard deviation $\sigma_i^*$:
$$
T_i^* | \theta_i^*, \sigma_i^* \sim N\left(\theta_i^*,  \left(\sigma_i^*\right)^2\right).
$$ {#eq-evidence-generation-level1}
We further assume that the effect size parameters are drawn from a normal distribution with overall average effect size $\mu$ and standard deviation $\tau$:
$$
\theta_i^* | \sigma_i^* \sim N\left(\mu,  \tau^2\right).
$$ {#eq-evidence-generation-level2}
The full evidence-generating process can also be written as a random effects model with two sources of error:
$$
T_i^* = \mu + \nu_i^* + \epsilon_i^*,
$$ {#eq-evidence-generation-full}
where $\nu_i^* \sim N(0, \tau^2)$ and $\epsilon_i^* \sim N\left(0, \left(\sigma_i^*\right)^2\right)$.

The second component is where the Copas model diverges from the step-function model. The Copas model posits that selection is driven by a latent index $\zeta_i$ that is normally distributed, correlated with $\epsilon_i^*$, and has a mean that is a function of $\sigma_i^*$:
$$
\zeta_i = \alpha + \frac{\beta}{\sigma_i^*} + \delta_i,
$$ {#eq-selection}
where $\delta_i \sim N(0, 1)$ and $\text{cor}(\delta_i, \epsilon_i^*) = \rho$. 
With this specification, $T_i^*$ is reported (and thus available for inclusion in a meta-analysis) if $\zeta_i > 0$ and is otherwise unreported.
Following the notation of my previous post, I'll use $O_i^*$ to denote a binary indicator equal to 1 if $T_i^*$ is reported and otherwise equal to zero, so $\Pr\left(O_i^* = 1 | \sigma_i^*\right) = \Pr\left(\zeta_i > 0 | \sigma_i^*\right)$.

@Copas2001sensitivity calls $\zeta_i$ the _propensity for selection_. 
Under the posited model, the selection propensity depends both on the precision of the study through $\sigma_i^*$ (because the mean of $\zeta_i$ depends on  the inverse of $\sigma_i^*$) and on the magnitude of the reported effect size estimate (because $\zeta_i$ is correlated with $\epsilon_i^*$).
The parameter $\alpha$ controls the overall probability of selection, irrespective of the findings; $\beta$ controls how strongly selection depends on study precision; and $\rho$ controls how strongly selection depends on the effect size estimate itself.

The Copas model posits a stable correlation $\rho$ between the selection propensity index and the _samplng error_ of the random effects model, $\epsilon_i^*$. 
If there is heterogeneity in the effect size parameters and heterogeneity in the sampling variances, then the correlation between $\zeta_i$ and $T_i^*$ will differ for each study. 
With a little variance algebra, it can be seen that
$$
\text{cor}\left(\zeta_i, T_i^* | \sigma_i^*\right) = \tilde\rho_i = \frac{\rho \sigma_i^*}{\sqrt{\tau^2 + \left(\sigma_i^*\right)^2}}. 
$$ {#eq-zeta-correlation}
Using the correlation, we can write the selection propensity index in terms of a regression on $T_i^*$:
$$
\zeta_i | T_i^*, \sigma_i^* \sim N \left(\alpha + \frac{\beta}{\sigma_i^*} + \tilde\rho_i \left(\frac{T_i^* - \mu}{\sqrt{\tau^2 + \left(\sigma_i^*\right)^2}}\right), \ 1 - \rho_i^2\right).
$$
Thus, given the effect size estimate $T_i^*$ and its standard error $\sigma_i^*$, the probability that finding $i$ is reported is
$$
\Pr\left(O_i^* = 1 | T_i^*, \sigma_i^*\right) = \Phi\left(\frac{1}{\sqrt{1 - \tilde\rho_i^2}}\left[\alpha + \frac{\beta}{\sigma_i^*} + \tilde\rho_i \left(\frac{T_i^* - \mu}{\sqrt{\tau^2 + \left(\sigma_i^*\right)^2}}\right)\right]\right)
$$ {#eq-conditional-selection-probability}
[@Copas2001sensitivity, Equation 4; @hedges2005selection, Equation 9.6].

# Distribution of observed effect sizes

The observed effect size estimates $T_i$ follow a distribution equivalent to that of $\left(T_i^* | \sigma_i^*, O_i^* = 1\right)$. It's possible to find an analytic expression for the density of the observed effect sizes (using Bayes Theorem, just as in [my previous post](/posts/step-function-selection-models/)). The density of the observed $T_i$'s is
$$
\Pr\left(T_i = t| \sigma_i^*\right) = \Pr\left(T_i^* = t | \sigma_i^*, O_i^* = 1\right) = \frac{\Pr\left(O_i^* = 1 | T_i^* = t, \sigma_i^*\right) \times \Pr\left(T_i^* = t | \sigma_i^*\right)}{\Pr\left(O_i^* = 1 | \sigma_i^*\right)},
$$ {#eq-Bayes-theorem}
where the first term in the numerator is given in (@eq-conditional-selection-probability), the second term in the numerator can be derived from (@eq-evidence-generation-full), and the denominator can be derived from (@eq-selection).
Substituting everything into the above gives
$$
\Pr\left(T_i = t| \sigma_i^*\right) = \frac{1}{\sqrt{\tau^2 + \left(\sigma_i^*\right)^2}} \phi\left(\frac{t - \mu}{\sqrt{\tau^2 + \left(\sigma_i^*\right)^2}}\right) \times \frac{\Phi\left(\frac{1}{\sqrt{1 - \tilde\rho_i^2}}\left[\alpha + \frac{\beta}{\sigma_i^*} + \tilde\rho_i \left(\frac{t - \mu}{\sqrt{\tau^2 + \left(\sigma_i^*\right)^2}}\right)\right]\right)} {\Phi\left(\alpha + \frac{\beta}{\sigma_i^*}\right)}
$$ {#eq-observed-density}
This density is identical to that of the _generalized skew-normal distribution_ [@arnold1999nontruncated; @arellano20006unification]. 

Here is an interactive graph showing the distribution of the effects prior to selection (in grey) and the distribution of observed effect sizes (in blue) based on the Copas selection model:

```{ojs}
math = require("mathjs")
norm = import('https://unpkg.com/norm-dist@3.1.0/index.js?module')

eta = math.sqrt(tau**2 + sigma**2)
rho_i = rho * sigma / eta
u = alpha + beta / sigma
lambda = norm.pdf(u) / norm.cdf(u)

Ai = norm.cdf(u)
ET = mu + rho * sigma * lambda
SDT = eta * math.sqrt(1 - rho_i**2 * lambda * (u + lambda))
Ai_toprint = Ai.toFixed(3)
ET_toprint = ET.toFixed(3)
eta_toprint = eta.toFixed(3)
SDT_toprint = SDT.toFixed(3)

function CopasSelection(t, s) {
  let eta_ = math.sqrt(tau**2 + s**2);
  let rho_i_ = rho * s / eta_; 
  let z = (t - mu) / eta_;
  let x = (u + rho_i_ * z) / math.sqrt(1 - rho_i_**2);
  return norm.cdf(x);
}

```

```{ojs}
pts = 201

dat = Array(pts).fill().map((element, index) => {
  let t = mu - 3 * eta + index * eta * 6 / (pts - 1);
  let dt = norm.pdf((t - mu) / eta) / eta;
  let pr_sel = CopasSelection(t, sigma);
  return ({
    t: t,
    d_unselected: dt,
    d_selected: pr_sel * dt
  })
})

```

::::: {.grid .column-page}

:::: {.g-col-8 .center}

```{ojs}
Plot.plot({
  height: 300,
  y: {
    grid: false,
    label: "Density"
  },
  x: {
    label: "Effect size estimate (Ti)"
  },   
  marks: [
    Plot.ruleY([0]),
    Plot.ruleX([0]),
    Plot.areaY(dat, {x: "t", y: "d_unselected", fillOpacity: 0.3}),
    Plot.areaY(dat, {x: "t", y: "d_selected", fill: "blue", fillOpacity: 0.5}),
    Plot.lineY(dat, {x: "t", y: "d_selected", stroke: "blue"})
  ]
})
```

:::{.moments}

```{ojs}
tex`
\begin{aligned}
\mu &= ${mu} & \qquad \eta &= ${eta_toprint} \\
\mathbb{E}\left(T_i | \sigma_i\right) &= ${ET_toprint}
& \qquad \sqrt{\mathbb{V}\left(T_i | \sigma_i\right)} &= ${SDT_toprint} \\ 
\Pr(O_i^* = 1 | \sigma_i^*) &= ${Ai_toprint}
\end{aligned}
`
```
:::

::::

:::: {.g-col-4}

```{ojs}
//| panel: input

viewof mu = Inputs.range(
  [-2, 2], 
  {value: 0.15, step: 0.01, label: "Average effect size (mu):"}
)

viewof tau = Inputs.range(
  [0, 2], 
  {value: 0.10, step: 0.01, label: "Heterogeneity SD (tau):"}
)

viewof sigma = Inputs.range(
  [0, 1], 
  {value: 0.20, step: 0.01, label: "Standard error (sigma):"}
)

viewof alpha = Inputs.range(
  [-10, 10],
  {value: -3, step: 0.1, label: "alpha selection parameter"}
)

viewof beta = Inputs.range(
  [0, 2],
  {value: 0.5, step: 0.01, label: "beta selection parameter"}
)

viewof rho = Inputs.range(
  [-1, 1],
  {value: 0, step: 0.01, label: "rho selection parameter"}
)

```

::::


:::::

# Moments of $T_i | \sigma_i$

# Comments

The shape of the distribution does not depend at all on $\mu$, and so the bias of $T_i$ is contant across all possible values of $\mu$.

The selection propensity index is correlated with the _sampling errors_ rather than with the marginal distribution of $T_i^*$.

The probability of selection is not directly connected to $p$-values.