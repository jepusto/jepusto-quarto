@article{Ades2015simultaneous,
  title = {Simultaneous Synthesis of Treatment Effects and Mapping to a Common Scale: An Alternative to Standardisation},
  shorttitle = {Simultaneous Synthesis of Treatment Effects and Mapping to a Common Scale},
  author = {Ades, A. E. and Lu, Guobing and Dias, Sofia and Mayo-Wilson, Evan and Kounali, Daphne},
  date = {2015},
  journaltitle = {Research Synthesis Methods},
  volume = {6},
  number = {1},
  pages = {96--107},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1130},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1130},
  urldate = {2025-03-27},
  abstract = {Objective Trials often may report several similar outcomes measured on different test instruments. We explored a method for synthesising treatment effect information both within and between trials and for reporting treatment effects on a common scale as an alternative to standardisation Study design We applied a procedure that simultaneously estimates a pooled treatment effect and the “mapping” ratios between the treatment effects on test instruments in a connected network. Standardised and non-standardised treatment effects were compared. The methods were illustrated in a dataset of 22 trials of selective serotonin reuptake inhibitors against placebo for social anxiety disorder, each reporting treatment effects on between one and six of a total nine test instruments. Results Ratios of treatment effects on different test instruments varied from trial to trial, with a coefficient of variation of 18\% (95\% credible interval 11–29\%). Standardised effect models fitted the data less well, and standardised treatment effects were estimated with less relative precision than non-standardised effects and with greater relative heterogeneity. Conclusion Simultaneous synthesis of treatment effects and mapping to a common scale make fewer assumptions than standardising by dividing effects by the sample standard deviation, allow results to be reported on a common scale, and deliver estimates with superior relative precision. © 2015 The Authors. Research Synthesis Methods published by John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {evidence synthesis,mapping,multiple outcomes,social anxiety}
}

@article{Arends2000baseline,
  title = {Baseline Risk as Predictor of Treatment Benefit: Three Clinical Meta-Re-Analyses},
  shorttitle = {Baseline Risk as Predictor of Treatment Benefit},
  author = {Arends, Lidia R. and Hoes, Arno W. and Lubsen, Jacobus and Grobbee, Diederik E. and Stijnen, Theo},
  date = {2000},
  journaltitle = {Statistics in Medicine},
  volume = {19},
  number = {24},
  pages = {3497--3518},
  issn = {1097-0258},
  doi = {10.1002/1097-0258(20001230)19:24<3497::AID-SIM830>3.0.CO;2-H},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1097-0258%2820001230%2919%3A24%3C3497%3A%3AAID-SIM830%3E3.0.CO%3B2-H},
  urldate = {2025-09-24},
  abstract = {A relationship between baseline risk and treatment effect is increasingly investigated as a possible explanation of between-study heterogeneity in clinical trial meta-analysis. An approach that is still often applied in the medical literature is to plot the estimated treatment effects against the estimated measures of risk in the control groups (as a measure of baseline risk), and to compute the ordinary weighted least squares regression line. However, it has been pointed out by several authors that this approach can be seriously flawed. The main problem is that the observed treatment effect and baseline risk measures should be viewed as estimates rather than the true values. In recent years several methods have been proposed in the statistical literature to potentially deal with the measurement errors in the estimates. In this article we propose a vague priors Bayesian solution to the problem which can be carried out using the ‘Bayesian inference using Gibbs sampling’ (BUGS) implementation of Markov chain Monte Carlo numerical integration techniques. Different from other proposed methods, it uses the exact rather than an approximate likelihood, while it can handle many different treatment effect measures and baseline risk measures. The method differs from a recently proposed Bayesian method in that it explicitly models the distribution of the underlying baseline risks. We apply the method to three meta-analyses published in the medical literature and compare the results with the outcomes of the other recently proposed methods. In particular we compare our approach to McIntosh's method, for which we show how it can be carried out using standard statistical software. We conclude that our proposed method offers a very general and flexible solution to the problem, which can be carried out relatively easily with existing Bayesian analysis software. A confidence band for the underlying relationship between true effect measure and baseline risk and a confidence interval for the value of the baseline risk measure for which there is no treatment effect are easily obtained by-products of our approach. Copyright © 2000 John Wiley \& Sons, Ltd.},
  langid = {english}
}


@article{borenstein2017basics,
  title = {Basics of Meta-Analysis: {{{\mkbibemph{I}}}} {\textsuperscript{2}} Is Not an Absolute Measure of Heterogeneity: {{{\mkbibemph{I}}}} {\textsuperscript{2}} Is Not an Absolute Measure of Heterogeneity},
  shorttitle = {Basics of Meta-Analysis},
  author = {Borenstein, Michael and Higgins, Julian P. T. and Hedges, Larry V. and Rothstein, Hannah R.},
  date = {2017-03},
  journaltitle = {Research Synthesis Methods},
  volume = {8},
  number = {1},
  pages = {5--18},
  issn = {17592879},
  doi = {10.1002/jrsm.1230},
  url = {http://doi.wiley.com/10.1002/jrsm.1230},
  urldate = {2019-05-28},
  langid = {english},
  file = {C:\Users\jamespustejovsky\Zotero\storage\9X69SRTF\Borenstein et al. (2017).pdf}
}


@article{Breiman2001statistical,
  title = {Statistical {{Modeling}}: {{The Two Cultures}} (with Comments and a Rejoinder by the Author)},
  shorttitle = {Statistical {{Modeling}}},
  author = {Breiman, Leo},
  date = {2001-08-01},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {16},
  number = {3},
  issn = {0883-4237},
  doi = {10.1214/ss/1009213726},
  url = {https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full},
  urldate = {2025-10-06},
  file = {C:\Users\jamespustejovsky\Zotero\storage\VQPJ4B48\Breiman - Statistical Modeling The Two Cultures.pdf}
}

@incollection{Cooper2009research,
  title = {Research synthesis as a scientific enterprise},
  booktitle = {The {{Handbook}} of {{Research Synthesis}} and {{Meta-Analysis}}},
  author = {Cooper, H. and Hedges, Larry V.},
  editor = {Cooper, H. and Hedges, Larry V. and Valentine, Jeffrey C.},
  date = {2009},
  edition = {2},
  pages = {3--14},
  publisher = {Russell Sage Foundation},
  location = {New York, NY}
}

@article{Crede2010class,
  title = {Class Attendance in College: A Meta-Analytic Review of the Relationship of Class Attendance With Grades and Student Characteristics},
  shorttitle = {Class {{Attendance}} in {{College}}},
  author = {Credé, Marcus and Roch, Sylvia G. and Kieszczynka, Urszula M.},
  date = {2010-06},
  journaltitle = {Review of Educational Research},
  shortjournal = {Review of Educational Research},
  volume = {80},
  number = {2},
  pages = {272--295},
  issn = {0034-6543, 1935-1046},
  doi = {10.3102/0034654310362998},
  url = {https://journals.sagepub.com/doi/10.3102/0034654310362998},
  urldate = {2025-10-07},
  abstract = {A meta-analysis of the relationship between class attendance in college and college grades reveals that attendance has strong relationships with both class grades ( k = 69, N = 21,195, ρ = .44) and GPA ( k = 33, N = 9,243, ρ = .41). These relationships make class attendance a better predictor of college grades than any other known predictor of academic performance, including scores on standardized admissions tests such as the SAT, high school GPA, study habits, and study skills. Results also show that class attendance explains large amounts of unique variance in college grades because of its relative independence from SAT scores and high school GPA and weak relationship with student characteristics such as conscientiousness and motivation. Mandatory attendance policies appear to have a small positive impact on average grades ( k = 3, N = 1,421, d = .21). Implications for theoretical frameworks of student academic performance and educational policy are discussed.},
  langid = {english}
}

@article{Crisafulli2020global,
  title = {Global Epidemiology of {{Duchenne}} Muscular Dystrophy: An Updated Systematic Review and Meta-Analysis},
  shorttitle = {Global Epidemiology of {{Duchenne}} Muscular Dystrophy},
  author = {Crisafulli, Salvatore and Sultana, Janet and Fontana, Andrea and Salvo, Francesco and Messina, Sonia and Trifirò, Gianluca},
  date = {2020-12},
  journaltitle = {Orphanet Journal of Rare Diseases},
  shortjournal = {Orphanet J Rare Dis},
  volume = {15},
  number = {1},
  pages = {141},
  issn = {1750-1172},
  doi = {10.1186/s13023-020-01430-8},
  url = {https://ojrd.biomedcentral.com/articles/10.1186/s13023-020-01430-8},
  urldate = {2025-10-08},
  abstract = {Abstract                            Background               Duchenne Muscular Dystrophy (DMD) is a rare disorder caused by mutations in the dystrophin gene. A recent systematic review and meta-analysis of global DMD epidemiology is not available. This study aimed to estimate the global overall and birth prevalence of DMD through an updated systematic review of the literature.                                         Methods                                MEDLINE and EMBASE databases were searched for original research articles on the epidemiology of DMD from inception until 1st October 2019. Studies were included if they were original observational research articles written in English, reporting DMD prevalence and/or incidence along with the number of individuals of the underlying population. The quality of the studies was assessed using a STrengthening the Reporting of OBservational studies in Epidemiology (STROBE) checklist adapted for observational studies on rare diseases. To derive the pooled epidemiological prevalence estimates, a meta-analysis was performed using random-effects logistic models for overall and birth prevalence and within two different underlying populations (i.e. all individuals and in males only), separately. Heterogeneity was assessed using Cochran’s Q-test along with its derived measure of inconsistency I                 2                 .                                                        Results                                A total of 44 studies reporting the global epidemiology of DMD were included in the systematic review and only 40 were included in the meta-analysis. The pooled global DMD prevalence was 7.1 cases (95\% CI: 5.0–10.1) per 100,000 males and 2.8 cases (95\% CI: 1.6–4.6) per 100,000 in the general population, while the pooled global DMD birth prevalence was 19.8 (95\% CI:16.6–23.6) per 100,000 live male births. A very high between-study heterogeneity was found for each epidemiological outcome and for all underlying populations (I                 2                 ~{$>$}\,90\%). The test for funnel plot asymmetry suggested the absence of publication bias. Of the 44 studies included in this systematic review, 36 (81.8\%) were assessed as being of medium and 8 (18.2\%) of low quality, while no study was assessed as being of high quality.                                                        Conclusions               Generating epidemiological evidence on DMD is fundamental to support public health decision-making. The high heterogeneity and the lack of high quality studies highlights the need to conduct better quality studies on rare diseases.},
  langid = {english}
}

@article{Cummings2011arguments,
  title = {Arguments for and against Standardized Mean Differences (Effect Sizes)},
  author = {Cummings, Peter},
  date = {2011-07},
  journaltitle = {Archives of Pediatrics \& Adolescent Medicine},
  shortjournal = {Arch Pediatr Adolesc Med},
  volume = {165},
  number = {7},
  eprint = {21727271},
  eprinttype = {pubmed},
  pages = {592--596},
  issn = {1538-3628},
  doi = {10.1001/archpediatrics.2011.97},
  langid = {english},
  keywords = {Causality,Effect Modifier Epidemiologic,Humans,Meta-Analysis as Topic,Statistics as Topic}
}

@article{Davies2024mapping,
  title = {Mapping between Measurement Scales in Meta-Analysis, with Application to Measures of Body Mass Index in Children},
  author = {Davies, Annabel L. and Ades, A. E. and Higgins, Julian P. T.},
  date = {2024},
  journaltitle = {Research Synthesis Methods},
  volume = {15},
  number = {6},
  pages = {1072--1093},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1758},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1758},
  urldate = {2025-03-27},
  abstract = {Quantitative evidence synthesis methods aim to combine data from multiple medical trials to infer relative effects of different interventions. A challenge arises when trials report continuous outcomes on different measurement scales. To include all evidence in one coherent analysis, we require methods to “map” the outcomes onto a single scale. This is particularly challenging when trials report aggregate rather than individual data. We are motivated by a meta-analysis of interventions to prevent obesity in children. Trials report aggregate measurements of body mass index (BMI) either expressed as raw values or standardized for age and sex. We develop three methods for mapping between aggregate BMI data using known or estimated relationships between measurements on different scales at the individual level. The first is an analytical method based on the mathematical definitions of z-scores and percentiles. The other two approaches involve sampling individual participant data on which to perform the conversions. One method is a straightforward sampling routine, while the other involves optimization with respect to the reported outcomes. In contrast to the analytical approach, these methods also have wider applicability for mapping between any pair of measurement scales with known or estimable individual-level relationships. We verify and contrast our methods using simulation studies and trials from our data set which report outcomes on multiple scales. We find that all methods recreate mean values with reasonable accuracy, but for standard deviations, optimization outperforms the other methods. However, the optimization method is more likely to underestimate standard deviations and is vulnerable to non-convergence.},
  langid = {english},
  keywords = {body mass index,mapping,meta-analysis,optimization,sampling,standardization}
}

@article{Demir2024reliability,
  title = {A Reliability Generalization Meta-Analysis of the {{Mother-To-Infant Bonding Scale}}},
  author = {Demir, Emin and Öz, Sena and Aral, Neriman and Gürsoy, Figen},
  date = {2024-02},
  journaltitle = {Psychological Reports},
  shortjournal = {Psychol Rep},
  volume = {127},
  number = {1},
  pages = {447--464},
  issn = {0033-2941, 1558-691X},
  doi = {10.1177/00332941221114413},
  url = {https://journals.sagepub.com/doi/10.1177/00332941221114413},
  urldate = {2025-10-08},
  abstract = {The Mother-to-Infant Bonding Scale (MIBS) is among the most popular measurement tools to evaluate caregiver-infant attachment. We carried out a meta-analysis study to explore the generalizability of the reliability coefficients for the MIBS in different studies. The literature review yielded a total of 702 studies investigating caregiver-infant attachment. After removing duplicate studies, we also excluded compilations, meta-analyses, qualitative studies, those using different measurement tools, studies published in a language other than English, citations, and those whose full texts could not be accessed. Eventually, we considered a total of 26 studies with 33 Cronbach’s alpha coefficients that satisfied the inclusion criteria. We normalized the alpha coefficients using Bonett’s transformation, and the analyses were performed using a 95\% confidence interval. The findings revealed a Cronbach’s alpha ( n = 33) coefficient of 0.73 (CI = 0.68–0.77); hence, the present reliability generalization study provides evidence that the reliability scores produced after measurements with the MIBS in previous studies are acceptable across samples. Overall, further studies may reliably utilize the MIBS to evaluate mother-infant attachment.},
  langid = {english}
}

@online{Deshpande2024are,
  title = {Are You Using Test Log-Likelihood Correctly?},
  author = {Deshpande, Sameer K. and Ghosh, Soumya and Nguyen, Tin D. and Broderick, Tamara},
  date = {2024-01-18},
  eprint = {2212.00219},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2212.00219},
  url = {http://arxiv.org/abs/2212.00219},
  urldate = {2025-10-09},
  abstract = {Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Other Statistics}
}

@article{Donoho2017fifty,
  title = {50 Years of Data Science},
  author = {Donoho, David},
  date = {2017-10-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {26},
  number = {4},
  pages = {745--766},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2017.1384734},
  url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734},
  urldate = {2025-10-06},
  abstract = {More than 50 years ago, John Tukey called for a reformation of academic statistics. In “The Future of Data Analysis,” he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or “data analysis.” Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name “data science” for this envisioned field. A recent and growing phenomenon has been the emergence of “data science”programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a \$100M “Data Science Initiative” that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as “cultural appropriation.” This article reviews some ingredients of the current “data science moment,” including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for “scaling up” to “big data.” This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere “scaling up,” but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts fieldby-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are “learning from data,” and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today’s data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.},
  langid = {english},
  file = {C:\Users\jamespustejovsky\Zotero\storage\J3GHBM8Y\Donoho - 2017 - 50 Years of Data Science.pdf}
}

@article{Engels2000heterogeneity,
  title = {Heterogeneity and Statistical Significance in Meta-Analysis: An Empirical Study of 125 Meta-Analyses},
  shorttitle = {Heterogeneity and Statistical Significance in Meta-Analysis},
  author = {Engels, Eric A. and Schmid, Christopher H. and Terrin, Norma and Olkin, Ingram and Lau, Joseph},
  date = {2000-07-15},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statist. Med.},
  volume = {19},
  number = {13},
  pages = {1707--1728},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/1097-0258(20000715)19:13<1707::AID-SIM491>3.0.CO;2-P},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/1097-0258(20000715)19:13<1707::AID-SIM491>3.0.CO;2-P},
  urldate = {2025-10-06},
  langid = {english}
}

@article{Fitzgerald2025using,
  title = {Using {{Extant Data}} to {{Improve Estimation}} of the {{Standardized Mean Difference}}},
  author = {Fitzgerald, Kaitlyn G. and Tipton, Elizabeth},
  date = {2025-02-01},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  volume = {50},
  number = {1},
  pages = {128--148},
  publisher = {American Educational Research Association},
  issn = {1076-9986},
  doi = {10.3102/10769986241238478},
  url = {https://doi.org/10.3102/10769986241238478},
  urldate = {2025-05-25},
  abstract = {This article presents methods for using extant data to improve the properties of estimators of the standardized mean difference (SMD) effect size. Because samples recruited into education research studies are often more homogeneous than the populations of policy interest, the variation in educational outcomes can be smaller in these samples than is reflective of the true variation in the population. This affects effect size estimation since the sample standard deviation is used in the denominator of the SMD. We propose leveraging extant data on sample variance estimates from multiple studies, made available via clearinghouse databases such as the What Works Clearinghouse, to standardize a mean difference. This allows effect sizes to be benchmarked across a common and broad population, thus enabling better comparability across studies and interventions. We derive the new estimators of the population variance and the corresponding SMD, which pool sample variances from multiple studies using both an analysis of variance and a meta-analytic framework. We demonstrate the properties of these estimators via analytic and simulation results and offer recommendations for when these estimators are appropriate in practice.},
  langid = {english}
}

@article{Friedrich2011ratio,
  title = {Ratio of Means for Analyzing Continuous Outcomes in Meta-Analysis Performed as Well as Mean Difference Methods},
  author = {Friedrich, Jan O. and Adhikari, Neill K. J. and Beyene, Joseph},
  date = {2011-05},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {J Clin Epidemiol},
  volume = {64},
  number = {5},
  eprint = {21447428},
  eprinttype = {pubmed},
  pages = {556--564},
  issn = {1878-5921},
  doi = {10.1016/j.jclinepi.2010.09.016},
  abstract = {OBJECTIVE: Meta-analyses of continuous outcomes typically use mean differences (MDs) or standardized mean differences (SMDs) (MD in pooled standard deviation units). Ratio of means (RoM) is an alternative effect measure that performs comparably in simulation. We compared treatment effects and heterogeneity for RoM, MD, and SMD using empiric data. STUDY DESIGN AND SETTING: From the Cochrane Database (2008, issue 1), we included systematic reviews reporting continuous outcomes, selected the meta-analysis with the most (and ≥five) trials, and calculated MD (where possible), SMD, and RoM. For each pair of effect measures, we compared P-values separately for treatment effect and heterogeneity and assessed asymmetry of discordant pairs (statistically significant result for only one of two measures). RESULTS: Two hundred thirty-two of 5,053 reviews were included. Measures demonstrated similar treatment effects, with ≤6\% discordant pairs and no asymmetry. A 0.5 SMD increase corresponded to 22 (95\% confidence interval: 19, 24)\% increase using RoM. There was less heterogeneity in RoM vs. MD (n=143, P=0.007), SMD vs. RoM (n=232, P=0.005), and SMD vs. MD (n=143, P=0.004). Comparing discordant pairs, fewer meta-analyses showed significant heterogeneity with SMD vs. RoM (P=0.04), consistent with the known bias of SMD. CONCLUSION: Empiric data from diverse meta-analyses demonstrate similar treatment effects and no large differences in heterogeneity of RoM compared with difference-based methods.},
  langid = {english},
  keywords = {Bias,Data Interpretation Statistical,Female,Humans,Male,Meta-Analysis as Topic,Outcome Assessment Health Care,Randomized Controlled Trials as Topic,Research Design,Review Literature as Topic}
}

@article{Guolo2022measurement,
  title = {Measurement Errors in Control Risk Regression: {{A}} Comparison of Correction Techniques},
  shorttitle = {Measurement Errors in Control Risk Regression},
  author = {Guolo, Annamaria},
  date = {2022},
  journaltitle = {Statistics in Medicine},
  volume = {41},
  number = {1},
  pages = {163--179},
  issn = {1097-0258},
  doi = {10.1002/sim.9228},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9228},
  urldate = {2025-09-24},
  abstract = {Control risk regression is a diffuse approach for meta-analysis about the effectiveness of a treatment, relating the measure of risk with which the outcome occurs in the treated group to that in the control group. The severity of illness is a source of between-study heterogeneity that can be difficult to measure. It can be approximated by the rate of events in the control group. Since the estimate is a surrogate for the underlying risk, it is prone to measurement error. Correction methods are necessary to provide reliable inference. This article illustrates the extent of measurement error effects under different scenarios, including departures from the classical normality assumption for the control risk distribution. The performance of different measurement error corrections is examined. Attention will be paid to likelihood-based structural methods assuming a distribution for the control risk measure and to functional methods avoiding the assumption, namely, a simulation-based method and two score function methods. Advantages and limits of the approaches are evaluated through simulation. In case of large heterogeneity, structural approaches are preferable to score methods, while score methods perform better for small heterogeneity and small sample size. The simulation-based approach has a satisfactory behavior whichever the examined scenario, with no convergence issues. The methods are applied to a meta-analysis about the association between diabetes and risk of Parkinson disease. The study intends to make researchers aware of the measurement error problem occurring in control risk regression and lead them to the use of appropriate correction techniques to prevent fallacious conclusions.},
  langid = {english},
  keywords = {likelihood,measurement error,meta-analysis,score function,SIMEX}
}

@article{Hannum2020objective,
  title = {Objective Sensory Testing Methods Reveal a Higher Prevalence of Olfactory Loss in {{COVID-19}}–Positive Patients Compared to Subjective Methods: {{A}} Systematic Review and Meta-Analysis},
  shorttitle = {Objective Sensory Testing Methods Reveal a Higher Prevalence of Olfactory Loss in {{COVID-19}}–Positive Patients Compared to Subjective Methods},
  author = {Hannum, Mackenzie E and Ramirez, Vicente A and Lipson, Sarah J and Herriman, Riley D and Toskala, Aurora K and Lin, Cailu and Joseph, Paule V and Reed, Danielle R},
  date = {2020-09-29},
  journaltitle = {Chemical Senses},
  pages = {bjaa064},
  issn = {0379-864X, 1464-3553},
  doi = {10.1093/chemse/bjaa064},
  url = {https://academic.oup.com/chemse/advance-article/doi/10.1093/chemse/bjaa064/5912953},
  urldate = {2025-10-08},
  abstract = {Abstract             Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which causes coronavirus disease 2019 (COVID-19), has currently infected over 6.5 million people worldwide. In response to the pandemic, numerous studies have tried to identify causes and symptoms of the disease. Emerging evidence supports recently acquired anosmia (complete loss of smell) and hyposmia (partial loss of smell) as symptoms of COVID-19, but studies of olfactory dysfunction show a wide range of prevalence, from 5\% to 98\%. We undertook a search of Pubmed/Medline and Google Scholar with the keywords “COVID-19,” “smell,” and/or “olfaction.” We included any study that quantified smell loss (anosmia and hyposmia) as a symptom of COVID-19. Studies were grouped and compared based on the type of method used to measure smell loss—subjective measures such as self-reported smell loss versus objective measures using rated stimuli—to determine if prevalence differed by method type. For each study, 95\% confidence intervals (CIs) were calculated from point estimates of olfactory disturbances. We identified 34 articles quantifying anosmia as a symptom of COVID-19 (6 objective, 28 subjective), collected from cases identified from January 16 to April 30, 2020. The pooled prevalence estimate of smell loss was 77\% when assessed through objective measurements (95\% CI of 61.4-89.2\%) and 44\% with subjective measurements (95\% CI of 32.2-57.0\%). Objective measures are a more sensitive method to identify smell loss as a result of infection with SARS-CoV-2; the use of subjective measures, while expedient during the early stages of the pandemic, underestimates the true prevalence of smell loss.},
  langid = {english}
}

@article{HartmannBoyce2018nicotine,
  title = {Nicotine Replacement Therapy versus Control for Smoking Cessation},
  author = {Hartmann-Boyce, Jamie and Chepkin, Samantha C and Ye, Weiyu and Bullen, Chris and Lancaster, Tim},
  editor = {{Cochrane Tobacco Addiction Group}},
  date = {2018-05-31},
  journaltitle = {Cochrane Database of Systematic Reviews},
  volume = {2019},
  number = {1},
  issn = {14651858},
  doi = {10.1002/14651858.CD000146.pub5},
  url = {http://doi.wiley.com/10.1002/14651858.CD000146.pub5},
  urldate = {2025-10-09},
  langid = {english}
}

@incollection{Hedges2019statistical,
  title = {Statistical Considerations},
  booktitle = {The {{Handbook}} of {{Research Synthesis}} and {{Meta-Analysis}}},
  author = {Hedges, Larry V.},
  editor = {Cooper, H. and Hedges, Larry V. and Valentine, Jeffrey C.},
  date = {2019},
  edition = {3},
  pages = {37--48},
  publisher = {Russell Sage Foundation},
  location = {New York, NY}
}

@article{Higgins2002quantifying,
  title = {Quantifying Heterogeneity in a Meta-Analysis.},
  author = {Higgins, Julian P. T. and Thompson, Simon G.},
  date = {2002},
  journaltitle = {Statistics in Medicine},
  volume = {21},
  number = {11},
  eprint = {12111919},
  eprinttype = {pubmed},
  pages = {1539--58},
  issn = {0277-6715},
  doi = {10.1002/sim.1186},
  abstract = {The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the chi2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of (H) that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity.},
  keywords = {Adjuvant,Adjuvant: methods,Albumins,Albumins: therapeutic use,Chemotherapy,Clinical Trials as Topic,Clinical Trials as Topic: methods,Cognition Disorders,Cognition Disorders: drug therapy,Cytidine Diphosphate Choline,Cytidine Diphosphate Choline: therapeutic use,Fibrosis,Fibrosis: therapy,Fracture Fixation,Fracture Fixation: methods,Hip Fractures,Hip Fractures: surgery,Humans,Meta-Analysis as Topic,Resuscitation,Resuscitation: methods,Sarcoma,Sarcoma: drug therapy,Sclerotherapy,Statistics as Topic,Statistics as Topic: methods}
}

@article{Higgins2009reevaluation,
  title = {A Re-Evaluation of Random-Effects Meta-Analysis},
  author = {Higgins, Julian P. T. and Thompson, Simon G. and Spiegelhalter, David J.},
  date = {2009-01},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume = {172},
  number = {1},
  pages = {137--159},
  issn = {09641998, 1467985X},
  doi = {10.1111/j.1467-985X.2008.00552.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-985X.2008.00552.x},
  urldate = {2022-02-25},
  abstract = {Meta-analysis in the presence of unexplained heterogeneity is frequently undertaken by using a random-effects model, in which the effects underlying different studies are assumed to be drawn from a normal distribution. Here we discuss the justification and interpretation of such models, by addressing in turn the aims of estimation, prediction and hypothesis testing. A particular issue that we consider is the distinction between inference on the mean of the random-effects distribution and inference on the whole distribution. We suggest that random-effects meta-analyses as currently conducted often fail to provide the key results, and we investigate the extent to which distribution-free, classical and Bayesian approaches can provide satisfactory methods. We conclude that the Bayesian approach has the advantage of naturally allowing for full uncertainty, especially for prediction. However, it is not without problems, including computational intensity and sensitivity to a priori judgements. We propose a simple prediction interval for classical meta-analysis and offer extensions to standard practice of Bayesian meta-analysis, making use of an example of studies of ‘set shifting’ ability in people with eating disorders.},
  langid = {english},
  file = {C:\Users\jamespustejovsky\Zotero\storage\EEVJM9GI\Higgins et al. - 2009 - A re-evaluation of random-effects meta-analysis.pdf}
}

@article{Hopkins2024standardization,
  title = {Standardization and Other Approaches to Meta-Analyze Differences in Means},
  author = {Hopkins, Will G. and Rowlands, David S.},
  date = {2024},
  journaltitle = {Statistics in Medicine},
  volume = {43},
  number = {16},
  pages = {3092--3108},
  issn = {1097-0258},
  doi = {10.1002/sim.10114},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.10114},
  urldate = {2025-04-24},
  abstract = {Meta-analysts often use standardized mean differences (SMD) to combine mean effects from studies in which the dependent variable has been measured with different instruments or scales. In this tutorial we show how the SMD is properly calculated as the difference in means divided by a between-subject reference-group, control-group, or pooled pre-intervention SD, usually free of measurement error. When combining mean effects from controlled trials and crossovers, most meta-analysts have divided by either the pooled SD of change scores, the pooled SD of post-intervention scores, or the pooled SD of pre- and post-intervention scores, resulting in SMDs that are biased and difficult to interpret. The frequent use of such inappropriate standardizing SDs by meta-analysts in three medical journals we surveyed is due to misleading advice in peer-reviewed publications and meta-analysis packages. Even with an appropriate standardizing SD, meta-analysis of SMDs increases heterogeneity artifactually via differences in the standardizing SD between settings. Furthermore, the usual magnitude thresholds for standardized mean effects are not thresholds for clinically important differences. We therefore explain how to use other approaches to combining mean effects of disparate measures: log transformation of factor effects (response ratios) and of percent effects converted to factors; rescaling of psychometrics to percent of maximum range; and rescaling with minimum clinically important differences. In the absence of clinically important differences, we explain how standardization after meta-analysis with appropriately transformed or rescaled pre-intervention SDs can be used to assess magnitudes of a meta-analyzed mean effect in different settings.},
  langid = {english},
  keywords = {bias,change-score SD,Cochrane,factor effect,meta-analysis,standardized mean difference}
}

@article{Lu2014simultaneous,
  title = {Simultaneous Multioutcome Synthesis and Mapping of Treatment Effects to a Common Scale},
  author = {Lu, Guobing and Kounali, Daphne and Ades, A. E.},
  date = {2014-03},
  journaltitle = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
  shortjournal = {Value Health},
  volume = {17},
  number = {2},
  eprint = {24636388},
  eprinttype = {pubmed},
  pages = {280--287},
  issn = {1524-4733},
  doi = {10.1016/j.jval.2013.12.006},
  abstract = {OBJECTIVES: A new method is presented for both synthesizing treatment effects on multiple outcomes subject to measurement error and estimating coherent mapping coefficients between all outcomes. It can be applied to sets of trials reporting different combinations of patient- or clinician-reported outcomes, including both disease-specific measures and generic health-related quality-of-life measures. It is underpinned by a structural equation model that includes measurement error and latent common treatment effect factor. Treatment effects can be expressed on any of the test instruments that have been used. METHODS: This is illustrated in a synthesis of eight placebo-controlled trials of TNF-α inhibitors in ankylosing spondylitis, each reporting treatment effects on between two and five of a total six test instruments. RESULTS: The method has advantages over other methods for synthesis of multiple outcome data, including standardization and multivariate normal synthesis. Unlike standardization, it allows synthesis of treatment effect information from test instruments sensitive to different underlying constructs. It represents a special case of previously proposed multivariate normal models for evidence synthesis, but unlike the former, it also estimates mappings. Combining synthesis and mapping as a single operation makes more efficient use of available data than do current mapping methods and generates treatment effects that are consistent with the mappings. A limitation, however, is that it can only generate mappings to and from those instruments on which some trial data exist. CONCLUSIONS: The method should be assessed in a wide range of data sets on different clinical conditions, before it can be used routinely in health technology assessment.},
  langid = {english},
  pmcid = {PMC3991420},
  keywords = {Antirheumatic Agents,congeneric tests,cross-walking,Humans,mapping,Models Statistical,multioutcome synthesis,Multivariate Analysis,Outcome Assessment Health Care,Quality of Life,Randomized Controlled Trials as Topic,Spondylitis Ankylosing,Technology Assessment Biomedical,Tumor Necrosis Factor-alpha}
}

@article{Panagiotou2015commentary,
  title = {Commentary: On Effect Measures, Heterogeneity, and the Laws of Nature},
  shorttitle = {Commentary},
  author = {Panagiotou, Orestis A. and Trikalinos, Thomas A.},
  date = {2015-09},
  journaltitle = {Epidemiology},
  volume = {26},
  number = {5},
  pages = {710},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000359},
  url = {https://journals.lww.com/epidem/fulltext/2015/09000/commentary__on_effect_measures,_heterogeneity,_and.13.aspx},
  urldate = {2025-07-17},
  abstract = {An abstract is unavailable.},
  langid = {american},
  keywords = {Causality,Humans,Meta-Analysis as Topic,Models Statistical}
}

@article{Poole2015risk,
  title = {Is the Risk Difference Really a More Heterogeneous Measure?},
  author = {Poole, Charlie and Shrier, Ian and VanderWeele, Tyler J.},
  date = {2015-09},
  journaltitle = {Epidemiology},
  volume = {26},
  number = {5},
  pages = {714},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000354},
  url = {https://journals.lww.com/epidem/fulltext/2015/09000/is_the_risk_difference_really_a_more_heterogeneous.14.aspx},
  urldate = {2025-08-06},
  abstract = {There are claims in the literature that the risk difference is a more heterogeneous measure than the odds ratio or risk ratio. These claims are based on surveys of meta-analyses showing that tests reject the null hypothesis of homogeneity more often for the risk difference than for the ratio measures. Discussions of this point have neglected the fact that homogeneity tests can have different levels of statistical power (i.e., different probabilities of rejecting the null when it is false) across different scales. We give hypothetical examples in which there is arguably equal heterogeneity across risk difference and odds ratio measures but in which the risk difference homogeneity test rejects more often, and therefore has higher power, than the odds ratio homogeneity test. These examples suggest that current empirical evidence for the claim that the risk difference is more heterogeneous is not at present satisfactory. Further research could consider other approaches to empirical comparisons of the heterogeneity of the three measures.},
  langid = {american}
}

@article{Schmid1998empirical,
  title = {An Empirical Study of the Effect of the Control Rate as a Predictor of Treatment Efficacy in Meta-Analysis of Clinical Trials},
  author = {Schmid, Christopher H. and Lau, Joseph and McIntosh, Martin W. and Cappelleri, Joseph C.},
  date = {1998},
  journaltitle = {Statistics in Medicine},
  volume = {17},
  number = {17},
  pages = {1923--1942},
  issn = {1097-0258},
  doi = {10.1002/(SICI)1097-0258(19980915)17:17<1923::AID-SIM874>3.0.CO;2-6},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819980915%2917%3A17%3C1923%3A%3AAID-SIM874%3E3.0.CO%3B2-6},
  urldate = {2025-09-11},
  abstract = {If the control rate (CR) in a clinical trial represents the incidence or the baseline severity of illness in the study population, the size of treatment effects may tend to vary with the size of control rates. To investigate this hypothesis, we examined 115 meta-analyses covering a wide range of medical applications for evidence of a linear relationship between the CR and three treatment effect (TE) measures: the risk difference (RD); the log relative risk (RR), and the log odds ratio (OR). We used a hierarchical model that estimates the true regression while accounting for the random error in the measurement of and the functional dependence between the observed TE and the CR. Using a two standard error rule of significance, we found the control rate was about two times more likely to be significantly related to the RD (31 per cent) than to the RR (13 per cent) or the OR (14 per cent). Correlations between TE and CR were more likely when the meta-analysis included 10 or more trials and if patient follow-up was less than six months and homogeneous. Use of weighted linear regression (WLR) of the observed TE on the observed CR instead of the hierarchical model underestimated standard errors and overestimated the number of significant results by a factor of two. The significant correlation between the CR and the TE suggests that, rather than merely pooling the TE into a single summary estimate, investigators should search for the causes of heterogeneity related to patient characteristics and treatment protocols to determine when treatment is most beneficial and that they should plan to study this heterogeneity in clinical trials. © 1998 John Wiley \& Sons, Ltd.},
  langid = {english}
}

@article{Stijnen2010random,
  title = {Random Effects Meta-Analysis of Event Outcome in the Framework of the Generalized Linear Mixed Model with Applications in Sparse Data},
  author = {Stijnen, Theo and Hamza, Taye H. and Özdemir, Pinar},
  date = {2010-12-20},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statist. Med.},
  volume = {29},
  number = {29},
  pages = {3046--3067},
  issn = {02776715},
  doi = {10.1002/sim.4040},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.4040},
  urldate = {2025-10-09},
  langid = {english}
}

@article{VanHouwelingen2002advanced,
  title = {Advanced Methods in Meta‐analysis: Multivariate Approach and Meta‐regression},
  shorttitle = {Advanced Methods in Meta‐analysis},
  author = {Van Houwelingen, Hans C. and Arends, Lidia R. and Stijnen, Theo},
  date = {2002-02-28},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statistics in Medicine},
  volume = {21},
  number = {4},
  pages = {589--624},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.1040},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.1040},
  urldate = {2025-10-09},
  abstract = {Abstract             This tutorial on advanced statistical methods for meta‐analysis can be seen as a sequel to the recent Tutorial in Biostatistics on meta‐analysis by Normand, which focused on elementary methods. Within the framework of the general linear mixed model using approximate likelihood, we discuss methods to analyse univariate as well as bivariate treatment effects in meta‐analyses as well as meta‐regression methods. Several extensions of the models are discussed, like exact likelihood, non‐normal mixtures and multiple endpoints. We end with a discussion about the use of Bayesian methods in meta‐analysis. All methods are illustrated by a meta‐analysis concerning the efficacy of BCG vaccine against tuberculosis. All analyses that use approximate likelihood can be carried out by standard software. We demonstrate how the models can be fitted using SAS Proc Mixed. Copyright © 2002 John Wiley \& Sons, Ltd.},
  langid = {english}
}


@online{Yang2024bivariate,
  title = {Bivariate Multilevel Meta-Analysis of Log Response Ratio and Standardized Mean Difference for Robust and Reproducible Environmental and Biological Sciences},
  author = {Yang, Yefeng and Williams, Coralie and Senior, Alistair M. and Morrison, Kyle and Ricolfi, Lorenzo and Pan, Jinming and Lagisz, Malgorzata and Nakagawa, Shinichi},
  date = {2024-05-16},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.05.13.594019},
  doi = {10.1101/2024.05.13.594019},
  url = {https://www.biorxiv.org/content/10.1101/2024.05.13.594019v1},
  urldate = {2025-04-24},
  abstract = {Meta-analytic modelling plays a pivotal role in synthesizing research and informing relevant policies. Yet researchers face many analytical challenges. In environmental and biological sciences, one of the most common yet unrecognised issues is the selection between two common effect size metrics, log response ratio (lnRR) and standardized mean difference (SMD); these two are the most popular and alternative effect sizes. Having to choose between them creates room for analytical flexibility, which is susceptible to researcher degrees of freedom. Another common issue is failure to deal with statistical dependence between effect sizes, resulting in invalid inferences on evidence. We propose addressing these two issues through the joint synthesis (dual use) of lnRR and SMD. Using 75 meta-analyses, including 3,887 environmental/biological primary studies (∼20,000 effect sizes), we show a high false positive rate (40\%) in conventional meta-analytic practices (random-effects model) compared to the proposed bivariate multilevel meta-analysis of lnRR and SMD along with robust variance estimation. Relying solely on either lnRR or SMD results in non-trivial discrepancies in detecting statistically significant effects (18\%) and occasional inconsistencies in sign (9\%). Discrepancies in interpreting effect size, heterogeneity, and publication bias are prevalent between models using lnRR and SMD (e.g., 52\% for publication bias). In contrast, bivariate synthesis of lnRR and SMD yields substantial information gain, reducing standard error in effect size estimates by 29\%, equivalent to adding 40 additional effect sizes. We present a user-friendly website with a step-by-step implementation guide. Our proposed robust approach aspires to improve meta-analytic modelling using lnRR and SMD in environmental and biological evidence synthesis, amplifying their reproducibility and credibility.},
  langid = {english},
  pubstate = {prepublished}
}

@article{Zhao2022empirical,
  title = {Empirical Comparisons of Heterogeneity Magnitudes of the Risk Difference, Relative Risk, and Odds Ratio},
  author = {Zhao, Yuxi and Slate, Elizabeth H. and Xu, Chang and Chu, Haitao and Lin, Lifeng},
  date = {2022-02-12},
  journaltitle = {Systematic Reviews},
  shortjournal = {Syst Rev},
  volume = {11},
  number = {1},
  eprint = {35151340},
  eprinttype = {pubmed},
  pages = {26},
  issn = {2046-4053},
  doi = {10.1186/s13643-022-01895-7},
  langid = {english},
  pmcid = {PMC8840324},
  keywords = {Humans,Odds Ratio,Risk}
}
